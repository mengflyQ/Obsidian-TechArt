大家新年好鸭，半年没更新了，趁着周末，摸一篇特效的文章，希望大家喜欢~

![](1677315630020.png)

![](1677315630087.png)

这次我们来做死亡搁浅的扫描特效，先来看一下我实现的效果：

![](1677315630421.png)

![](1677315630890.png)

![](1677315631304.png)

‍

![](1677315631421.png)

是不是有内味儿了  

![](1677315631646.png)

![](1677315631788.png)

![](1677315632086.png)

**搁浅天下第一，还没玩的快去玩！**

![](1677315632476.png)

![](1677315632554.png)

本文主要介绍 **ASE** 结合 **Unity** 官方 **Post Process Stack** 插件（以下简称 **PPS**）制作后处理特效

首先分析一下死亡搁浅原版特效中的主要元素：  

**★ 扫描轮廓描边**

**★ 扫描等距描边**

**★ 扇形范围扫描**

**☆ 根据坡度、地形范围生成的不同标记图标**

（这里我主要讲解前三个的做法，最后一项相对进阶，只做简单介绍）  

了解了特效内容，我们就可以开始选择方案进行具体制作了

观察参考会发现，扫描特效属于全局特效，并且范围广，所以考虑使用 **PostProcess**（后处理）的方式制作

官方有一套**白给**并且还挺好用的后处理插件，即 **PPS**（可以在引擎中的 **PackageManager** 窗口进行加载）  

![](1677315632715.png)

并且 **ASE** 针对 **PPS** 也制作了一个便捷工具，可以很方便的将我们制作的后处理 **Shader** 嵌入 **PPS** 中，详细使用方法可以参考 **ASE** 官方文档：

**https://wiki.amplify.pt/index.php?title=Unity_Products:Amplify_Shader_Editor/Post_Processing_Stack**

![](1677315632852.png)

**介绍完做法与工具，我们就可以开始干了！**  

![](1677315633061.png)

首先我们来制作一个测试场景，不用特别复杂：

![](1677315633111.png)

**准备后处理 Shader**

  

  

  

在 **ASE** 如下路径中导入 **PPStackTemplates**

![](1677315633259.png)

然后打开 **ASE** 创建 **ShaderType** 为 **Post-Processing Stack** 模板的 **Shader**，并通过创建脚本或者使用 **Post-Processing Stack Tool** 将其应用到相机上

**Post-Processing Stack Tool** 的使用方法就是写好 **Shader** 之后将其拖入面板中，点击 **Build** 生成脚本：

![](1677315633412.png)

随后在 **PostProcess Volume** 中的 **Profile** 里即可添加刚刚写好的后处理了  

![](1677315633528.png)

**轮廓描边**

  

  

  

由于是后处理，所以首先想到使用 **Depth Buffer** 数据进行卷积描边，常见的描边算法有 **Sobel**（索贝尔）算子、**Laplace**（拉普拉斯）算子、**Canny**（坎尼）算子等，这里我使用的是 **Sobel** 算子，关于卷积算法以及各算子差异，有兴趣的可以移步 Wiki、知乎或者百度关键词获取更多信息

下图为 **3** 阶 **Sobel** 算子，也可以构建 **5** 阶、**7** 阶等窗口更大的 **Sobel** 算子：

![](1677315633854.png)

最终梯度公式：

![](1677315633969.png)

对于不熟悉 **Sobel** 的同学，**ASE** 官方内置如下两个 **Shader Function** 可展开节点作为 **Sobel** 的参考：  

![](1677315634057.png)

将**全局**贴图 **_CameraDepthTexture** 输入备用：

![](1677315634251.png)

连接 **Sobel** 节点网，暴露偏移量作为描线粗细参数，八个方向偏移采样以及中心像素采样：

![](1677315634531.png)

现在我们就得到了基于深度数据的描边结果：

![](1677315634693.png)

**等距描边**

  

  

  

这一步相对比较复杂，因为这里我们需要先取到世界坐标数据，才能进行距离运算，然而后处理阶段我们无法直接取得模型表面的世界坐标数据

所以要通过现有的一些数据进行推导  

这一步网上有很多种算法，但是基本思路都是通过深度数据**反求**世界坐标位置

算法女神的入门精要书里也有介绍，我记得在后处理那个章节

正常渲染流程是点经过 **MVP** **Matrix** 输出到屏幕上，现在我们有了深度数据以及屏幕坐标，也就是说我们可以通过 **Inverse Camera Projcection Matrix** 反求出屏幕某一点相对相机的位置，然后再通过 **Camera to World Matrix** 即可求出屏幕某一点的世界坐标位置了  

ASE 最新版内置了一个 **Reconstruct World Position From Depth** 的 **Shader Function**，可以打开参考：

![](1677315634828.png)

反求世界坐标结果：

![](1677315634961.png)

有了世界坐标之后我们就可以用 **Distance** 求得与空间某一点（即特效中心）的距离信息了：  

![](1677315635098.png)

根据描边原理可知，信息突变的位置会进行描边，而距离信息是线性均匀变化的，突变信息较少，我们要等距描边的信息就要手动生成所需突变，所以要对线性的距离信息进行 **Fract** 计算，得到如下：

![](1677315635231.png)

有了这些，我们就可以使用 **Sobel** 对其进行卷积描边计算了，再结合之前的轮廓描边，我们现在得到如下描边效果：

![](1677315635346.png)

至此描边部分基本结束  

**扫描范围及渐变**

  

  

  

搁浅原版是扇形的扫描范围，我们这里改成圆形，便于操作

这部分没有什么好讲的，有了世界坐标信息后，用 **Distance** 求距离做圆形 **Mask** 就好，然后对之前的描线进行一些加减乘除，只保留中间部分：  

![](1677315635496.png)

最后我们将得到的信息作为 **Mask** 乘以发光颜色叠加到原相机图像上：

![](1677315635614.png)

至此后处理部分结束，动画效果需要写个小脚本实时修改 **PPS Profile** 中的数据：  

![](1677315635764.png)

**标记点的生成**

  

  

  

由于标记点数量十分庞大，普通绘制会造成 **DrawCall** 爆炸，出于性能考虑，我选择使用 **DrawMeshInstancedIndirect** 配合特殊 **Shader** 来进行一次性绘制，官方文档给这个 **API** 的介绍是：使用 **GPU** 实例进行同一模型的多次绘制

绘制时需要每个标记点的位置信息等，加上标记点位置需要贴合场景，所以我们再一次想到使用深度数据  

建立额外的正交深度相机，竖直向下摆放在场景中抓取特效范围内的深度数据，并将其传入脚本，计算每个标记点的坐标  

根据坡度对标记点进行颜色和贴图还有尺寸的设置  

根据每个标记点位置计算每个标记点朝向主摄像机的旋转方向  

最后将每个标记点的坐标信息、尺寸信息、旋转信息、颜色信息、贴图信息等以 **ComputeBuffer** 等形式一次性传入 **Shader**，然后调用 **API** 进行绘制：

![](1677315636043.png)

最后再加上一些光晕特效就完成啦

![](1677315636232.png)

  

![](1677315636558.png)

最后希望大家喜欢，看过之后能学到东西就更好啦，附上 PP 美照一张  

![](1677315636649.png)

![](1677315636840.png)

_本文作者：Aaron_

 _E-mail：m173417199@gmail.com_ 

![](1677315636909.png)
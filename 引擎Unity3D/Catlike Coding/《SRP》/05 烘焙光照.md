---
title: 05 烘焙光照
aliases: [05 Baked Light]
tags: []
create_time: 2023-06-25 21:47
uid: 202306252147
banner: "[[Pasted image 20230625214719.png]]"
---


![[Pasted image 20230625214732.png]]

# 5.1 烘焙静态光照

除了在渲染的时候实时计算光照信息，我们还可以在运行前预先计算光源产生的直接照明和间接照明信息，并**烘焙（Baked）到光照贴图（Lightmap）或者光照探针（Light Probe）上**。当前场景中静态物体表面颜色信息是烘焙到光照贴图，而用于照明动态物体的照明信息是烘焙到光照探针，这样在运行时就不需要重新计算这些照明信息了。间接照明是全局光照的一部分，即光线通过环境或自发光的物体表面照射而来。

## 5.1.1 场景中光照的设置

若光源的 Light 组件中 Mode 属性设为 Mixed，我们称之为混合模式光源。**在场景中，所有的混合模式光源将使用同一种混合光照模式（Mixed Lighting Mode）**。要设置混合光照模式，可以通过 Window->Rendering->Lighting Settings 调出 Lighting 窗口，在 Scene 选项卡中可以看到 Mixed Lighting 选项，这就是混合光照模式的设置选项。该选项下面有两个子选项，分别是 Baked Global Illumin 复选框和 Lighting Mode 下拉列表，下拉列表的子选项有 3 个，分别是 Baked Indirect、Shadowmask 和 Subtractive。

**其中 Baked Indirect 光照模式仅对光源提供的间接照明部分进行预计算烘焙。本节我们只讨论这个**，所以将本场景的混合照明模式设置为 Baked Indirect。然后勾选 Baked Global Illumin 复选框启用烘焙照明的功能。
![[Pasted image 20230625214748.png]]

![[Pasted image 20230625214749.png]]
下图是要生成的光照贴图的常规配置，我们把 Lightmap Resolution 设置为 20，取消 Compress Lightmaps 勾选，Directional Mode 选择 Non-Directional（**默认为 Directional，它会额外烘焙出一张光源的方向贴图（Directional Map），用来存储物体表面上的入射光方向信息，使得法线贴图可以影响入射烘焙光照，让凹凸感更强一些，因为我们目前还不支持法线贴图，所以不启用它），其它用默认的值就行。**

![[Pasted image 20230625214752.png]]



## ​5.1.2 搭建烘焙场景
![[Pasted image 20230625214755.png]]

### Mixed
我们搭建一个用于烘焙的场景
1.**主方向光源的 Mode 属性设置为 Mixed**，作为混合模式光源，混合使用实时光照和烘焙光照。
2.勾选对象 Mesh Renderer 组件上的 Contribute Global Illumination 复选框。对象就可以作为光线反射的对象，提供间接照明，然后 Receive Global Illumination 属性会自动切换成 Lightmaps 模式，这意味着到达其表面的间接光也会被烘焙到光照贴图中。
3.做完这个工作后，该对象 Inspector 面板右上角的 Static 中的 Contribute GI 选项就会被勾选，所以你还可以直接勾选 Static 来更方便地做这个操作。
![[Pasted image 20230625214759.png]]

4.然后点击 Generate Lighting 烘焙整个场景的光照信息。
![[Pasted image 20230625214802.png]]

![[Pasted image 20230625214804.png]]


4.烘焙好以后，我们可以选择一个对象，然后在它的 Mesh Renderer 组件中的 Lightmapping 面板中可以看到烘焙的光照贴图的样子，点击 Open Preview 放大观看，蓝线的矩形就是我们场景中的物体在光照贴图的位置和占用大小，黄色矩形就是你选择的对象所在的位置。**烘焙的贴图大部分区域是偏蓝的，是因为天空盒导致的，它代表环境天空的间接照明。**
### Baked
我们**把主方向光源的 Mode 设置为 Baked，它会将直接光照和间接光照都烘焙到 Lightmap 中，然后场景中就不再有实时光照了，会变得很黑**。实际上烘焙的直接光照也会被视为间接光照，因此也会出现在 Lightmap 中，此时 Lightmap 会显得更加明亮。


![[Pasted image 20230625214807.png]]


# 5.2 采样烘焙光照

**现在场景中没有了实时光照，我们需要在着色器中对烘焙好的光照贴图进行采样，从而获取烘焙照明信息。**

## **5.2.1 全局光照（Global Illumination）**

1.在 ShaderLibrary 文件夹下创建一个 GI.hlsl 文件，我们将后续所有和全局光照相关的代码写在这里。首先定义一个 GI 结构体，里面定义一个漫反射颜色。**间接光照的来源是不固定的，因此只能用于漫反射照明，其镜面反射一般是通过反射探针实现的**。然后定义一个 GetGI 方法，最开始使用光照贴图的 UV 来填充漫反射，用于后续调试。
```cs
//全局光照相关库  
#ifndef CUSTOM_GI_INCLUDED  
#define CUSTOM_GI_INCLUDED  
   
struct GI   
{  
    //漫反射颜色  
    float3 diffuse;  
};  
   
GI GetGI(float2 lightMapUV)   
{  
    GI gi;  
    gi.diffuse = float3(lightMapUV, 0.0);  
    return gi;  
}  
   
#endif
```
2.给 Lighting.hlsl 文件的 GetLighting 方法添加一个 GI 结构体的传参，然后用 GI 的漫反射颜色给 color 赋一个初始值。这时我们不和表面的漫反射相乘，以便观察未修改的接收光照。

```cs
float3 GetLighting(Surface surfaceWS, BRDF brdf,  GI gi)   
{  
   ... 
   float3 color = gi.diffuse;  
   ... 
}
```
3.在 LitPass.hlsl 文件中把 GI.hlsl 文件 include 进来，放在 Light.hlsl 之前。

```cs
#include "../ShaderLibrary/GI.hlsl"  
#include "../ShaderLibrary/Lighting.hlsl"
```

4.在片元函数中获取调用 GetLighting 方法之前，我们声明一个 GI 对象，调用 GetGI 方法并传递一个值为 0 的 UV 坐标，用来获取全局光照数据，然后传递给 GetLighting 方法。

```cs
//获取全局光照数据  
 GI gi = GetGI(0.0);  
 float3 color = GetLighting(surface, brdf, gi);  
 return float4(color, surface.alpha);
```

## 5.2.2 光照贴图的 UV 坐标

1.要**获取光照贴图的 UV 坐标，需要由 Unity 将其发送到着色器中，我们需要指示渲染管线对每个被烘焙了光照信息的对象都这样做**。在 CameraRenderer 脚本的 DrawVisibleGeometry 方法中创建 drawingSettings 实例时，**给每个对象的数据属性设置为 `PerObjectData.Lightmaps`。**

```cs
var drawingSettings = new DrawingSettings(unlitShaderTagId, sortingSettings)  
{  
    enableDynamicBatching = useDynamicBatching,  
    enableInstancing = useGPUInstancing,  
    perObjectData = PerObjectData.Lightmaps  
};
```

2.在 Lit.shader 的 CustomLit Pass 中添加一个带 `LIGHTMAP_ON` 关键字的编译指令。它是否启用决定了**是否渲染光照贴图对象**。

```cs
  #pragma multi_compile _ LIGHTMAP_ON  
  #pragma multi_compile_instancing
```

3.**光照贴图的 UV 坐标是顶点数据的一部分**，应该在顶点和片元输入结构体中都定义它，在顶点函数中将其转换到片元函数中用于贴图采样。但应该只**有 LIGHTMAP_ON 关键字启用时定义它们才有意义**，所以我们暂时添加三个宏：`GI_ATTRIBUTE_DATA`，`GI_VARYINGS_DATA` 和 `TRANSFER_GI_DATA` 来作为上面的定义结果，后面会定义这些宏的内容。然后，还需添加一个宏 `GI_FRAGMENT_DATA`，用来**检索 GetGI 方法需要的参数**。

```cs
struct Attributes   
{  
    ... 
    GI_ATTRIBUTE_DATA  
    UNITY_VERTEX_INPUT_INSTANCE_ID  
};  
   
struct Varyings   
{  
    ... 
    GI_VARYINGS_DATA  
    UNITY_VERTEX_INPUT_INSTANCE_ID  
};  
//顶点函数  
Varyings LitPassVertex(Attributes input)   
{  
    Varyings output;  
    UNITY_SETUP_INSTANCE_ID(input);  
    UNITY_TRANSFER_INSTANCE_ID(input, output);  
    TRANSFER_GI_DATA(input, output);  
    ... 
}  
//片元函数  
float4 LitPassFragment(Varyings input) : SV_TARGET   
{  
    ... 
    GI gi = GetGI(GI_FRAGMENT_DATA(input));  
    ... 
}
```
4.我们在 GI.hlsl 中定义这些宏，当关键字 LIGHTMAP_ON 被定义时，应获取 lightMap 的 UV 坐标，这是通过第二个纹理坐标通道提供的，然后进行相关转换。当关键字未被定义时，这几个宏都应定义为空，GI_FRAGMENT_DATA 要设置为0。
```cs
//当需要渲染光照贴图对象时  
#if defined(LIGHTMAP_ON)  
#define GI_ATTRIBUTE_DATA float2 lightMapUV : TEXCOORD1;  
#define GI_VARYINGS_DATA float2 lightMapUV : VAR_LIGHT_MAP_UV;  
#define TRANSFER_GI_DATA(input, output) output.lightMapUV = input.lightMapUV;  
#define GI_FRAGMENT_DATA(input) input.lightMapUV  
#else  
//否则这些宏都应为空  
#define GI_ATTRIBUTE_DATA  
#define GI_VARYINGS_DATA  
#define TRANSFER_GI_DATA(input, output)  
#define GI_FRAGMENT_DATA(input) 0.0  
#endif
```

![[Pasted image 20230625214936.png]]

**光照贴图的 UV 坐标通常由 Unity 给每个 Mesh 自动生成，或者在建模软件中设置好后作为 Mesh 数据的一部分导入进来，它们会将 Mesh 平铺展开，像一张纹理一样，且保持不重叠、不拉伸、不旋转，以便将其映射到纹理坐标**。然后使所有物体均匀且不重叠的按照缩放和偏移放置在这张光照贴图中，就像将缩放和偏移应用到 Base UV 一样，我们也将其应用到光照贴图的 UV 中。 

5.在 UnityInput.hlsl 文件的 UnityPerDraw 缓冲区中我们**定义光照贴图和动态光照贴图的 UV 转换属性**。**添加动态光照贴图的 UV 转换属性是为了防止因为一些兼容问题而导致 SRP 的批处理中断。** 

```cs
CBUFFER_START(UnityPerDraw)  
... 
float4 unity_LightmapST;  
float4 unity_DynamicLightmapST;  
CBUFFER_END
```

6.在 GI 文件中修改 TRANSFER_GI_DATA 宏的定义，对光照贴图的 UV 坐标进行缩放和偏移的转换。

```cs
#define TRANSFER_GI_DATA(input, output) output.lightMapUV = input.lightMapUV * unity_LightmapST.xy + unity_LightmapST.zw;
```

下图展示了转换后的光照贴图 UV 坐标的效果。
![[Pasted image 20230625214949.png]]


## ​5.2.3 采样光照贴图

1.接下来我们可以对光照贴图进行采样了。在 GI.hlsl 中把源码库中的 `EnityLighting.hlsl` 文件 include 进来，从中获取光照贴图和它的采样器。
```cs
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/EntityLighting.hlsl"  
   
TEXTURE2D(unity_Lightmap);  
SAMPLER(samplerunity_Lightmap);
```
2.创建 SampleLightMap 方法用来进行采样，传递光照贴图的 UV 坐标，**如果渲染了光照贴图对象，调用 `SampleSingleLightmap` 方法对光照贴图进行采样**，否则直接返回 0。然后在 GetGI 方法中调用该函数，并将采样结果作为漫反射光照。

```cs
//采样光照贴图  
float3 SampleLightMap(float2 lightMapUV)   
{  
  #if defined(LIGHTMAP_ON)  
     return SampleSingleLightmap(lightMapUV);  
  #else  
     return 0.0;  
  #endif  
}  
GI GetGI(float2 lightMapUV)   
{  
    GI gi;  
    gi.diffuse = SampleLightMap(lightMapUV);  
    return gi;  
}
```

1.**`SampleSingleLightmap` 方法除了 UV 坐标还需要其它的参数**
   - 第 1 个参数是 TEXTURE2D_ARGS 宏，它需要将光照贴图和采样器作为参数；
   - 第 3 个参数是 UV 的缩放和偏移，我们之前已经用它们处理过 UV 坐标了，所以传入默认值即可；
   - 第 4 个参数是一个 Bool 值，它表示是否压缩了光照贴图，这是通过 UNITY_LIGHTMAP_FULL_HDR 是否被定义来判断的；
   - 最后一个参数是一个包含了解码指令的 float4类型的变量。
```cs
return SampleSingleLightmap(TEXTURE2D_ARGS(unity_Lightmap, samplerunity_Lightmap), lightMapUV,float4(1.0, 1.0, 0.0, 0.0),  
#if defined(UNITY_LIGHTMAP_FULL_HDR)  
   false,  
#else  
   true,  
#endif  
   float4(LIGHTMAP_HDR_MULTIPLIER, LIGHTMAP_HDR_EXPONENT, 0.0, 0.0));
```

![[Pasted image 20230625215008.png]]
4.上图是采样了烘焙照明信息后的效果，烘焙照明现在非常亮，因为它还包括了天空盒的间接环境照明，在 Lighting 窗口的 Environment Lighting 中，我们把强度系数属性设置为 0 来禁用环境光照。
![[Pasted image 20230625215011.png]]


# 5.3 光照探针

**光照贴图可以大幅度提升场景渲染的真实程度，但无法作用在非静态物体上，所以看上去运动的物体和场景就显得不协调**。

所以我们**使用光照探针（Light Probe)模拟光照贴图的效果**。

**它的原理是**：在某一光照探针的所在位置点上对光照信息进行采样，然后从该光照探针**相邻**的其它光照探针的位置上对光照信息进行采样，把这些采样得到的光照信息进行**插值**运算，便可**算出这些光照探针之间某个位置的光照信息**。运行期间这些**插值的速度很快**，可以达到**实时渲染**的要求。**利用光照探针技术，可以避免运动的物体的光照效果和整个使用静态光照贴图的场景产生不协调的感觉。光照探针在运行时性能很高效，并且它用到的光照信息可以在运行之前快速地被预计算出来。**

从实现技术角度来说，**光照探针照明技术对照亮在 3D 空间中某一个指定点的光照信息在运行前的预计算阶段进行采样，然后把这些信息通过球谐函数（Spherical Harmonic Function，球面调和函数）进行编码打包存储。在游戏运行时，通过着色器程序可以把这些光照信息编码快速地重建出光照原始效果**。

**Unity 通过 Light Probe 组件实现光照探针照明技术。**

类似光照贴图，光照探针也存储了场景中的照明信息，**不同之处在于光照贴图存储的是光线照射到场景物体表面的照明信息**，而**光照探针则存储的是穿过场景中空白空间的光线信息**，**光照探针之间的连线表示在空间中光线的传递路径。**

当然，**使用光照探针照明会有一些限制**，如果要处理光的高频信息，球谐函数的阶数就要增大，而当提升阶数时，所需要的性能耗费也会增加，因此 Unity 3D 在编码打包光照信息时用的函数都是**低阶球谐函数（通常使用三阶球谐函数），即会忽略光的一些高频信息**。

## 5.3.1 光照探针组

光照探针组件不能直接挂到一个游戏对象上面，通常需要依赖**光照探针组（Light Probe Group）组件**挂接，光照探针组组件可以挂到任何游戏对象上面。
Hierachy 中右键>Light ->Light Probe Group 可以创建一个光照探针组组件，默认情况下在一个立方体空间中包含六个探针，场景中用黄色小球表示的就是光照探针，它可以通过组件上的 Edit Light Probes 来编辑探针，你可以移动、复制或删除单个探针，就好像它们是游戏对象一样，场景中光照探针要达到一定数量才能被正确烘焙。

一个场景中可以存在多个光照探针组，Unity 最终会将所有探针组合并到一起，然后创建一个连接它们的四面体体积网格，每个动态物体最终都会进入一个四面体内，对其顶点处的四个探针进行插值，从而计算并得出应用于该对象的最终照明信息。**如果对象在光照探针覆盖区域外面，则改用最近的三角形代替，因此照明看起来可能有点奇怪。**

默认情况下，当选择一个动态对象时，将使用一个 Gizmos 来显示影响该对象的光照探针，以及在其位置的插值结果。可以通过 Lighting 窗口中的 Debug Settings 条目下调整 Light Probe Visualization 修改该设置。
![[Pasted image 20230625215024.png]]
![[Pasted image 20230625215026.png]]


**最简单的光照探针布局方式是将光照探针排列成一个规则的 3D 网格样式，这样的设置方式简单高效，但会消耗大量内存**，因为每一个光照探针本质上是一个球形的且记录了当前采样点周围环境的纹理图像。如**果一片区域的照明信息都差不多，那么就没必要使用大量光照探针了**。

**光照探针通常用于照明效果突然改变的场合（有灯光过渡的周围），如从一个较为明亮的区域进入一个较暗的区域，且不要将它们放在被烘焙的物体里面，那样最终会变黑**。

**Unity 不支持所有平面化的光照探针组，即光照探针不能平坦分布在一个水平面上，光照探针之间在垂直方向上要有高度差**。总而言之，放置光照探针的位置有很多讲究，需要自己去慢慢测试。

现在我们想把场景中的所有球体当成动态物体，**让它们接受光照探针的照明而不是光照贴图，我们可以修改所有球体的 Receive Global Illumination 属性，设置为 Light Probes 模式即可。** 设置完后会发现动态物体都变成了黑色的，让我们**接下来采样光照探针来获取光照信息**。
![[Pasted image 20230625215029.png]]


## ​5.3.2 采样光照探针

1.光照探针的插值数据需要逐对象的传递给 GPU，我们需要告诉 Unity 这么做，通过在 CameraRenderer 脚本的 DrawVisibleGeometry()方法中，**创建 drawingSettings 实例时把 `PerObjectData.LightProbe` 也赋值给 `perObjectData` 数据。**
```cs
var drawingSettings = new DrawingSettings(unlitShaderTagId, sortingSettings)  
{  
    enableDynamicBatching = useDynamicBatching,  
    enableInstancing = useGPUInstancing,  
    perObjectData = PerObjectData.Lightmaps | PerObjectData.LightProbe  
};
```

2.我们需要在 UnityInput.hlsl 文件的 UnityPerDraw 缓冲区中**定义 7 个 float4 类型变量来接收 CPU 传递来的光探针数据，它们是代表红色、绿色和蓝光的多项式组件，被命名为 `unity_SH*`**，其中*为 A、B 或 C。A 和 B 有三个版本，分别带有 r，g 和 b 后缀。

```cs
CBUFFER_START(UnityPerDraw)  
... 
float4 unity_SHAr;  
float4 unity_SHAg;  
float4 unity_SHAb;  
float4 unity_SHBr;  
float4 unity_SHBg;  
float4 unity_SHBb;  
float4 unity_SHC;  
CBUFFER_END
```

3.在 GI.hlsl 文件中**创建 `SampleLightProbe` 方法对光照探针进行采样，该方法需要一个世界空间的表面属性传参**。首先需要判断，若该对象正在使用光照贴图就直接返回 0，**否则返回 0 和使用 `SampleSH9()`方法得到的光照数据之间最大值**。**`SampleSH9` 方法用于采样光照探针的照明信息，它需要光照探针数据和表面的法线向量作为传参。**
```cs
//光照探针采样  
float3 SampleLightProbe(Surface surfaceWS)   
{  
    #if defined(LIGHTMAP_ON)  
        return 0.0;  
    #else  
        float4 coefficients[7];  
        coefficients[0] = unity_SHAr;  
        coefficients[1] = unity_SHAg;  
        coefficients[2] = unity_SHAb;  
        coefficients[3] = unity_SHBr;  
        coefficients[4] = unity_SHBg;  
        coefficients[5] = unity_SHBb;  
        coefficients[6] = unity_SHC;  
        return max(0.0, SampleSH9(coefficients, surfaceWS.normal));  
    #endif  
}
```
4.给 GetGI 方法添加一个表面属性的传参，然后将光照探针的采样结果和光照贴图的采样结果相加得到最终的漫反射照明。
```cs
GI GetGI(float2 lightMapUV, Surface surfaceWS)   
{  
    GI gi;  
    gi.diffuse = SampleLightMap(lightMapUV) + SampleLightProbe(surfaceWS);  
    return gi;  
}
```
5.最后在片元函数中调用 GetGI 方法的时候把表面属性作为参数传递。
```cs
//获取全局光照  
 GI gi = GetGI(GI_FRAGMENT_DATA(input), surface);
```

![[Pasted image 20230625215100.png]]
## 5.3.3 光照探针代理体（LPPV）

**光照探针的限制：**
1.在 3D 空间的一个位置点上，**因为有且只使用一个球面表达式用于描述光照，所以光照探针照明还不适合用于描述光线穿过一个很大的物体时的情况，这种情况下光照会发生很多变动，从而无法精准地进行模拟。光照探针适合小物体，它的照明是基于一个点，因此不适用于大的物体**。
2.**另一个限制就是，因为球谐函数是在一个球面上对光照信息进行编码，所以对于一个大型的有着平坦表面的物体，或者是一个有着凹面的物体，光照探针照明技术也不适用**。

**如果想在一个大物体上应用光照探针照明，则需要使用光照探针代理体（Light Probe Proxy Volume）组件辅助实现**。
Unity 在 5.4 版本后增加了这个光探针代理体（Light Probe Proxy Volume，LPPV）的新功能。光探针代理体是一个“**解决无法直接使用光探针技术去处理的大型动态游戏对象问题**”的组件。

我们做个实验，创建一个拉伸的立方体，如下图，把它的一边放在黑暗区域内，结果物体的整个颜色都会偏暗，这显然不符合照明。我们可以使用光照探针代理体解决这个问题，**只需要将 Light Probe Proxy Volume 组件添加到该物体上，将它 Mesh Renderer 组件上的的 Light Probes 改为 Use Proxy Volume。为了让这些探针在场景视图可见，将 Refresh Mode 属性改为 Every Frame，每帧刷新让探针可见。**

![loading]( https://uwa-edu.oss-cn-beijing.aliyuncs.com/17.1620458745262.png "UWA")
![[Pasted image 20230625215105.png]]
## ​5.3.4 采样 LPPV

1.LPPV 也需要将每个对象的数据发给 GPU，在 CameraRenderer 脚本的 DrawVisibleGeometry 方法中**实例化 DrawingSettings 的时候启用 `PerObjectData.LightProbeProxyVolume`**。

```cs
//设置渲染的 shader pass 和渲染排序  
var drawingSettings = new DrawingSettings(unlitShaderTagId, sortingSettings)  
{  
    //设置渲染时批处理的使用状态  
    enableDynamicBatching = useDynamicBatching,  
    enableInstancing = useGPUInstancing,  
    perObjectData = PerObjectData.Lightmaps | PerObjectData.LightProbe | PerObjectData.LightProbeProxyVolume  
};
```
2.然后需要在 UnityInput.hlsl 的 UnityPerDraw 缓冲区中添加 4 个相关属性。
```cs
CBUFFER_START(UnityPerDraw)  
... 
float4 unity_ProbeVolumeParams;  
float4x4 unity_ProbeVolumeWorldToObject;  
float4 unity_ProbeVolumeSizeInv;  
float4 unity_ProbeVolumeMin;  
CBUFFER_END
```
3.**光照探针代理体数据会存储在一个名为 `unity_ProbeVolumeSH` 的 3D float 纹理中，在 GI.hlsl 中通过 TEXTURE3D_FLOAT 宏获取该纹理，并获取它的采样器。**
```cs
TEXTURE3D_FLOAT(unity_ProbeVolumeSH);  
SAMPLER(samplerunity_ProbeVolumeSH);
```
4.在 SampleLightProbe 方法中通过 `unity_ProbeVolumeParams` 的 X 分量的值判断物体是否使用了 LPPV 或插值光照探针，如果使用了，必须使用 `SampleProbeVolumeSH4` 方法对光探针代理体进行采样，传参需要好几个，分别是对应纹理和采样器、世界空间的顶点位置和法线、一个转换矩阵、unity_ProbeVolumeParams 的 Y 和 Z 分量，最后是 unity_ProbeVolumeMin 和 unity_ProbeVolumeSizeInv 的 XYZ 分量。
```cs
//光照探针采样  
float3 SampleLightProbe(Surface surfaceWS)   
{  
    #if defined(LIGHTMAP_ON)  
        return 0.0;  
    #else  
        //判断是否使用 LPPV 或插值光照探针  
        if(unity_ProbeVolumeParams.x)   
        {  
            return SampleProbeVolumeSH4(TEXTURE3D_ARGS(unity_ProbeVolumeSH, samplerunity_ProbeVolumeSH), surfaceWS.position, surfaceWS.normal,  
            unity_ProbeVolumeWorldToObject, unity_ProbeVolumeParams.y, unity_ProbeVolumeParams.z, unity_ProbeVolumeMin.xyz, unity_ProbeVolumeSizeInv.xyz);  
        }  
        else   
        {  
            float4 coefficients[7];  
            ... 
        }  
     #endif  
}
```

![[Pasted image 20230625215123.png]]

对 LPPV 进行采样需要对代理体的空间进行转换，以及一些其它计算，例如代理体纹理采样和球谐函数的应用等。这种情况下，仅使用 L1 球谐函数，结果会不太精确，但可能因单个物体的表面而异。

# 5.4 Meta Pass

因为间接漫反射光照会从表面反射出来，因此还应该受到这些表面的漫反射率的影响。**Unity 使用一个特殊的 `Meta Pass` 来确定烘焙时从表面反射出来的光照，然后提供给烘焙系统，从而计算间接光照**。目前我们没有定义该 Pass，Unity 会默认我们的表面为白色。

## 5.4.1 抽离公用属性

1.添加新的 Pass 意味着需要再次定义着色器属性，我们干脆**把一些公用属性抽离到一个单独的 LitInput.hlsl 文件中**，让我们在 Shaders 文件夹下创建它，然后**将 LitPass.hlsl 文件中的纹理属性和 UnityPerMaterial 缓冲区的属性拷贝过来**，然后**定义一些基本的方法获取这些属性，而不是直接访问缓冲区中的属性**，代码如下：
```c
#ifndef CUSTOM_LIT_INPUT_INCLUDED  
#define CUSTOM_LIT_INPUT_INCLUDED  
   
TEXTURE2D(_BaseMap);  
SAMPLER(sampler_BaseMap);  
   
UNITY_INSTANCING_BUFFER_START(UnityPerMaterial)  
   
UNITY_DEFINE_INSTANCED_PROP(float4, _BaseMap_ST)  
UNITY_DEFINE_INSTANCED_PROP(float4, _BaseColor)  
UNITY_DEFINE_INSTANCED_PROP(float, _Cutoff)  
UNITY_DEFINE_INSTANCED_PROP(float, _Metallic)  
UNITY_DEFINE_INSTANCED_PROP(float, _Smoothness)  
UNITY_INSTANCING_BUFFER_END(UnityPerMaterial)  
   
float2 TransformBaseUV(float2 baseUV)   
{  
    float4 baseST = UNITY_ACCESS_INSTANCED_PROP(UnityPerMaterial, _BaseMap_ST);  
    return baseUV * baseST.xy + baseST.zw;  
}  
   
float4 GetBase(float2 baseUV)   
{  
    float4 map = SAMPLE_TEXTURE2D(_BaseMap, sampler_BaseMap, baseUV);  
    float4 color = UNITY_ACCESS_INSTANCED_PROP(UnityPerMaterial, _BaseColor);  
    return map * color;  
}  
   
float GetCutoff(float2 baseUV)   
{  
    return UNITY_ACCESS_INSTANCED_PROP(UnityPerMaterial, _Cutoff);  
}  
   
float GetMetallic(float2 baseUV)   
{  
    return UNITY_ACCESS_INSTANCED_PROP(UnityPerMaterial, _Metallic);  
}  
   
float GetSmoothness(float2 baseUV)   
{  
    return UNITY_ACCESS_INSTANCED_PROP(UnityPerMaterial, _Smoothness);  
}  
    
#endif
```
2.因为我们需要在所有的着色器 Pass 中访问它们，所以直接将 include Common 和 LitInput 文件的指令放到所有 Pass 的外面。
```c
SubShader  
{   
    HLSLINCLUDE  
        #include "../ShaderLibrary/Common.hlsl"  
        #include "LitInput.hlsl"  
        ENDHLSL  
    ... 
}
```
3.将 LitPass 文件中重复的声明删掉。
```c
// #include "../ShaderLibrary/Common.hlsl"  
//TEXTURE2D(_BaseMap);  
//SAMPLER(sampler_BaseMap);  
//  
//UNITY_INSTANCING_BUFFER_START(UnityPerMaterial)  
////提供纹理的缩放和平移  
//UNITY_DEFINE_INSTANCED_PROP(float4, _BaseMap_ST)  
//UNITY_DEFINE_INSTANCED_PROP(float4, _BaseColor)  
//UNITY_DEFINE_INSTANCED_PROP(float, _Cutoff)  
//UNITY_DEFINE_INSTANCED_PROP(float, _Metallic)  
//UNITY_DEFINE_INSTANCED_PROP(float, _Smoothness)  
//UNITY_INSTANCING_BUFFER_END(UnityPerMaterial)
```
4.顶点函数中我们使用定义好的 TransformBaseUV 方法来对 UV 坐标进行转换。
```c
 //计算缩放和偏移后的 UV 坐标  
 //float4 baseST = UNITY_ACCESS_INSTANCED_PROP(UnityPerMaterial, _BaseMap_ST);  
 output.baseUV = TransformBaseUV(input.baseUV);
```
5.在片元函数中调整一些属性的获取方式，改为使用 LitInput 文件中定义的属性获取方法。
```c
 //float4 baseMap = SAMPLE_TEXTURE2D(_BaseMap, sampler_BaseMap, input.baseUV);  
     //float4 baseColor = UNITY_ACCESS_INSTANCED_PROP(UnityPerMaterial, _BaseColor);  
     float4 base = GetBase(input.baseUV);  
     #if defined(_CLIPPING)  
         clip(base.a - GetCutoff(input.baseUV));  
     #endif  
     ... 
     surface.metallic = GetMetallic(input.baseUV);  
     surface.smoothness = GetSmoothness(input.baseUV);
```
6.我们还需要在 ShadowCasterPass.hlsl 文件中也做和 LitPass.hlsl 同样的修改。

7.在 Unlit.shader 中我们也做类似的处理。复制 LitInput.hlsl 文件命名为 UnlitInput.hlsl，因为这个着色器是不受光的，所以_Metallic 和_Smoothness 属性和相关获取方法可以删掉。然后在 Unlit.shader 的 Subshader 中做类似的 include 操作。最后跟之前一样，把 UnlitPass.hlsl 文件中重复的属性定义都删除掉。
```c
HLSLINCLUDE  
  #include "../ShaderLibrary/Common.hlsl"  
  #include "UnlitInput.hlsl"  
  ENDHLSL
```
## 5.4.2 实现 Meta Pass

1. 在 Lit.shader 和 Unlit.shader 中添加 Meta Pass 的定义，该 Pass 的 **LightMode 设置为 Meta**，**关闭剔除功能**，include 名为 MetaPass.hlsl 的文件。
```c
Pass   
{  
    Tags   
    {  
        "LightMode" = "Meta"  
    }  
   
    Cull Off  
   
    HLSLPROGRAM  
    #pragma target 3.5  
    #pragma vertex MetaPassVertex  
    #pragma fragment MetaPassFragment  
    #include "MetaPass.hlsl"  
    ENDHLSL  
 }
```
2. 在 Shaders 文件夹下新建 MetaPass.hlsl 文件，包含的初始代码如下。我们需要知道表面的漫反射率，所以 BRDF、Surface、Shadows 和 Light 的库文件要 include 进来，
- 我们只需要顶点对象空间的位置和基础 UV
- 在**顶点函数中裁剪空间的顶点位置设为 0**
- **片元函数通过 `ZERO_INITIALIZE` 宏把表面数据初始化为 0**。通过获取表面的颜色、金属度和光滑度来获取其 BRDF 数据。
```c
#ifndef CUSTOM_META_PASS_INCLUDED  
#define CUSTOM_META_PASS_INCLUDED  
   
#include "../ShaderLibrary/Surface.hlsl"  
#include "../ShaderLibrary/Shadows.hlsl"  
#include "../ShaderLibrary/Light.hlsl"  
#include "../ShaderLibrary/BRDF.hlsl"  
   
struct Attributes   
{  
    float3 positionOS : POSITION;  
    float2 baseUV : TEXCOORD0;  
};  
   
struct Varyings   
{  
    float4 positionCS : SV_POSITION;  
    float2 baseUV : VAR_BASE_UV;  
};  
   
Varyings MetaPassVertex(Attributes input)   
{  
    Varyings output;
    output.positionCS = 0.0;  
    output.baseUV = TransformBaseUV(input.baseUV);  
    return output;  
}  
   
float4 MetaPassFragment(Varyings input) : SV_TARGET   
{  
    float4 base = GetBase(input.baseUV);  
    Surface surface;  
    ZERO_INITIALIZE(Surface, surface);  
    surface.color = base.rgb;  
    surface.metallic = GetMetallic(input.baseUV);  
    surface.smoothness = GetSmoothness(input.baseUV);  
    BRDF brdf = GetBRDF(surface);  
    float4 meta = 0.0;  
    return meta;  
}   
#endif
```
现在重新烘焙场景，所有的间接照明都会消失，因为我们在片元函数中返回的是 0 向量，黑色表面不会反射任何东西。
![[Pasted image 20230625215204.png]]


3. 就像采样光照贴图一样，我们要使用光照贴图的 UV 坐标。不同的是，**我们将 UV 赋值给对象空间顶点位置的 XY 分量，Z 分量需要限制到 `[0，FLT_MIN]` 区间，其中 FLT_MIN 代表最小的正浮点数**。然后使用 `TransformWorldToHClip` 方法将该顶点位置转换到裁剪空间中（尽管传入的不是世界空间的顶点位置，不过还是需要这么做）。

```c
struct Attributes   
{  
    float3 positionOS : POSITION;  
    float2 baseUV : TEXCOORD0;  
    float2 lightMapUV : TEXCOORD1;  
};  
Varyings MetaPassVertex(Attributes input)   
{  
    Varyings output;  
    input.positionOS.xy = input.lightMapUV * unity_LightmapST.xy + unity_LightmapST.zw;  
    input.positionOS.z = input.positionOS.z > 0.0 ? FLT_MIN : 0.0;  
    output.positionCS = TransformWorldToHClip(input.positionOS);  
    output.baseUV = TransformBaseUV(input.baseUV);  
    return output;  
}
```

## 5.4.3 漫反射率

1. **Meta Pass 可用于生成不同的数据，通过定义一个 bool4 类型的标记向量 `unity_MetaFragmentControl` 进行通信**。在片元函数中进行判断，如果标记了 X 分量，则需要漫反射率。
```c
bool4 unity_MetaFragmentControl;

float4 meta = 0.0;  
if(unity_MetaFragmentControl.x)   
{  
   meta = float4(brdf.diffuse, 1.0);  
}  
return meta;
```
2. 这足以给反射光照着色，但 **Unity 的 Meta Pass 还通过加上粗糙度乘以一半的镜面反射率来提升效果**。其背后的想法是，**高镜面但粗糙的材质也可以传递一些间接光照**。最后通过 PositivePow 方法扩大反射光照，但将其限制到 unity_MaxOutputValue，这两个属性需要声明为 float 类型的。
```cs
float unity_OneOverOutputBoost;  
float unity_MaxOutputValue;

meta = float4(brdf.diffuse, 1.0);  
  meta.rgb += brdf.specular * brdf.roughness * 0.5;  
meta.rgb = min(PositivePow(meta.rgb, unity_OneOverOutputBoost), unity_MaxOutputValue);
```
因为我们的地面材质的颜色是红色的，所以间接光照大部分都是地面的红色。

![[Pasted image 20230625215219.png]]
​3.现在我们得到了正确的间接光照颜色，在 Lighting.hlsl 文件的 GetLighting 方法中，也将表面的漫反射应用上，从而得到正确的烘焙照明。
```
ShadowData shadowData = GetShadowData(surfaceWS);  
   
 float3 color = gi.diffuse * brdf.diffuse;
```

![[Pasted image 20230625215227.png]]
4.还可以通过 Lighting Settings 中把环境光照强度设回 1。然后将方向光组件的 Model 属性设为 Mixed。现在我们又有了实时光照，并且烘焙了所有的间接漫反射光照。
![[Pasted image 20230625215232.png]]
### 5.5 自发光表面

有些表面可以发出光，即使场景中没用任何照明，因为它不是真正的光源，所以它不会影响其它表面，**但可以参与烘焙光照贴图的计算中，从而照明周围的静态物体**。

## 5.5.1 实现

1.在 Shader 属性中添加两个属性，一个自发光纹理贴图和一个 HDR 自发光颜色。将颜色调成白色，自发光纹理使用 Unity 的自带纹理 Default-Particle。

```c
//自发光  
    [NoScaleOffset] _EmissionMap("Emission", 2D) = "white" {}  
    [HDR] _EmissionColor("Emission", Color) =(0.0, 0.0, 0.0, 0.0)
```
![loading]( https://uwa-edu.oss-cn-beijing.aliyuncs.com/23.1620459791706.png "UWA")
![[Pasted image 20230625215239.png]]
2.在 LitInput.hlsl 文件的 UnityPerMaterial 缓冲区中添加一个自发光颜色属性，声明一个自发光纹理属性。然后定义一个 GetEmission 方法，将采样的自发光纹理结果和颜色值相乘得到最终的自发光颜色。
```c
TEXTURE2D(_EmissionMap);  
   
UNITY_INSTANCING_BUFFER_START(UnityPerMaterial)  
... 
UNITY_DEFINE_INSTANCED_PROP(float4, _EmissionColor)  
UNITY_INSTANCING_BUFFER_END(UnityPerMaterial)  
   
float3 GetEmission(float2 baseUV)   
{  
    float4 map = SAMPLE_TEXTURE2D(_EmissionMap, sampler_BaseMap, baseUV);  
    float4 color = UNITY_ACCESS_INSTANCED_PROP(UnityPerMaterial, _EmissionColor);  
    return map.rgb * color.rgb;  
}
```
3.在 LitPass.hlsl 文件的片元函数末尾将自发光颜色添加到最终颜色中。
```c
float3 color = GetLighting(surface, brdf, gi);  
  color += GetEmission(input.baseUV);  
  return float4(color, surface.alpha);
```
4.还要在 UnlitInput.hlsl 文件中也定义一个 GetEmission 方法，不过只需获取基础纹理颜色即可。
```c
float3 GetEmission(float2 baseUV)   
{  
    return GetBase(baseUV).rgb;  
}
```
5.给 Unlit.shader 的_BaseColor 基础颜色添加一个 HDR 的标签，使得不受光的材质也能发出非常明亮的光。
```c
[HDR]  _BaseColor("Color", Color) =(1.0, 1.0, 1.0, 1.0)
```
6.将自发光颜色也配置在 PerObjectMaterialProperties.cs 脚本中，调整的颜色值同步到材质中。
```cs
static int emissionColorId = Shader.PropertyToID("_EmissionColor");  
   
[SerializeField, ColorUsage(false, true)]  
Color emissionColor = Color.black;  
   
void OnValidate()  
{  
    ... 
    block.SetColor(emissionColorId, emissionColor);  
    GetComponent<Renderer>().SetPropertyBlock(block);  
}
```
现在我们的场景中已经有了一些自发光的物体，后续准备进行烘焙。
![[Pasted image 20230625215257.png]]


## ​5.5.2 烘焙自发光

在 Meta Pass 文件的片元函数中进行判断，如果 unity_MetaFragmentControl 的 Y 分量被标记，则返回自发光的颜色，Alpha 为1。
```cs
if(unity_MetaFragmentControl.x)   
{  
    ... 
}  
else if(unity_MetaFragmentControl.y)   
{  
    meta = float4(GetEmission(input.baseUV), 1.0);  
}
```

现在自发光的光线还不能参与烘焙光照贴图的计算中，也就不会照亮其周围的物体。

**自发光是通过一个单独的 Pass 进行烘焙的，我们需要对每个材质进行烘焙自发光的设置才行**。在 CustomShaderGUI 脚本中定义一个 `BakedEmission` 方法并在 OnGUI 中调用，在 BakedEmission 方法**通过调用 MaterialEditor 的 LightmapEmissionProperty 方法将自发光的 Global Illumination 属性在材质面板中暴露出来。**

**Global Illumination 属性有三个选项：**
1. None。这是默认选项，表示物体会自发光，但自发光的颜色不会照亮其周围的物体。
2. Realtime。表示物体自发光的光线将会参与实时全局照亮计算中，这些自发光光线可以照亮周围的动态和静态物体。（已被弃用。）
3. Baked。表示本物体自发光光线将会参与烘焙光照贴图的计算中，这些自发光光线可以照亮周围的静态物体，但对动态物体无效。

**我们需要对每个自发光的物体材质的 Global Illumination 属性设置为 Baked，这将在烘焙光照贴图时使用单独的 Pass 来烘焙自发光**。但只是这样还不能起作用，当 Global Illumination 的切换选项发生改变时，**我们应该更新每个材质的 Global Illumination Flags 标志，这是一个枚举。**

![[Pasted image 20230625215314.png]]

```cs
public override void OnGUI(MaterialEditor materialEditor, MaterialProperty[] properties)  
{  
    ... 
    this.properties = properties;  
    BakedEmission();  
    ... 
}  
//烘焙自发光  
void BakedEmission()  
{  
    EditorGUI.BeginChangeCheck();  
    editor.LightmapEmissionProperty();  
    if(EditorGUI.EndChangeCheck())  
    {  
        foreach(Material m in editor.targets)  
        {  
            m.globalIlluminationFlags &=~MaterialGlobalIlluminationFlags.EmissiveIsBlack;  
        }  
    }  
}
```
下图是烘焙了自发光，开启和禁用方向光的效果。
![[Pasted image 20230625215317.png]]

![[Pasted image 20230625215319.png]]


# 5.6 烘焙透明物体

透明物体也可以进行烘焙，但需要一些额外的设置。

## 5.6.1 实现

1. 不幸的是，Unity 的烘焙系统对透明的处理是硬编码的，首先它会根据材质的渲染队列来判断该材质是透明、不透明还是裁切材质。接着将_MainTex 和_Color 属性的 Alpha 相乘，然后通过_Cutoff 属性对该透明度进行裁剪**。我们的 Shader 中目前有定义_Cutoff 属性，所以还需要定义_MainTex 和_Color 属性（虽然我们有定义_BaseMap 和_BaseColor 属性，它们作用是一样的，只是命名不一样，但是这也没办法，烘焙系统对透明的处理就是硬编码的），然后将这两个属性通过 HideInInspector 标签使它们不在材质面板中显示，因为我们不希望这两个属性被调节。
```cs
[HideInInspector] _MainTex("Texture for Lightmap", 2D) = "white" {}  
[HideInInspector] _Color("Color for Lightmap", Color) =(0.5, 0.5, 0.5, 1.0)
```
2. 我们要确保_MainTex、`_Color` 的属性值和 `_BaseMap`、`_BaseColor` 属性值保持一致，在 CustomShaderGUI 脚本中定义一个 CopyLightMappingProperties 方法，若 `_BaseMap`、`_BaseColor` 属性值有修改，则应将其同步到 `_MainTex` 和 `_Color` 中。在 OnGUI 方法的最后面调用该方法进行追踪。
```cs
public override void OnGUI(MaterialEditor materialEditor, MaterialProperty[] properties)   
{  
    ... 
    if(EditorGUI.EndChangeCheck())   
    {  
        SetShadowCasterPass();  
        CopyLightMappingProperties();  
    }  
}  
   
void CopyLightMappingProperties()   
{  
    MaterialProperty mainTex = FindProperty("_MainTex", properties, false);  
    MaterialProperty baseMap = FindProperty("_BaseMap", properties, false);  
    if(mainTex != null && baseMap != null)   
    {  
        mainTex.textureValue = baseMap.textureValue;  
        mainTex.textureScaleAndOffset = baseMap.textureScaleAndOffset;  
    }  
    MaterialProperty color = FindProperty("_Color", properties, false);  
    MaterialProperty baseColor =  
    FindProperty("_BaseColor", properties, false);  
    if(color != null && baseColor != null)   
    {  
        color.colorValue = baseColor.colorValue;  
    }  
}
```
---

# 5.7 Mesh Ball

最后我们也对 Mesh Ball 脚本生成的多个对象实例来添加全局光照的支持，**因为对象实例是在运行模式下生成的，因此它们无法被烘焙，但可以使用光照探针存储照明信息。**

## 5.7.1 光照探针的支持

1.在 Mesh Ball 脚本中的 `Graphics.DrawMeshInstanced` 方法调用中添**加额外的 5 个参数来使用光照探针**，第 1 个参数代表是否投射阴影，我们启用它。第 2 个布尔参数代表是否接收阴影，我们设为 true。第 3 个参数代表层级，我们使用默认的 0。第 4 个参数代表提供一个渲染相机，我们设置 null 为所有相机渲染它们。第 5 个参数代表光照探针插值类型，我们使用 CustomProvided。
```cs
 Graphics.DrawMeshInstanced(mesh, 0, material, matrices, 1023, block, ShadowCastingMode.On, true, 0, null, LightProbeUsage.CustomProvided);
```
2.**我们需要为所有对象实例生成插值光照探针，并将它们添加到材料属性块（MaterialPropertyBlock）中**。这意味着在配置块时，我们需要访问实例位置。我们可以**获取转换矩阵的最后一列来得到实例位置，并将它们存储在临时数组中。然后通过实例化一个 `SphericalHarmonicsL2` 类型的数组来创建每个对象实例的光照探针，并使用 `LightProbes.CalculateInterpolatedLightAndOcclusionProbes` 来填充数据**，该方法需要传递三个参数，对象实例的位置和光照探针数据，第三个参数用于遮挡，我们设置为空。**最后通过 `block.CopySHCoefficientArraysFrom` 方法将光照探针数据复制到材质属性块中。**
```cs
if(block == null)  
{  
    ... 
    block.SetFloatArray(smoothnessId, smoothness);  
    var positions = new Vector3[1023];  
    for(int i = 0; i < matrices.Length; i++)  
    {  
        positions[i] = matrices[i].GetColumn(3);  
    }  
    var lightProbes = new SphericalHarmonicsL2[1023];  
    LightProbes.CalculateInterpolatedLightAndOcclusionProbes(positions, lightProbes, null);  
    block.CopySHCoefficientArraysFrom(lightProbes);  
   
}   
```
## 5.7.2.光照探针代理体的支持

也可以对对象实例添加 LPPV 的支持，因为实例都存在于狭小空间中，这样就不必计算和存储插值光照探针。我们添加一个 `LightProbeProxyVolume` 配置字段，如果该字段正在使用，则不需要将光照探针数据添加到材质属性块中，且将 LightProbeUsage.UseProxyVolume 作为 DrawMeshInstanced 方法的最后一个参数。
```cs
 [SerializeField]  
 LightProbeProxyVolume lightProbeVolume = null;  
 void Update()  
 {  
      if(block == null)  
      {  
          ... 
          if(! lightProbeVolume)  
          {  
              var positions = new Vector3[1023];  
              ... 
              block.CopySHCoefficientArraysFrom(lightProbes);  
          }  
   
          block.SetFloat(cutoffId, cutoff);  
      }      
      Graphics.DrawMeshInstanced(mesh, 0, material, matrices, 1023, block, ShadowCastingMode.On, true, 0, null, lightProbeVolume ? LightProbeUsage.UseProxyVolume : LightProbeUsage.CustomProvided, lightProbeVolume);  
 }
```
将 LPPV 组件添加到挂载 Mesh Ball 脚本的对象中，并将组件传递给 LightProbeProxyVolume 字段。可以将 LPPV 组件的 Bounding Box Mode 设置为 Custom 自定义代理体的世界空间区域，能够将所有对象实例包裹进来。

​ ![[Pasted image 20230625215343.png]]
## 前言

本文章不具体到如何实现，只提供优化思路，内容究极压缩全是精华无废话

写这篇文章的原因是在知乎看到的有关 URP 渲染优化的内容都不太全，在其他平台购买的资料又太简单（感觉被坑了啊），所以就打算自己写一篇供后人查看。当然，个人认为相对来说比较全面，实际上也存在大量疏漏，欢迎在评论区补充，共同学习。


## UI 部分优化

### UI 与场景分离

降分辨率大法是真的立竿见影，但是如果 UI 与场景一起降分辨率会导致整个游戏都是糊的。

玩家能够接受场景分辨率稍微降低一些，UI 的分辨率不降。  
那么我们可以这么做：分离出场景与 UI 的 RT，场景在低分辨率绘制完将它 Blit 到 UI RT 上。再在 UIRT 上绘制剩下的内容。这里也需要自己魔改渲染管线。

URP 原始管线的渲染流程为：

backbuffer 渲染场景，切到 UI 相机，渲染 UI，finalblit 到屏幕上

修改后的流程为：

backbuffer 渲染场景，切到 UI 相机，创建 UIRT，场景 blit 到 UIRT 上，渲染 UI，finalblit 到屏幕上

### UI 部分再优化

上述方案会带来几个问题：UI 需要额外生成一张颜色 RT，还要再生成一张深度 RT（有人会说，嗯？UI 需要深度吗，需要的，除了在 UI 上展示 3D 物体需要外，模板值也需要在这里存储）。还需要将场景的 RT 拷贝到 UI 的 RT 上，Blit 一下在低端机也会要狗命，如果分辨率降的不多，可能会带来负优化。。

综上所述，我们可以考虑，把 UIRT 干掉，将场景与 UI RT 直接 blit 到屏幕上。

修改渲染管线流程：

backbuffer 渲染场景，blit 到屏幕 RT，渲染 UI 到屏幕上

### UI 部分另一种优化方案

基于 UI 的 PS 遮挡剔除方案

这个方案不是我想出来的，是由公司另外一位 TA 大佬提出。

[@Jave](https://www.zhihu.com/people/9cb1b2e6d98dfe0db847e0eb322cab9b)

常规方案是先渲染场景，再渲染 UI

![[631a2287569db3dac74f27474a99cf98_MD5.png]]

大佬提出的想法是，能不能将 UI 不透明部分作为深度写入到屏幕上，再渲染场景。这样场景部分就可以不需要渲染被 UI 遮挡的部分，特别是现在很多游戏都已经是 PBR 渲染了，再外加一堆一堆的半透特效，场景每个像素的复杂度都蛮高。不透明 UI 越多，性能越强。

渲染流程：

渲染 UI 到单独 RT 并先渲染一次，切到场景 RT 全屏写入一次深度信息，渲染场景，提交到屏幕时将场景与 UIRT 混合

主要还是得看 UI 遮挡量，如果量不够大，会导致负优化。注意这里场景与 UI 的混合，会导致半透部分的混合可能产生色差（特别是 Image 中使用了 Alpha 调整透明度）

**优化方案**

创建深度与颜色 RT 去绘制模型，再将 RT 渲染到 RawImage 中

**再优化一下**

像级联阴影一样，一次性渲染四个模型到 RT 上，在不同的区域展示。

## 植被优化

### prezpass

植被基本上都会使用 alphaclip，但是 alphaclip 会导致在移动端 EarlyZ 无法生效，原因是 alphaclip 是在片元着色器中进行的。可以使用 prezpass 对其进行优化。不要单纯的在植被上挂载两个材质都设置成 2450，这样会导致大量的材质交叉，导致 drawcall 爆表。

正确的做法应该是在 URP 的 piplinesettings 中增加 RenderObjects，在非透明物体之前写入 prezpass。

注意：这个方案会顶点计算是翻倍的，是否需要使用得具体看植被量，互相遮挡量等（大部分情况就无视这句话无脑怼就是了）。

### GPU 合批

大量重复植被当然是用 GPU Instancing 了！！！

嗯，确实是这样，大量重复植被用 GPU Instancing 最好了，但 Unity 默认的 GPU Instancing 的性能其实很一般。

如果你想要高性能的 GPU Instancing，建议自己写剔除逻辑，使用 DrawMeshInstanced 实例化性能最好了。

其他的用 SRP Batcher 就好了

## 灯光优化方案

想搞一个实时光源的成本可不小，搞成烘焙的高光，法线又丢了，真的要狗命。  
烘焙的时候加上 light_dir，再将 light_dir 解析出光照方向，lightmap 中解析出光照强度和颜色。拿到这些信息了，可以再去进行高光计算。做完看到法线和高光都回来了，牛批！是不是又可以找同事装一天 b 了

## Shader 品质分级

这个没啥好说的，高端机的玩家当然是效果拉满，低端玩家拿着奶奶的 500 块的合约机，能流畅玩游戏就感动天感动地了要啥自行车。听我的，搞上 Shader LOD 做品质分级。什么 PBR，换布林冯，什么法线，LightTexture 通通干掉！什么后处理，深度图，copycolor，MSAA，砍砍砍！小身板扛着所有家当怎么满帧跑两小时不发烫。

## 减少 overdraw

拿把刀，架在特效大佬脖子上。让他好好想想，这个地方的特效是不是少搞两层，如果他坚持不肯少。就拿刀背在他脖子上划拉两下。你会发现，砍效果这个事都是可以好好商量的。

## Mipmap

尽量开着吧，如果觉得贴图会糊。那就在 mipmap 的面板上瞎调调瞎找找，修改 mipmap 的等级就行了。

## Shader 内存优化

如果你把所有的 keyword 都使用了 multi_compile。那爆表是正常的。是不是 Shader 已经怼上 500M 了？再加点效果，是不是编码的小手已经在微微颤抖？

搞成 shader_feature_local 吧。收集下变体，内存直线下降，系统雾，就限制美术只能搞一个，比如 FOG_LINEAR，不然又增加了内存占用。

尽量避免用宏定义隔开计算，如果计算量不大。考虑用 lerp(a,b,switch)，内存嘎嘎往下降

## RT 优化

具体项目具体分析，能降分辨率的就尽量降低分辨率。能减少采样次数的就尽量减少采样次数（隔帧采样或者屏幕内容发生变化的时候才采样）

## 其他

把 FXAA 干掉吧，画面也没见好多少，低分辨率画面更糊了，用 URP 的 MSAA 就好了

把 UI 上的后处理记得干掉，深度信息 copycolor 啥啥啥的都干掉。用不到的

项目用的是 vulkan 还是 opengl? 确定 vulkan 真的会提升性能吗？

中远景需要 PBR 吗，需要法线吗，可以用插片吗？

纹理无脑用 ASTC_XXX 方案，其他都不用，美术会忘记就搞个工具刷下格式

超大量重复 skinedmeshrenderer 对象，把动画烘焙到纹理中，再用 GPU 合批，比 animator 性能好太多。

URP 默认的渲染中，主灯和叠加光都是 PBR 计算的，如果有较多的叠加光，那就考虑把叠加光做成布林冯会更好。

预生成是个好方法，固定视角下 ，如果需要深度图的话，可以在编辑环境先计算生成。

是否需要 2048 分辨率阴影？是否需要那么多层级联？是否需要 shadow distance 模式？

有哥们儿为了降低内存，干掉 normal 宏定义，但是未使用法线贴图多出来的 tbn 矩阵计算量也不小。

后处理考虑要不要合并到 urp 自带的后处理中，合并不进去的话是否考虑将自定义的后处理合并一下，减少 blit 操作

## 总结

大部分情况来说是没有通用优化方案的，优化的过程基本上都是效果与性能之间的权衡。

重点关注：全屏 blit，overdraw，setpasscall，顶点数，带宽，shader 计算复杂度

划水不易（咳咳），建议关注收藏，不正确的或者不明白的地方欢迎评论留言，如果有特别感兴趣的内容希望展开说说的也可以评论，视情况是否新开一篇文章

**关于技术实现细节后续将在微信公众号中同步**

![[c388f963d5e53c0eaf80a26b9e9cf469_MD5.png]]

内容原创，转载注明出处！
---
title: 线性代数基础
aliases: 
tags: 
create_time: 2023-04-25 23:37
uid: "202304252337"
banner: "[[Pasted image 20230421222215.png]]"
banner_y: 0.9275
---


> [!NOTE] 约定
> 采用列向量
> $\begin{bmatrix}a_1 \\ a_2 \\ a_3 \\ ... \\ a_n\end{bmatrix}=(a_1,a_2,…,an)^T$

# 一、向量
线性代数围绕两种基本运算：**向量加法**和**向量数乘**

<table data-draft-node="block" data-draft-type="table" data-size="normal" data-row-style="normal"><tbody><tr><th></th><th>物理观点</th><th>列表观点</th></tr><tr><td>向量的加法</td><td>运动</td><td>对应项相加</td></tr><tr><td>向量的数乘</td><td>缩放（标量的作用就是缩放）</td><td>分量与标量相乘</td></tr></tbody></table>

## 内积

> [!NOTE] 内积和点积的关系
> 在[欧几里得几何](https://zh.wikipedia.org/wiki/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E5%87%A0%E4%BD%95 "欧几里得几何")里，两条[笛卡尔坐标](https://zh.wikipedia.org/wiki/%E7%AC%9B%E5%8D%A1%E5%B0%94%E5%9D%90%E6%A0%87%E7%B3%BB "笛卡尔坐标系")向量的点积常称为**内积**。点积是**内积**的一种特殊形式：内积是点积的抽象，内积是一种双线性函数，点积是欧几里得空间（[内积空间](https://zh.wikipedia.org/wiki/%E5%86%85%E7%A7%AF%E7%A9%BA%E9%97%B4 "内积空间")）的度量。

设 n 维向量 $\alpha=(a_1,a_2,…,an)^T,\beta=(b_1,b_2,…,bn)^T$，则向量内积为
$$
(\alpha,\beta)=\alpha^{T}\beta=\beta^{T}\alpha=a_1b_1+a_2b_2+\cdots+a_3b_3
 $$  
若 $(\alpha,\beta)=0$，则 $\alpha,\beta$ **正交**，记为 $\alpha\perp\beta$  

向量长度：$\left\|\textbf{a}\right\|=\sqrt{\textbf{a}^{\mathsf{T}}\textbf{a}}=\sqrt{a_1^2+a_2^2+\cdots+a_n^2}$ 

## 点积 (dot product)

> [!NOTE] 点积公式
>1.  代数定义： $$\mathbf{a}\cdot\mathbf{b}=\sum_{i=1}^n a_i b_i=a_1b_1+a_2b_2+\cdots+a_n b_n$$
> 2. 几何定义： $$\mathbf{a}\cdot\mathbf{b}=\|\mathbf{a}\|\ \|\mathbf{b}\|\cos\theta$$
> 点积为 0，向量正交
> 
> 3. 正交投影 (向量 a 落在向量 b 上的正交投影)
> $$\mathbf p=proj_{b}(a)=||a||\cos{\theta}$$

**又称标量积、数量积 (scalar product)。它是两个数字序列的相应条目的乘积之和。** 在欧几里得几何中，两个向量的笛卡尔坐标的点积被广泛使用。它通常被称为**欧几里得空间（欧氏空间）的内积**（或很少称为**投影积**），是**内积的一种特殊情况**，尽管它不是可以在欧几里得空间上定义的唯一内积。

在代数上，点积是两个数字序列的相应条目的乘积之和。在几何上，它是两个向量的欧几里得大小和它们之间夹角的余弦的乘积。这两个定义在使用笛卡尔坐标时是等价的。在现代几何中，欧几里得空间通常使用向量空间来定义。在这种情况下，点积用于定义长度（向量的长度是向量本身的点积的平方根）和角度（两个向量夹角的余弦等于它们的点积与它们长度的乘积的商）。

### 代数定义

![[1676774595161.png]]

### 几何定义

![[1676774595282.png]]

## 叉积 (cross product)

> [!NOTE] 叉积公式
> 1. 代数定义，注意第二行的顺序：
> $$\begin{bmatrix}x_1\\ y_1\\ z_1\end{bmatrix}\times\begin{bmatrix}x_2\\ y_2\\ z_2\end{bmatrix}=\begin{bmatrix}y_1z_2-z_1y_2\\ z_1x_2-x_1z_2\\ x_1y_2-y_1x_2\end{bmatrix}$$
> 
>1. 几何定义：c 是一个正交（垂直）于 **a** 和 **b** 的向量（方向：右手定则）
> $$c=a\times b$$
>
>4. 叉积的大小=平行四边形面积：
> $$||\mathbf{a}\times\mathbf{b}||\,=\,||\mathbf{a}||\,||\mathbf{b}||\,\sin\theta=两个边a和b形成的平行四边形的面积$$
> 


又称**向量积** (vector product )（有时是**有向面积积**，以强调其几何意义）是在三维有向欧几里得向量空间，并用符号 $\times$ 表示. 给定两个线性独立的向量 **a** 和 **b**，叉积 **a** × **b**（读作 “a cross b”）是一个垂直于 **a** 和 **b** 的向量，因此垂直于包含它们的平面。

### 定义

![[1676774595482.png]]

下图为使用 Sarrus 规则得到 **a** 和 **b** **的叉积**

![[1676774595670.png]]

叉积也可以表示为形式行列式：

![[1676774595768.png]]

这个行列式可以使用 Sarrus 规则或辅因子扩展来计算。使用 Sarrus 规则，它扩展为

![[1676774595864.png]]

 沿用第一行使用辅因子改为，它展开为

![[1676774595933.png]]

它直接给出了结果的分量。

### 几何意义

![[1676774596000.png]]


## 规范化
**normalize** 的不同译法：标准化，归一化，规范化，规格化，单位化...... 译者按：区间、范围为归一化，名词向量或空间为规范化 (把一个向量的长度变为单位长度称为向量的规范化，方法是将向量的每个分量除以该向量的模，结果得到一个单位向量。

有一个特殊类型的向量叫做**单位向量 (Unit Vector)**。单位向量有一个特别的性质——它的长度是 1。我们可以用任意向量的每个分量除以向量的长度得到它的单位向量 $\hat{n}$：
$$\:\hat{n}=\dfrac{\bar{v}}{||\bar{v}||}$$
## 正交化
如果向量集 $\{{v_0,\cdots,v_{n-1}} \}$ 中的每个向量都是互相正交且皆具单位长度，那么我们就称此集合是**规范正交 (orthonormal)的。

![[Pasted image 20230402125557.png]]
2D 正交化：假设我们有向量集合 ${v_0,v_1}$ ，现欲将它正交化为图 1.11 中所示的正交集 ${w_0, w_1}$。首先设 ${w_0=v_0}$, 通过使 $v_1$ 减去它在 $w_0$ 上的分量（投影）来令它正交于 $w_0$ :
$$w_1=v_1-proj_{w_0} (v_1)$$
此时得到了元素相互正交的向量集合 $\{w_0,w_1 \}$ ，最后将其规范化为单位向量即可。

3D 正交化方法类似，这种方法比较麻烦，我们可以采用更通用的方法，即格拉姆-施密特 （Gram-Schmidt Orthogonalization）正交化（以下简称施密特正交化）。
### 施密特正交化

> [!NOTE] 计算方法
> 如果向量组 $\alpha_1,\alpha_2,\alpha_3$ 线性无关，令
> $$
\begin{array}{l}
\boldsymbol{\beta}_{_1}=\boldsymbol{\alpha}_{_1}\:,\\
\boldsymbol{\beta}_2\:=\:\boldsymbol{\alpha}_2-\frac{(\boldsymbol{\alpha}_2\:,\boldsymbol{\beta}_1)}{(\boldsymbol{\beta}_1\:,\boldsymbol{\beta}_1)}\boldsymbol{\beta}_1\\
\boldsymbol{\beta}_3\:=\:\boldsymbol{\alpha}_3-\frac{(\boldsymbol{\alpha}_3\:,\boldsymbol{\beta}_1\:)}{(\boldsymbol{\beta}_1\:,\boldsymbol{\beta}_1\:)}\boldsymbol{\beta}_1-\frac{(\boldsymbol{\alpha}_3\:,\boldsymbol{\beta}_2\:)}{(\boldsymbol{\beta}_2\:,\boldsymbol{\beta}_2\:)}\boldsymbol{\beta}_2\:,
\end{array}
>$$
那么 $\beta_1,\beta_2,\beta_3$ 两两正交，称为正交向量组，将其规范化，有 $$
\boldsymbol{\gamma}_1=\dfrac{\boldsymbol{\beta}_1}{\|\boldsymbol{\beta}_1\|},\boldsymbol{\gamma}_2=\dfrac{\boldsymbol{\beta}_2}{\|\boldsymbol{\beta}_2\|},\boldsymbol{\gamma}_3=\dfrac{\boldsymbol{\beta}_3}{\|\boldsymbol{\beta}_3\|},$$ 完成由 $\alpha 到 \gamma$ 的施密特正交化。

基本步骤：设 ${w_0=v_0}$
对于 $1\leqslant i\leqslant-1$，令 $\displaystyle{w}_{i}={\nu}_{i}-\sum_{j=0}^{i-1}\mathrm{proj}_{{w}_{j}}\left({\nu}_{i}\right)$
规范化：令 $\displaystyle{w}_{i}={\frac{{w}_{i}}{\left\|\:{w}_{i}\right\|}}$

从直观上来说，在将给定集合内的向量添加到规范正交集中时，我们需要令减去它在现有规范正交集中其他向量 ${w_0, w_1,…, w_{i-1}}$ 方向上的分量（投影)，这样方可确保新加入规范正交集的向量与该集合中的其他向量互相正交。

优化：3D 数学基础 P156
![[Pasted image 20230409142339.png]]
### 通过叉积正交化

> [!NOTE] 通过叉积正交化
> 1. 令 $\displaystyle{w}_{0}=\frac{{\nu}_{0}}{\left\|{\nu}_{0}\right\|}$
> 
>2. 令 $\displaystyle w_{2}=\frac{{w}_{0}\times w_{1}}{\parallel{w}_{0}\times{w}_{1}\parallel}$
>
>3. 令 $w_1=w_2\times w_0$ 
>
由于 ${w}_{2}\perp w_{0}$，且 $||w_2||=||w_1||=1$，因此 $||w_2\times w_0||=1$ ，所以结果已经是规范化的。
此时 $\{w_0,w_1,w_2 \}$ 是规范正交的。

在上面的示例中，我们首先令 $\displaystyle{w}_{0}=\frac{{\nu}_{0}}{\left\|{\nu}_{0}\right\|}$，这意味着将向量 $v_0$ 转换到向量 $w_0$ 时并未改变方向，仅缩放了的长度。但是，向量 $w1$ 与向量 $w2$ 的方向却可以分别不同于 $v_1$ 和向量  $v_2$ 。**对于特定的应用来说，不改变集合中某个向量的方向也许是件很重要的事。**
例如，龙书中利用 3 个规范正交向量 $\{v_0, v_1, v_2\}$ 来表示摄像机（camera)的朝向，而其中的第三个向量 $v_2$ 描述的正是摄像机的观察方向。在对这些向量进行正交化处的过程中，我们通常并不希望改变此摄像机的观察方向。所以，我们会运用上面的算法，在第一步中处理向量 $v_2$，再通过修改向量 $v_0$ 和向量 $v_1$ 来使它们正交化。

例：
![[Pasted image 20230401211040.png|450]]
单位化时 $\beta$ 的分母不用带入


# 二、矩阵
## 转置矩阵
**转置矩阵**$A^T$：行列互换

$$\begin{array}{l}{(\boldsymbol{A}^{\top})^{\top}=\boldsymbol{A}}\\\\ {(\boldsymbol{A}+\boldsymbol{B})^{\top}=\boldsymbol{A}^{\top}+\boldsymbol{B}^{\top}}\\\\\begin{array}{l}\left(k\mathbf{A}\right)^{\text{T}}=k\mathbf{A}^{\text{T}}\\\\ \left(\mathbf{A}\mathbf{B}\right)^{\text{T}}=\mathbf{B}^{\text{T}}\mathbf{A}^{\text{T}}\\\\ (\mathbf{A}^{-1})^{\mathbf{T}}=(\mathbf{A}^{\mathbf{T}})^{-1}\end{array} \end{array}$$

## 逆矩阵
存在逆矩阵的矩阵叫**可逆矩阵**
不存在的叫**奇异矩阵**

**逆矩阵**$A^{-1}$：$AA^{-1}=E$


$$\begin{array}{l}(\mathbf{A}^{-1})^{-1}=\mathbf{A}\mathbf;\\\\(k\mathbf{A})^{-1}=\dfrac{1}{k}\mathbf{A}^{-1}\quad(k\neq0)\\\\ (\mathbf{A}\mathbf{B})^{-1}=\mathbf{B}^{-1}\mathbf{A}^{-1}\\\\(\mathbf{A}^{n})^{-1}=(\mathbf{A}^{-1})^n\\\\\left|\mathbf{A}^{-1}\right|=\dfrac{1}{\left|\mathbf{A}\right|}\\\\ \mathbf{A}^{-1}=\dfrac{1}{\left|\mathbf{A}\right|}{\mathbf A}^*\end{array}$$


N 阶矩阵可逆的充分必要条件：
- $|A|≠0$
- $r (A)=n$
- $A$ 的列（行）向量组线性无关
- $A$ 是初等矩阵
- $A$ 与单位矩阵等价
- $0$ 不是矩阵 $A$ 的特征值.

### 求逆矩阵
1. 初等行变换 $$

\left [
\begin{array}{c:c}
\begin{matrix}
A 
\end{matrix}&
\begin{matrix}
E 
\end{matrix}
\end{array}
\right ]\rightarrow
\left [
\begin{array}{c:c}
\begin{matrix}
E
\end{matrix}&
\begin{matrix}
A^{-1} 
\end{matrix}
\end{array}
\right ]
$$
2. 伴随矩阵法 $\displaystyle A^{-1}=\frac{A^*}{|A|}$（不适合 $4\times 4$ 以上的矩阵，浪费 CPU 资源）
3. 图形计算中最常使用通式，省资源。如 $2\times2$ 矩阵 $A=\begin{bmatrix}A_{11} & A_{12} \\ A_{21} & A_{22}\end{bmatrix}$ 的逆矩阵通式为 $$
A=\frac{1}{A_{11}A_{22}-A_{12}A_{21}}\left[\begin{matrix}{A_{22}}&{-A_{12}}\\ {-A_{21}}&{A_{11}}\\ \end{matrix}\right]\quad
$$
4. 分块：主对角线直接写相反数，副对角线交换位置写相反数
$$
\begin{bmatrix}\mathbf{A}&\mathbf{O}\\ \mathbf{O}&\mathbf{B}\end{bmatrix}^{-1}=\begin{bmatrix}\mathbf{A}^{-1}&\mathbf{O}\\ \mathbf{O}&\mathbf{B}^{-1}\end{bmatrix},\begin{bmatrix}\mathbf{O}&\mathbf{A}\\ \mathbf{B}&\mathbf{O}\end{bmatrix}^{-1}=\begin{bmatrix}\mathbf{0}&\mathbf{B}^{-1}\\ \mathbf{A}^{-1}&\mathbf{O}\end{bmatrix}
$$
## 伴随矩阵
**伴随矩阵**$A^*$：由行列式 $A$ 的每个元素 $a_{ij}$ 的代数余子式 $A_{ij}$ 构成
$$A^*=\begin{bmatrix}A_{11}&A_{21}&\cdots&A_{n1}\\ A_{12}&A_{22}&\cdots&A_{n2}\\ \vdots&\vdots&&\vdots\\ A_{1n}&A_{2n}&\cdots&A_{nn}\end{bmatrix}$$
 对于 2 阶矩阵，用主对角线元素对换，副对角线元素变号即可求出伴随矩阵
$$
\begin{array}{l}{{\mathbf{AA}^{*}=\mathbf{A}^{*}\mathbf{A}=\big|\mathbf{A}\big|\mathbf{E}}}\\ \\{{\mathbf{A}^{*}=\big|\mathbf{A}\big|\mathbf{A}^{-1}}}\\\\
\big|\mathbf{A}^{*}\big|=\big|\mathbf{A}\big|^{n-1}\\\\ 
\mathbf{(A}^{*}\big)^{-1}=(\mathbf{A}^{-1}\big)^{*}=\frac{1}{\big|\mathbf{A}\big|}\mathbf{A}\\\\
\mathbf{(A}^{*}\big)^{T}=(\mathbf{A}^{T}\big)^{*}\\\\(k\mathbf{A}\big)^{*}=k^{n-1}\mathbf{A}^{*}\\\\(\mathbf{A}^{*}\big)^{*}=\big|\mathbf{A}\big|^{n-2}\mathbf{A}\\ \end{array}
$$
$$
r(A^*)=\begin{cases}
n,&如果r(A)=n \\\\
1,&如果r(A)=n-1 \\\\
0,&如果r(A)<n-1 
\end{cases}
$$
## 正交矩阵
对正交矩阵的几何解释：3D 数学基础 P155

**正交矩阵**：矩阵 $A$ 满足 $\mathbf{A}\mathbf{A}^{\mathsf{T}}=\mathbf{A}^{\mathsf{T}}\mathbf{A}=\mathbf{E}.$
$A$ 是正交矩阵 $\Leftrightarrow$ $A^T=A^{-1}$.
$A$ 是正交矩阵 $\Rightarrow$ $|A|^2=1$.

要使矩阵正交，必须满足：
- 矩阵的每一列都为单位矢量
- 矩阵的列必须相互垂直

> [!NOTE] 注意
> 这里需要进行一项很重要的专业说明，因为它可能会让人有点困惑。
> - 在线性代数中，如果一组基向量量相互垂直，则将它们描述为**正交** (Orthogonal )。它们不需要具有单位长度。
> - 如果它们确实具有单位长度，则它们是**标准正交基** (Orthonormal Basis )。
> 
> 因此，**正交矩阵 (Orthogonal Matrix)的行和列是标准正交基矢量 (Orthonormal Basis Vector )** 。然而，**从一组正交基矢量构造矩阵不一定导致正交矩阵（除非基矢量也是标准正交基)。**
>


## 秩
矩阵 A 的非零子式的最高阶数称为矩阵的秩 $r(A)$
$r(\mathbf{A})=r(\mathbf{A}^{\mathrm{T}})r;(\mathbf{A}^{\mathrm{T}}\mathbf{A})=r(\mathbf{A});$

$\begin{array}{l}r(\mathbf{A}+\mathbf{B})\leqslant r(\mathbf{A})+r(\mathbf{B});\\ \\r(\mathbf{A}\mathbf{B})\leqslant\min(r(\mathbf{A}),r(\mathbf{B}));\end{array}$

## 矩阵的初等变换
对 $m×n$ 矩阵，下列三种变换
(1)用非零常数 k 乘矩阵的某一行（列）
(2)互换矩阵某两行（列）的位置；
(3)把某行（列）的 k 倍加至另一行（列）

**初等矩阵：单位矩阵**经过**一次初等变换**所得的矩阵
用初等矩阵左（右）乘矩阵 $A$，其结果 $PA(AP)$ 就是对矩阵 $A$ 做一次相应的处等行（列）变换。

**等价：** $A$ 矩阵经过有限次初等变换 $B$，则称矩阵 $A$ 与矩阵 $B$ 等价，记为 $A \cong B$
$A \cong B\Leftrightarrow \text{存在可逆矩阵P与Q，使得PAQ=B}$


# 三、行列式
## 概念
**本质：** [[《线性代数的本质》#05 - 行列式]]
**定义：** n 阶行列式 $D=\left|\begin{array}{ccccc}a_{11}&a_{12}&\cdots&a_{1n}\\ a_{21}&a_{22}&\cdots&a_{2n}\\ \vdots&\vdots&&\vdots\\ a_{n1}&a_{n2}&\cdots&a_{nn}\end{array}\right|$（后文统一称为 D）是所有取自**不同行不同列**的 n 个元素的乘积 $a_{1j_1}a_{2j_2}\cdots a_{nj_n}\quad\quad$ 的代数和。  
$$\begin{vmatrix}a_{11}&a_{12}&\cdots&a_{1n}\\ a_{21}&a_{22}&\cdots&a_{2n}\\ \vdots&\vdots&&\vdots\\ a_{n1}&a_{n2}&\cdots&a_{nn}\\ \end{vmatrix}=\sum_{j_1j_{2\cdots}j_n}(-1)^{\tau\left(j_{1}j_{2}\cdots j_{n}\right)}a_{1_{j_1}}a_{2_{j_2}}\cdots a_{n_{j_n}}$$

> [!note] 逆序数
> 一个排列中，如果一个大的数排在小的数之前，就称这两个数构成一个逆序。一个排列的逆序总数称为这个排列的逆序数。用 $\tau\left(j_{1}j_{2}\cdots j_{n}\right)$ 表示逆序数。
> 例如，$a_{14}a_{23}a_{31}a_{42}$ 对应的逆序数 $\tau\left(4312\right)=3+2+0=5$


> [!NOTE] 余子式\代数余子式
> $n$ 阶行列式 $D$ 划去元素 $a_{ij}$ 所在的第 $i$ 行、第 $j$ 列，由剩下的元素按原来的排法构成一个 $n-1$ 阶的行列式，称为 $a_{ij}$ 的**余子式**，记为 $M_{ij}$
>
$(-1)^{i+j}M_{ij}$ 为 $a_{ij}$ 的**代数余子式**，记为 $A_{ij}$

1. $D$ 等于它的任意一行（或列）的所有元素与它们各自对应的代数余子式的乘积之和：
$$D=a_{k1}A_{k1}+a_{k2}A_{k2}+\cdots+a_{kn}A_{kn}\quad(k=1,2,\cdots,n).$$
2. 元素 $a_{ij}$ 的代数余子式为 $A_{ij}$,当 $i≠k(i,k=1,2,…,n)$ 时，有
$a_{i1}A_{k1}+a_{i2}A_{k2}+\cdots+a_{in}A_{kn}=0;$

当 $j≠k(j,k=1,2,…,n)$ 时，有
$a_{1j}A_{1k}+a_{2j}A_{2k}+\cdots+a_{nj}A_{nk}=0.$
## 性质
![[Pasted image 20230401162350.png]]
## 行列式变换
经转置行列式的值不变，即 $|A^T|=A$
某行（列）有公因数 k, 可把 k 提到行列式外。特别地，某行元素全为 0，则行列式的值为 0
两行（列）互换行列式变号。特别地，两行相等，行列式值为 0；两行成比例，行列式值为 0
某行（列）所有元素都是两个数的和，则可写成两个行列式之和
某行（列）的 k 倍加至另一行，行列式的值不变
## 克拉默法则
1. 若 n 个方程 n 个未知数的**线性方程组**
$$\begin{cases}
a_{11}x_1+a_{12}x_2+\cdots+a_{1n}x_n=b_1,\\ a_{21}x_1+a_{21}x_2+\cdots+a_{2n}x_n=b_2,\\ \vdots\\ a_{n1}x_1+a_{n0}x_2+\cdots+a_{nn}x_n=b_n
\end{cases}$$
的系数行列式
$$D=\begin{vmatrix}a_{11}&a_{12}&\cdots&a_{1n}\\ a_{21}&a_{22}&\cdots&a_{2n}\\ \vdots&\vdots&&\vdots\\ a_{n1}&a_{n2}&\cdots&a_{nn}\end{vmatrix}\neq0,$$
则方程组有唯一解（$D_1$ 即将 $D$ 第一列换成 0，其他列不变，计算得出的行列式值）
$$x_1=\dfrac{D_1}{D},x_2=\dfrac{D_2}{D},\cdots,x_n=\dfrac{D_n}{D},\quad\text{}$$

2. **齐次线性方程组**
$$\begin{cases}
a_{11}x_1+a_{12}x_2+\cdots+a_{1n}x_n=0,\\ a_{21}x_1+a_{21}x_2+\cdots+a_{2n}x_n=0,\\ \vdots\\ a_{n1}x_1+a_{n0}x_2+\cdots+a_{nn}x_n=0
\end{cases}$$
系数行列式 $|A|\neq0$，方程组只有零解
有非零解，则 $|A| =0$

# 四、线性方程组
## 线性方程组的初等变换
(1) 用一个非零常数乘方程的两边；
(2) 把某方程的 k 倍加到另一方程上；
(3) 互换两个方程的位置；
线性方程组的初等行变换把线性方程组编程与它**同解**的线性方程组。

同解：两个方程组有相同的解集合，它们互为同解方程组
公共解：如果 $\alpha$ 既是方程组 A 又是方程组 B 的解，则称 $\alpha$ 为 A、B 的公共解

## 解的判定
**非齐次线性方程组 $Ax=b$ 有解的充分必要条件是其系数矩阵和增广矩阵的秩相等**，即 $\displaystyle r(A)=r(A|b)$
若 $r (A)=r (A|b)=n$, 则方程组有唯一解；
若 $r (A)=r (A|b)<n$, 则方程组有无穷多解.
若 $r (A)=r (A|b)>n$, 则方程组无解.
非齐次线性方程组 $Ax=b$ 无解 $\Leftrightarrow r (A)+ 1=r(A|b)$

## 求基础解系
将**系数矩阵**先化**行最简**

$$
\begin{bmatrix}
1 & \color{red}2 & 0 & \color{red}-5 \\
0 & \color{red}0 & 1 & \color{red}3  \\
0 & \color{red}0 & 0 & \color{red}0
\end{bmatrix}
$$
$$n-r(A)=4-2=2,说明有两个基础解系$$
红色列为自由变量，对应行写 0，1
黑色列为主变量，对应行写红色列得相反数

得基础解系：
$$
\eta_1=\begin{bmatrix}
-2 \\ \color{red}1 \\ 0 \\ \color{red}0
\end{bmatrix},
\eta_2=\begin{bmatrix}
5 \\ \color{red}0 \\ -3 \\ \color{red}1
\end{bmatrix}
$$

## 求通解
**增广矩阵**先化**行最简**

$$
A\rightarrow
\left [
\begin{array}{c:c}
\begin{matrix}
1 & 1 & -1 & 1 \\ 
0 & 2 & 1 & -6 \\ 
0 & 0 & 0 & 0 
\end{matrix}&
\begin{matrix}
-2 \\ 
3  \\ 
0
\end{matrix}
\end{array}
\right ]\rightarrow
\left [
\begin{array}{c:c}
\begin{matrix}
1 & 0 & \color{red}-\frac{3}{2} & \color{red}4 \\ 
0 & 1 & \color{red}\frac{1}{2} & \color{red}-3 \\ 
0 & 0 & \color{red}0 & \color{red}0 
\end{matrix}&
\begin{matrix}
\color{blue}-\frac{7}{2} \\ 
\color{blue}\frac{2}{3}  \\ 
0
\end{matrix}
\end{array}
\right ]
$$
$$n-r(A)=4-2=2$$

红色列为自由变量，对应行写 0，1
黑色列为主变量，对应行写红色列得相反数
蓝色特解部分直接抄写，并补 0

得通解为：

$$
x=
\begin{bmatrix}
-{\frac{7}{2}} \\ \frac{3}{2} \\ \color{red}0 \\ \color{red}0 \\ 
\end{bmatrix}+
k_1{\begin{bmatrix} \frac{3}{2} \\ -{\frac{1}{2}} \\ \color{red}1 \\ \color{red}0\end{bmatrix}}+
k_2\begin{bmatrix}-4  \\  3  \\  \color{red}0  \\  \color{red}1\end{bmatrix}\qquad(k_1,k_{2}为任意常数)
$$
# 五、特征值与特征向量

设  $A$  是 $n$ 阶矩阵，如果存在一个数 $\lambda$ 及非零的 $n$ 维列向量 $\alpha$，使得 $A \alpha=\lambda \alpha$ 成立，则称 $\lambda$ 是矩阵 $A$ 的一个**特征值**，称非零向量 $\alpha$ 是矩阵  $A$  属于特征值 $\lambda$ 的一个**特征向量**。
## 求特征值和特征向量
已知矩阵 $A$
（1）由 $A$ 的特征多项式 $|\lambda E-A|$ =0 的特征值分别为 $\lambda_1,\lambda_2\cdots\lambda_n$
（2）当 $\lambda=1$ 时，由 $（E-A）x=0$ 得基础解系 $\alpha_1$
以此类推，求出所有基础解系 $\alpha_1,\alpha_2\cdots\alpha_n$
（3）求得矩阵 A 关于特征值 $\lambda_1,\lambda_{2\cdots}\lambda_n$ 的特征向量分别为 $k_1\alpha_1,k_2\alpha_2\cdots k_n\alpha_n(其中k_1,k_2,k_n均为非零常数)$
## 相似 

设 $A$ 和 $B$ 都是 $n$ 阶矩阵，如果存在可逆矩阵 $P$ 使得 $P^-1AP=B$，则称矩阵 $A$ 和 $B$ 相似，记作 $A \sim B$.
特别地，如果 A 能与对角矩阵相似，则称 A 可对角化。

如果 $A \sim B$，则
$\left|A\right|=\left|B\right|;r\left(A\right)=r\left(B\right);\lambda_{A}=\lambda_{B};\sum a_{i}=\sum b_{i}.$

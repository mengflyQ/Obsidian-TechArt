[undefined](https://zhuanlan.zhihu.com/p/191487550)[undefined](https://zhuanlan.zhihu.com/p/151301323)

## **概率论背景**

**(1) 数学期望**

设 $X$ 是随机变量, $Y$ 是 $X$ 的函数, $Y = g(X)$ .

A. 如果 $X$ 是离散型随机变量, 其分布列为 $p_i = P\{ X= x_i \}(i=1,2,3\cdots)$ .

随机变量 $X$ 的**数学期望**定义为 $EX=\sum_{i =1}^{\infty}{x_ip_i}$ .

$Y = g(X)$ 的数学期望定义为 $E[g(X)] = \sum_{i =1}^{\infty}{g(x_i)p_i}$ .

B. 如果 $X$ 是连续性随机变量, 其概率密度为 $f(x)$ .

随机变量 $X$ 的**数学期望**定义为 $EX=\int_{-\infty}^{+\infty}xf(x)dx$ .

$Y = g(X)$ 的数学期望定义为 $E[g(X)] =\int_{-\infty}^{+\infty}g(x)f(x)dx$ .

**(2) 方差标准差**

设 $X$ 是随机变量, $X$ 的方差 $DX$ 定义为 $DX = E[(X-EX)^2] = E(X^2) - (EX)^2$ .

$\sqrt{DX}$ 称为 $X$ 的标准差.

## 黎曼和

在开始讲蒙特卡洛估计之前, 我们先来回顾下黎曼和, 这样可以和下面对比, 加深印象.

设我们现在想求解积分 $\int_{a}^{b} g(x) dx$ , 我们将 $(a, b)$ 划分成 N 等份, 这样每一份的长度为 $\Delta x = \frac{b - a}{N}$ . 在每一小份中我们可以任取一个位置的值代表这一小份上 $g(x)$ 的平均值, 我们这里取每小份上左边的值 (也可以取右边或者中间), 这样这个积分的**黎曼和**为

$$S = \Delta x[g(a) + g(a + \Delta x ) + g(a + 2\Delta x) + \dots + g(b - \Delta x)] $$

当 $N\rightarrow +\infty$ , 黎曼和就趋近于定积分的值, 这也是定积分的一种定义方法.

黎曼和是一种简单有效的估计积分值的方法.

## 蒙特卡洛估计

**蒙特卡洛估计 (Monte Carlo Estimator)** 的原理很简单, 假设现在我们要求解一个一维的积分 $\int_{a}^{b} g(x) dx$. 已知一个概率密度为 $f(x)$ 的随机变量 $X$ , 蒙特卡洛估计可以表示为:

$$G_N = \frac{1}{N}\sum_{i=1}^{N}{\frac{g(X_i)}{f(X_i)}}$$

概率密度 $f(x)$ 需要满足  

$$\begin{cases} f(x) > 0, x \in (a, b),\\ f(x) = 0, x \notin (a, b).\end{cases}$$

现在来验证下, 这种方式是正确的:

$$\begin{align*} E[G_N] & =E\left [ \frac{1}{N}\sum_{i=1}^{N}{\frac{g(X_i)}{f(X_i)}} \right]\\ & = \frac{1}{N}\sum_{i=1}^{N}\int_{a}^{b}\frac{g(x)}{f(x)}f(x)dx\\ &= \frac{1}{N}\sum_{i=1}^{N}\int_{a}^{b}g(x)dx\\ &= \int_{a}^{b}g(x)dx \end{align*}$$

  
这种积分同样可以任意扩展到多维度的情况.

蒙特卡洛估计的采样次数 $N$ 是可以任意确定的, 这是蒙特卡洛估计相对其他估计方式的一个重要的优点.

计算结果表明, 蒙特卡洛估计误差收敛的速度为 $O(\sqrt N)$ (意味着 4 倍的采样会使误差减少一半). 虽然在一维情况下不如其他的近似方法, 但由于蒙特卡洛估计不受维度影响, 在高维情况下比其他估计方法收敛要快得多.

## 重要性采样

现在我们有了蒙特卡洛估计方法, 下一步就是确定随机变量 $X$ 的概率密度函数 $f(x)$ .

一种简单的方式是直接直接使 $X$ 在 $(a,b)$ 上均匀分布, $f(x)$ 为某个常数.

更好的方法使用**重要性采样 (importance sampling)**, 即使概率密度 $f(x)$ 和需要积分的函数 $g(x)$ 尽量接近.

重要性采样本身很好理解, 就是得到值更大的部分, 对结果影响也更大, 自然需要更多的采样. 这样我们把有限的采样次数合理地分配在每个区间上.

值得注意的是, 一个不好的概率密度函数反而会使得结果的误差增大.

有的时候, 需要积分的方程中可能包含多个需要积分的部分, 这时候就需要用到**多重重要性采样 (multiple importance sampling/MIS)**.

比如现在要求解 $\int_{}^{} g_1(x)g_2(x)$ 这样的积分时, 两个部分分别对应两个概率密度 $f_1(x), f_2(x)$ , MIS 给出的新的蒙特卡洛估计为:

$$\frac{1}{n_1} \sum_{i=1}^{n_1}{\frac{g_1(X_1)g_2(X_1)\omega_1(X_1)}{f(X_1)}} + \frac{1}{n_2} \sum_{i=1}^{n_2}{\frac{g_1(X_2)g_2(X_2)\omega_2(X_2)}{f(X_2)}}$$

$n_1,n_2$ 分别是两边的采样次数, $\omega_1, \omega_2$ 分别是两个部分对应的权重.

一个常用的权重函数为:

$$\omega_k = \frac{(n_kf_k(x))^2} {\sum_{i}^{}{(n_1f_i(x))^2}}$$

在上面有两个部分的情况下得:

$\omega_1 = \frac{(n_1f_1(x))^2} {(n_1f_1(x))^2 +(n_2f_2(x))^2 }\\ \omega_2 = \frac{(n_2f_2(x))^2} {(n_1f_1(x))^2 +(n_2f_2(x))^2 }$

## 分层采样

有了上面得部分, 我们已经得到得完整的蒙特卡洛估计的步骤, 可以开始进行求解问题了.

比如现在要采样 10 次, 就取 $N = 10$ , 然后随机 10 次, 计算累加结果就可以了.

这时我们又遇到了一个问题, 那就是这样独立地随机, 产生的随机结果是不均匀的, 会使结果的误差增大.

一个好的随机过程是取一系列的**采样序列**, 采样序列是一个复杂深奥的话题, 我们这里仅仅介绍下最简单的**分层采样 (Stratified Sampling)**. 想要进一步了解各种低差异采样序列的朋友可以参考本系列文章的下一篇 [[三) 低差异采样序列](https://zhuanlan.zhihu.com/p/343666731|TC130：看懂蒙特卡洛积分 (三) 低差异采样序列]]。

分层采样的原理就是采样的样本空间均匀分成 n 等份, 在每份中取一个采样点. 为了减少采样结果的走样, 在每份中采样时加上一点抖动. 下图是一个简单的示例, 可以看出, 分层采样的结果更加均匀.

![[5e2f18723bed1610ba7ebe6d3efdf64a_MD5.png]]

## 实践: IBL 漫反射贴图

游戏中常用一个 cubemap 来表示环境光照, 在求解物体表面的环境光漫反射时, 通常会将漫反射贴图预积分计算出来.

漫反射的方程为:

$$L_o = \int_{\Omega}^{} \frac{\bm c_{diff}}{\pi} L_i cos\theta_i d\omega_i,$$

左边的部分是不会变化的, 提出来得到:

$$L_o = \frac{\bm c_{diff}}{\pi} \int_{\Omega}^{} L_i cos\theta_i d\omega_i$$

这样我们就可以把 $\frac{1}{\pi} \int_{\Omega}^{} L_i cos\theta_i d\omega$ 部分提前计算出来, 在实时渲染中就不需要再求积分. 这个过程也叫做求 irradiance map.

现在我们尝试用两种方式来求解:

**A. 黎曼和**

 

$$\frac{1}{\pi} \int_{\Omega}^{} L_i cos\theta_i d\omega_i = \frac{1}{\pi} \int_{0}^{2\pi}\int_{0}^{\pi/2} L_i \cos \theta_i \sin \theta_i d\theta d\phi$$

将 $\theta, \phi$ 分别划分成 $n_1, n_2$ 份, 得:

 

$$\frac{1}{\pi} \int_{\Omega}^{} L_i cos\theta_i d\omega_i = \frac{\pi}{n_1n_2} \sum_{\theta=0}^{n_1}{}\sum_{\phi=0}^{n_2}{L_i \cos \theta \sin \theta d\phi d\theta}$$

其实这里也可以看成是蒙特卡洛估计:

$f(\theta, \phi) = \frac{1}{\pi ^2 }\\ f(\omega) = \frac{1}{\pi ^2 \sin \theta }\\ L_o = \frac{1}{n_1n_2 \pi} \sum_{\theta=0}^{n_1}{}\sum_{\phi=0}^{n_2}{\frac{L_i \cos \theta }{f(\omega)} d\phi d\theta} \\= \frac{\pi}{n_1n_2} \sum_{\theta=0}^{n_1}{}\sum_{\phi=0}^{n_2}{L_i \cos \theta \sin \theta d\phi d\theta}$

**B. 蒙特卡洛估计**

我们这里按照余弦权重来采样, 使用分层采样分别将 $\xi_1, \xi_2$ 取 $n_1, n_2$ 次, 得到随机在单位圆上的点

$$(r' = \sqrt{\xi_1}, \theta' = 2\pi \xi_2)$$

 由 Malley 方法映射到单位半球面上, 得到

$$(x =r' \cos \theta', y = r' \sin \theta', z = \sqrt{1 - r'^2})$$

已知 $f(\omega) = \frac{\cos \theta}{\pi}$ , 蒙特卡洛估计为:

 $\frac{1}{\pi} \int_{\Omega}^{} L_i cos\theta_i d\omega_i = \frac{1}{n_1n_2\pi} \sum_{\xi_1}^{n_1}{}\sum_{\xi_2}^{n_2}{\frac{L_i \cos \theta_i}{f(\omega)}} =\frac{1}{n_1n_2} \sum_{\xi_1}^{n_1}{}\sum_{\xi_2}^{n_2}{L_i }$

下图是两种方式得到的结果，可以看出，相同采样次数下，蒙特卡洛估计的结果，要好于黎曼和估计。实现的代码，我放在这里 [GitHub - raphael10241024/monte_carlo_demo](https://github.com/raphael10241024/monte_carlo_demo)。。

![[120c262df8c2870aa3c2b8ddacc229ec_MD5.png]]

![[1319e2e887b1c44349a7c6e79f3625f8_MD5.png]]
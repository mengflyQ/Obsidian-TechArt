# 摘要

3DGS 最近彻底改变了辐射场重建，实现了高质量的新视角合成和快速渲染。然而，由于3D高斯的多视角不一致性（multi-view inconsistent），3D高斯无法准确地表示曲面。我们提出了 2DGS，这是一种从多视角图像中建模和重建几何精确辐射场的新方法。**我们的主要想法是将 3D volume 折叠成一组 2D 定向平面高斯盘 (2D oriented planar Gaussian disks)。**  

与 3D 高斯不同，2D 高斯在对曲面进行建模的同时，还提供了与视图一致（ view-consistent）的几何形状。  

为了精确恢复**薄曲面**并实现稳定的优化，我们引入了一种透视精确的 2D“泼溅”流程，利用 ray-splat 相交和光栅化技术。此外，我们还加入了深度失真（depth distortion）和法线一致性项，以进一步提高重建质量。  

我们证明，我们的可微分渲染器可以实现无噪声和详细的几何重建，同时保持有竞争力的外观质量、快速训练速度和实时渲染。我们的代码将公开发布。

关键词：novel view synthesis, radiance fields, surface splatting, surface reconstruction  

![[Pasted image 20240415143029.png]]

>图 1. 我们的方法 2DGS 
 - （a）优化了一组 2D 定向 disk ，以便从多视角 RGB 图像中表示和重建复杂的现实世界场景。这些优化后的 2D disk 与曲面紧密对齐。
 - （b）利用 2DGS 技术，我们可以实时渲染高质量的新视角图像，这些图像具有与视图一致的法线和深度图。视图一致的法线和深度图。
 - （c）最后，我们的方法可根据优化后的 2D disk 重建详细且无噪声的三角形 Mesh。


# 1 引言
逼真的新视角合成（NVS）和精确的几何重建是计算机图形学和视觉领域至关重要的长期目标。最近，3DGS 因其在高分辨率下的实时逼真 NVS 结果，成为 NVS 中隐式（Mildenhall 等人，2020 年；Barron 等人，2022 年 a）和基于特征网格的表示（Barron 等人，2023 年；Müller 等人，2022 年）的极具吸引力的替代方案。3DGS 发展迅速，已迅速扩展到多个领域，包括抗锯齿渲染（Yu 等，2024 年）、材料建模（Shi 等，2023 年；Jiang 等，2023 年）、动态场景重建（Yan 等，2023 年）和动画化身（animatable avatar）创建（Zielonka 等，2023 年；Qian 等，2023 年）。然而，它在捕捉复杂的几何图形方面仍有不足，因为体积3D高斯模拟的是完整的角辐射（angular radiance），与曲面的薄（thin）特性相冲突。

另一方面，早期的研究（Pfister 等人，2000 年；Zwicker 等人，2001a）表明，surfels（surface elements）可以有效地表示复杂的几何图形。surfels 通过形状和阴影属性对物体曲面进行局部近似，并可从已知几何图形中推导出来。作为一种高效的几何表示法，它们被广泛应用于 SLAM（Whelan 等人，2016 年）和其他机器人任务（Schöps 等人，2019 年）中。随后的进展（Yifan 等人，2019 年）将 surfels 纳入了可微分框架。不过，这些方法通常需要 GroundTrue 几何图形、深度传感器数据，或在已知照明的受限场景下运行。

**受这些著作的启发，我们提出了用于3D场景重建的 2DGS 技术和新颖的视角合成技术，它结合了这两个领域的优点，同时克服了它们的局限性。**

与 3DGS 不同，我们的方法是用 2D 高斯表示3D场景，每个基元定义一个定向椭圆盘。与 3D 高斯相比，2DGS 的显著优势在于渲染过程中的精确几何表示。**具体来说，3DGS 在 pixel ray 与 3D 高斯的交点处评估高斯值（Keselman 和 Hebert，2022，2023），这导致从不同视角渲染时深度不一致**。**相比之下，我们的方法利用明确的 ray-splat 交点，实现了透视精确泼溅**，如图 2 所示，从而显著提高了重建质量。**此外，2D 高斯中固有的曲面法线可以通过法线约束直接进行曲面正则化。与基于曲面的模型（Pfister 等人，2000 年；Zwicker 等人，2001 年 a；Yifan 等人，2019 年）相比，我们的 2D 高斯模型可以通过基于梯度的优化从未知几何体中恢复。**

![[Pasted image 20240415143040.png]]
>图 2：3DGS 与 2DGS 的比较。当从不同视角观察时，3DGS 利用不同的相交平面进行值评估，从而导致不一致。而我们的 2DGS 可提供多视角一致的数值评估。

虽然我们的 2D 高斯方法在几何建模方面表现出色，但**由于3D重建任务本身不受约束的性质，仅利用光度损失（photometric loss）进行优化可能会导致噪声**，正如（Barron 等，2022b；Zhang 等，2020；Yu 等，2022b）所指出的那样。**为了增强重建效果并获得更平滑的曲面，我们引入了两个==正则化项==：深度失真和法线一致性。**
- 深度变形项将 2D 高斯集中在沿光线分布的狭小范围内，解决了渲染过程中忽略高斯之间距离的限制。
- 法线一致性项使渲染的法线贴图与渲染的深度梯度之间的差异最小化，从而确保深度和法线定义的几何图形保持一致。将这些正则化与 2D 高斯模型相结合，我们就能提取出高度精确的曲面网格，如图 1 所示。

我们做出了以下贡献：
- 我们提出了一种高效的可微分2D高斯渲染器，通过利用2D曲面建模、ray-splat 相交和体积积分（ volumetric integration），实现透视精确的泼溅
- 我们引入了两种正则化损失，以改进无噪声曲面重建。
- 与其他显式表示法相比，我们的方法实现了最先进的几何重建和 NVS 结果。

# 2 相关工作
## 2.1. 新视角合成
NVS 取得了长足的进步，尤其是在引入 NeRF 之后。NeRF 采用 MLP 来表示几何图形和视图相关外观，并通过体积渲染进行优化，以提供卓越的渲染质量。NeRF 之后的发展进一步增强了其功能。例如，Mip-NeRF（Barron 等人，2021 年）和后续作品（Barron 等人，2022a, 2023 年；Hu 等人，2023 年）解决了 NeRF 的混叠问题。此外，通过蒸馏（Reiser 等人，2021 年；Yu 等人，2021 年）和烘焙（Reiser 等人，2023 年；Hedman 等人，2021 年；Yariv 等人，2023 年；Chen 等人，2023a 年）等技术，NeRF 的渲染效率也得到了大幅提高。此外，基于特征网格的场景表征也增强了 NeRF 的训练和表征能力（Chen 等，2022；Müller 等，2022；Liu 等，2020；Sun 等，2022a；Chen 等，2023c；Fridovich-Keil 等，2022）。

最近，出现了 3DGS，展示了令人印象深刻的实时 NVS 结果。这种方法已被迅速扩展到多个领域（Yu 等人，2024 年；Yan 等人，2023 年；Zielonka 等人，2023 年；Xie 等人，2023 年）。在这项工作中，我们建议将3D高斯 "扁平化 "为2D高斯，使其形状与物体曲面更加一致。

结合两种新颖的正则化损失，我们的方法比 3DGS 更精确地重建了曲面，同时保持了高质量和实时渲染能力。

## 2.3D 重建

从多视角图像进行3D重建一直是计算机视觉领域的一个长期目标。基于 MVS 的方法（Schönberger 等人，2016 年；Yao 等人，2018 年；Yu 和 Gao，2020 年）依赖于涉及特征匹配、深度预测和融合的模块化管线。

相比之下，最近的神经方法（Niemeyer 等人，2020 年；Yariv 等人，2020 年）通过 MLP 表示隐式曲面（Park 等人，2019 年；Mescheder 等人，2019 年），通过 Marching Cube 算法提取训练后的曲面。进一步的进展（Oechsle 等人，2021 年；Wang 等人，2021 年；Yariv 等人，2021 年）将隐式曲面与体积渲染相结合，从 RGB 图像中实现了详细的曲面重建。这些方法已通过额外的正则化（Yu 等，2022b；Li 等，2023；Yu 等，2022a）和高效的物体重建（Wang 等，2023）扩展到大规模重建。尽管取得了这些令人瞩目的进展，但高效的大规模场景重建仍是一项挑战。例如，Neuralangelo（Li 等人，2023 年）从坦克和寺庙数据集（Knapitsch 等人，2017 年）中重建一个场景需要 128 个 GPU 小时。

在这项工作中，我们引入了 2DGS，这是一种能显著加快重建过程的方法。与之前的隐式神经曲面表示法相比，它能获得相似或略微更好的结果，同时速度快了一个数量级。

## 2.3 基于点的可微图形
 
Differentiable Point-based Graphics（Insafutdinov 和 Dosovitskiy，2018 年；Yifan 等人，2019 年；Aliev 等人，2020 年；Wiles 等人，2020 年；Rückert 等人，2022 年）因其在表现复杂结构方面的高效性和灵活性而被广泛探索。值得注意的是，NPBG（Aliev 等，2020 年）将点云特征光栅化到图像平面上，然后利用卷积神经网络进行 RGB 图像预测。DSS（Yifan 等人，2019 年）侧重于在已知照明条件下优化多视角图像中的定向点云。Pulsar（Lassner 和 Zollhofer，2021 年）引入了基于 tile 的加速结构，以实现更高效的光栅化。最近，3DGS（Kerbl 等人，2023 年）优化了各向异性3D高斯基元，展示了实时逼真的 NVS 结果。尽管取得了这些进展，但从无约束多视角图像中使用基于点的表示法仍然具有挑战性。
 
本文中，我们展示了使用2D高斯基元进行的详细曲面重建。我们还强调了额外正则化损失在优化中的关键作用，展示了它们对重建质量的重大影响。

## 2.4 同时进行的工作

自 3DGS（Kerbl 等人，2023 年）问世以来，它已在多个领域得到迅速应用。我们现在回顾一下在逆渲染方面最接近的工作。这些工作（Liang 等人，2023 年；Gao 等人，2023 年；Jiang 等人，2023 年；Shi 等人，2023 年）通过将法线建模为 3D 高斯的附加属性，对 3DGS 进行了扩展。**相比之下，我们的方法通过使用 2D 高斯表示 3D 曲面的切线空间来定义法线，使它们与底层几何更紧密地对齐。** 此外，**上述工作主要侧重于估计场景的材质属性，并评估其在重新照明（relighting）任务中的结果。值得注意的是，这些工作都没有专门针对曲面重建，而这正是我们工作的主要重点。**


我们还强调了**我们的方法与同时进行的 SuGaR（Guédon 和 Lepetit，2023 年）和 NeuSG（Chen 等，2023 年 b）之间的区别**。
- 与用 3D 高斯逼近 2D 高斯的 SuGaR 不同，我们的方法直接采用 2D 高斯，简化了过程并增强了几何结果，无需额外的网格细化。
- NeuSG 联合优化了 3D 高斯和隐式 SDF 网络，并从 SDF 网络中提取曲面，而我们的方法则利用 2D 高斯基元进行曲面逼近，提供了一种速度更快、概念更简单的解决方案。

## 3 3DGS
定义略

**使用 3DGS 曲面重建的挑战**：
1. 3D高斯的体积辐射表示与曲面的薄特性相冲突。
2. 3DGS 没有对高质量曲面重建所必需的曲面法线进行原生（natively）建模。
3. 3DGS 的光栅化过程缺乏多视角一致性，导致不同视角的 2D 相交平面各不相同（Keselman 和 Hebert，2023 年），如图 2 (a) 所示。此外，使用仿射矩阵将3D高斯转换为 ray space 只能获得中心附近的精确投影，而周围区域的透视精度则会大打折扣（Zwicker 等人，2004 年）。因此，如图 5 所示，这种方法往往会产生噪声。

![[Pasted image 20240415143055.png]]
>图 5. DTU 基准的定性比较（Jensen 等人，2014 年）。我们的 2DGS 可生成细致且无噪声的曲面。

# 4 2DGS
为了在保持高质量新视角合成的同时准确重建几何图形，我们提出了可微 2DGS。

## 4.1 建模

3DGS （Kerbl 等人，2023 年）将整个角辐射（angular radiance）建模为一个椭球，与之不同的是，我们采用嵌入 3D 空间的扁平 2D 高斯来简化 3D 建模。在 2D 高斯建模中，2D 高斯将密度分布在一个平面 disk 中，将法线定义为密度变化最陡峭的方向。

这一特点可以更好地对准薄曲面。虽然以前的方法（Kopanas 等人，2021 年；Yifan 等人，2019 年）也利用 2D 高斯进行几何重建，但它们需要密集的点云或 GT 法线作为输入。相比之下，我们只需要稀疏的校准点云和光度（photometric）监督，就能同时重建外观和几何。

![[Pasted image 20240415151323.png]]
>图 3：2DGS图解。2D 高斯是一种椭圆形盘，其特征是中心点 $\mathbf{p}_k$ 、切向量 $\mathbf{t}_u$ 和 $\mathbf{t}_v$ 以及两个控制方差的缩放因子（ $s_u$ 和 $s_v$ ）。它们的椭圆投影通过射线-花盘交点（第 4.2 节）进行采样，并在图像空间中通过 alpha 混合进行累积。2DGS 通过梯度下降重建颜色、深度和法线等曲面属性。

如图 3 所示，我们的 2D 高斯的特征在于其中心点 $\mathbf{p}_k$ 、两个切线向量 $\mathbf{t}_u$ 和 $\mathbf{t}_v$ 以及一个控制 2D 高斯方差的缩放向量 $\mathbf{S}=(s_{u},s_{v})$。请注意，原始法线是由两个正交切向量的叉乘 $\mathbf{t}_{w}=\mathbf{t}_{u}\times\mathbf{t}_{v}$ 定义的。我们可以将方向排列成一个 3×3 旋转矩阵 $\mathbf{R}=[\mathbf{t}_{u},\mathbf{t}_{v},\mathbf{t}_{w}]$ ，将缩放因子排列成一个 3×3 对角矩阵 𝐒 ，其最后一项为零。

因此，2D高斯是在世界空间的局部切平面上定义的，该切平面已被参数化：
$$
P(u,v)=\mathbf{p}_k+s_u\mathbf{t}_uu+s_v\mathbf{t}_vv=\mathbf{H}(u,v,1,1)^\top \tag{4}
$$
其中$𝐇∈4×4$ 是表示 2D 高斯几何图形的齐次变换矩阵（homogeneous transformation）
$$
\mathbf{H}=\begin{bmatrix}s_u\mathbf{t}_u&&s_v\mathbf{t}_v&&\mathbf{0}&&\mathbf{p}_k\\0&&0&&0&&1\end{bmatrix}=\begin{bmatrix}\mathbf{R}\mathbf{S}&&\mathbf{p}_k\\\mathbf{0}&&1\end{bmatrix} \tag{5}
$$

对于 UV 空间中的点 $𝐮=(u,v)$，其对应的**2D高斯值**可通过标准高斯进行评估
$$
\mathcal{G}(\mathbf{u})=\exp\left(-\frac{u^2+v^2}{2}\right)\tag{6}
$$
中心 $\mathcal{p}_k$  、缩放 $(s_u, s_v)$ 和旋转 $(t_u,t_v)$ 都是可学习的参数。参照3DGS，每个 2D高斯都有不透明度 $α$ 和与视图相关的颜色 $c$，并用球谐函数参数化。
## 4.2 泼溅
渲染2D高斯的一种常见策略是使用透视投影的仿射近似法将2D高斯投影到图像空间（Zwicker et al, 2001a）。然而，正如（Zwicker 等人，2004 年）所指出的那样，这种投影只在高斯中心精确，而且随着与中心距离的增加，近似误差也在增加。为了解决这个问题，Zwicker 等人提出了一种基于齐次坐标（homogeneous coordinates）的方法。**具体来说，将2D splat 投影到图像平面可以用齐次坐标的一般2D-to-2D映射来描述。让 $𝐖∈4×4$ 成为从世界空间到屏幕空间的变换矩阵。因此，屏幕空间点可通过以下方式获得**
$$
\mathbf{x}=(xz,yz,z,z)^\top=\mathbf{W}P(u,v)=\mathbf{W}\mathbf{H}(u,v,1,1)^\top \tag{7}
$$
其中， 𝐱 表示从摄像机发出的齐次光线，穿过像素 $(x,y)$ 并与深度 $z$ 处的 splat 相交。

为了将2D高斯光栅化，Zwicker 等人建议使用 ${\mathbf{M}}=(\mathbf{WH})^{-1}$ 的隐式方法将其圆锥投影到屏幕空间。**然而，逆变换会带来数值上的不稳定性，尤其是当splat 退化为线段时（即从侧面观察时）**。为了解决这个问题，之前的曲面泼溅渲染方法会使用一个预定义的阈值摒弃这种条件不佳的变换。然而，这种方案在可微分渲染框架中存在挑战，因为阈值化会导致优化不稳定。为了解决这个问题，我们受（Sigg 等人，2006 年）的启发，采用了显式 **ray-splat 相交法**。

### ray-splat 相交法
ray-splat 相交法通过寻找三个不平行平面的交点来有效定位 ray-splat 交点，这种方法最初是为专用硬件设计的（Weyrich et al, 2007）。给定图像坐标 $\mathbf{x}=(x,y)$ ，我们将像素的 ray 参数化为两个正交平面的相交：A 平面和 B 平面。具体来说，A 平面由法线向量 $(−1,0,0)$ 和偏移量 $x$ 定义。因此，A 平面可以表示为一个 4D 齐次平面 $𝐡_A=(−1,0,0,x)$ 。同样，B 平面表示为 $𝐡_B=(0,-1,0,y)$ 。因此，射线 $\mathbf{x}=(x,y)$ 是由 A 平面和 B 平面的相交决定的。
接下来，我们将两个平面转换为 2D 高斯的局部坐标，即 uv 坐标系。请注意，使用变换矩阵 $M$ 对平面上的点进行变换，等同于使用逆转置 $M^{-⊤}$ 对齐次平面参数进行变换 [Vince 2008]。因此，应用 $\mathbf{M}=(\mathbf{WH})^{-1}$ 等价于 $(\mathbf{WH})^{\mathsf{T}}$，省去了显式矩阵转置，从而得到
$$
\mathbf{h}_u=(\mathbf{WH})^\top\mathbf{h}_x\quad\mathbf{h}_v=(\mathbf{WH})^\top\mathbf{h}_y \tag{8}
$$
如第 4.1 节所述，2D高斯平面上的点用 $(u,v,1,1)$ 表示。同时，交点应落在变换后的 A 平面和 B 平面上。因此
$$
\mathbf{h}_u\cdot(u,v,1,1)^\top=\mathbf{h}_v\cdot(u,v,1,1)^\top=0 \tag{9}
$$
这样就可以得到交点 𝐮⁢(𝐱) 的有效解：
$$
u(\mathbf{x})=\frac{\mathbf{h}_u^2\mathbf{h}_v^4-\mathbf{h}_u^4\mathbf{h}_v^2}{\mathbf{h}_u^1\mathbf{h}_v^2-\mathbf{h}_u^2\mathbf{h}_v^1}\quad v(\mathbf{x})=\frac{\mathbf{h}_u^4\mathbf{h}_v^1-\mathbf{h}_u^1\mathbf{h}_v^4}{\mathbf{h}_u^1\mathbf{h}_v^2-\mathbf{h}_u^2\mathbf{h}_v^1}\tag{10}
$$
其中 $\mathbf{h}_u^i,\mathbf{h}_v^i$ 是  i-th 参数的 4D 齐次平面参数。我们通过公式 7 获得相交点的深度 $z$ ，并通过公式 6 评估高斯值。


### 退化问题
从倾斜视角观察2D高斯时，它在屏幕空间中会退化为一条线。因此，在光栅化过程中可能会漏掉它。为了处理这些情况并稳定优化结果，我们采用了（Botsch et al, 2005）中引入的对象空间低通滤波器：
$$
\hat{\mathcal{G}}(\mathbf{x})=\max\left\{\mathcal{G}(\mathbf{u}(\mathbf{x})),\mathcal{G}(\frac{\mathbf{x}-\mathbf{c}}{\sigma})\right\}\tag{11}
$$
其中 $𝐮⁢(𝐱)$ 由 (14) 给出， $𝐜$ 是中心 $𝐩_k$ 的投影。

直观地说， $\hat{\mathcal{G}}(\mathbf{x})$ 的下限是一个固定的屏幕空间高斯低通滤波器，其中心为 $c_k$ ，半径为 $\sigma$ 。在实验中，我们设置了 $\sigma=\frac{\sqrt{2}}{2}$ ，以确保在渲染过程中使用足够的像素。

### 光栅化
我们采用与 3DGS 类似的光栅化流程。

首先，为每个高斯计算一个屏幕空间bounding box。然后，根据高斯中心的深度对2D高斯进行排序，并根据它们的bounding box将其组织成tile。
 
最后，使用体积 alpha 混合技术将 alpha加权的颜色从前面整合到后面：
$$
\mathbf{c}(\mathbf{x})=\sum_{i=1}\mathbf{c}_i\alpha_i\hat{\mathcal{G}}_i(\mathbf{u}(\mathbf{x}))\prod_{j=1}^{i-1}(1-\alpha_j\hat{\mathcal{G}}_j(\mathbf{u}(\mathbf{x})))\tag{12}
$$
当累积的不透明度达到饱和时，迭代过程结束。

# 5 训练
我们的2D高斯方法虽然在几何建模方面很有效，但如果仅根据光度损失进行优化，则可能导致噪声，这是3D重建任务所固有的挑战（Barron 等，2022b；Zhang 等，2020；Yu 等，2022b）。为了缓解这一问题并改进几何重建，我们引入了两个正则化项：深度失真和法线一致性。
## 深度失真
Depth distortion

 与 NeRF 不同，3DGS 的体积渲染不考虑相交高斯之间的距离。因此，分散的高斯可能会导致相似的颜色和深度渲染。这与曲面渲染不同，在曲面渲染中，光线与第一个可见曲面相交一次即可。为了缓解这一问题，我们从 Mip-NeRF360 （Barron 等人，2022a）中汲取灵感，提出了一种 depth distortion loss，通过最小化射线与平面交叉点之间的距离来集中射线沿线的权重分布：
$$\mathcal{L}_d=\sum_{i,j}\omega_i\omega_j|z_i-z_j|\tag{13}$$

其中，
- $\omega_{i}=\alpha_{i}\hat{\mathcal{G}}_{i}(\mathbf{u}(\mathbf{x}))\prod_{i=1}^{i-1}(1-\alpha_{j}\hat{\mathcal{G}}_{j}(\mathbf{u}(\mathbf{x})))$ 是第 $i$ 个交点的混合权重
- $z_i$ 是交点的深度。

与 Mip-NeRF360 中的 distortion loss（$z_i$ 是采样点之间的距离，未进行优化）不同，我们的方法通过调整交点深度 $z_i$   直接促进了 splats的集中。请注意，我们使用 CUDA 以类似于 [Sun 等人，2022b] 的方式高效地实现了这一正则化项。

## 法线一致性
Normal Consistency

由于我们的表示方法基于2D高斯曲面元素，因此必须确保所有2D泼溅都与实际曲面局部对齐。在体积渲染的情况下，沿光线可能存在多个半透明曲面，**我们将实际曲面视为交点中值，即累积不透明度达到 0.5 的地方**。然后，我们按如下方法将 splat 的法线与深度图的梯度对齐：
$$
\mathcal{L}_{n}=\sum_{i}\omega_{i}(1-\mathbf{n}_{i}^{\mathsf{T}}\mathbf{N})\tag{14}
$$
其中，
- $i$ 代表沿射线相交的 splat
-  $\omega$ 代表交点的混合权重
- $n_i$ 代表朝向摄像机的 splat的法线
-  $\mathbf{N}$ 代表附近深度点 $p$ 估算的法线。具体来说，  $\mathbf{N}$ 的有限差分计算方法如下：
$$
\mathrm{N}(x,y)=\frac{\nabla_{x}\mathbf{p}\times\nabla_{y}\mathbf{p}}{|\nabla_{x}\mathbf{p}\times\nabla_{y}\mathbf{p}|}
$$
通过将 splat 法线与估计的曲面法线对齐，我们可以确保2D splat局部接近实际物体曲面。

## 最终损失
最后，我们利用一组位姿图像，从初始稀疏点云优化我们的模型。我们将最小化以下损失函数：
$$
\mathcal{L}=\mathcal{L}_{c}+\alpha\mathcal{L}_{d}+\beta\mathcal{L}_{n}
$$

其中，
-  $\mathcal{L}_{c}$ 是将 $\mathcal{L}_{1}$ 与[Kerbl 等人，2023] 的 D-SSIM 项相结合的 RGB 重建损失
-  $\mathcal{L}_{d}$ 和 $\mathcal{L}_{n}$ 则是正则化项。
- 对于有界场景，我们设定 α = 1000；对于无界场景，我们设定 α = 100；对于所有场景，我们设定 β = 0.05。
# 6 实验

现在，我们将对我们的2DGS重建方法进行广泛评估，包括与之前最先进的隐式和显式方法进行外观和几何比较。然后，我们分析了所提出的组件的贡献。

### 6.1 实现

在 3DGS 框架（Kerbl 等人，2023 年）的基础上，我们使用定制的 CUDA 内核实现了2DGS。我们对渲染器进行了扩展，以输出深度扰动图（depth distortion map）、深度图和法线图用于正则化。在训练过程中，我们按照 3DGS 中的自适应控制策略增加2D高斯的数量。

由于我们的方法并不直接依赖于投影2D中心的梯度，因此我们将3D中心p_k 的梯度投影到屏幕空间作为近似值。同样，我们将梯度阈值设为 0.0002 ，并每 3000 步删除不透明度低于 0.05 的splats。我们在单个 GTX RTX3090 GPU 上进行所有实验。

**网格提取**：为了从重建的2D splats中提取网格，我们使用投影到像素的splats的深度中值来渲染训练视图的深度图，并利用截断符号距离融合（ truncated signed distance fusion，TSDF）来融合重建的深度图，使用的是 Open3D（Zhou 等人，2018 年）。在 TSDF 融合过程中，我们将体素大小设置为 0.004 ，截断阈值设置为 0.02。我们还将原始 3DGS 扩展到渲染深度，并采用相同的技术进行曲面重建，以进行公平比较。

## 6.2 比较

# 6.2.1 数据集

我们在各种数据集上评估了我们方法的性能，包括 DTU（Jensen 等人，2014 年）、Tanks and Temples（Knapitsch 等人，2017 年）和 Mip-NeRF360 （Barron 等人，2022a）。DTU 数据集包括 15 个场景，每个场景有 49 或 69 幅分辨率为 1600×1200 的图像。我们使用 Colmap 为每个场景生成稀疏点云，并将图像向下采样至 800×600 的分辨率以提高效率。为了进行公平比较，我们对 3DGS （Kerbl 等人，2023 年）和 SuGar （Guédon 和 Lepetit，2023 年）使用了相同的训练流程。

## 6.2.2 几何重建

在表 1 和表 3 中，我们使用 DTU 数据集将我们的几何重建与 SOTA 隐式（即 NeRF、VolSDF和 NeuS）、显式（即 3DGS）和同时进行的 SuGaR（Guédon 和 Lepetit，2023 年））**在倒角(Chamfer)距离和训练时间方面进行了比较。在倒角距离方面，我们的方法优于所有对比方法。** 此外，如表 2 所示，在 TnT 数据集上，2DGS 与 SDF 模型（即 NeuS（Wang 等人，2021 年）和 Geo-Neus（Fu 等人，2022 年））取得了具有竞争力的结果，并且重建效果明显优于显式重建方法（即 3DGS 和 SuGaR）。 

![[Pasted image 20240418094030.png]]
> 表 2. 坦克和寺庙数据集的量化结果。我们报告的是 F1 分数和训练时间。

**值得注意的是，我们的模型显示出卓越的效率，其重建速度比隐式重建方法快约 100 倍，比同时进行的 SuGaR 工作快 3 倍多。**

如图 5 所示，我们的方法还能实现质量更好的重建，外观和几何细节更多，异常值更少。 ![[Pasted image 20240418094239.png]]

> 图 5.DTU 基准的定性比较（Jensen 等人，2014 年）。我们的 2DGS 可生成细致且无噪音的曲面。

几何重建结果见补充图 10。此外，基于 SDF 的重建方法需要预先定义球面尺寸进行初始化，这对 SDF 重建的成功与否起着至关重要的作用。相比之下，我们的方法利用基于辐射场的几何建模，对初始化不那么敏感。 ![[Pasted image 20240418100606.png]]

## 6.2.3 外观重建

外观重建：我们的方法将三维场景表示为辐射场，从而提供高质量的新视角合成。在本节中，我们将使用 Mip-NeRF360 数据集与基准方法比较我们的新视角渲染，如表 4 和图 4 所示。需要注意的是，由于 Mip-NeRF360 数据集中没有地面实况几何图形，因此我们将重点放在定量比较上。

值得注意的是，我们的方法在提供几何精度曲面重建的同时，还能获得与最先进技术相媲美的 NVS 结果。 ![[Pasted image 20240418094652.png]]

> 图 4.我们的方法、3DGS 和 SuGaR 使用无边界真实世界数据集（厨房、自行车、树桩和树丘）中的场景进行的视觉比较（测试集视图）。 第一列显示的是gt 第二列和第三列显示的是我们的渲染结果，展示了高保真的新视角和精确的几何图形。 第四栏和第五栏展示了我们的方法和 3DGS 的地表重建结果，利用的是深度范围为 6 米的 TSDF 融合技术。背景区域（在此范围之外）为浅灰色。 第六栏显示的是 SuGaR 的结果。 **与这两条基线相比，我们的方法在捕捉锐利边缘和复杂几何形状方面表现出色。**

![[Pasted image 20240418094540.png]]

> 表 4.Mip-NeRF 360（Barron 等人，2022a）数据集的定量结果。基线方法的所有得分均直接摘自其论文。我们使用 30⁢k 迭代来报告 3DGS、SuGaR 和我们的性能。

## 6.3 消融实验

略

# 7 结论

我们介绍了2DGS 技术，这是一种用于几何精确辐射场重建的新方法。我们利用2D高斯进行3D场景表示，从而促进了精确且视图一致的几何建模和渲染。

我们提出了两种正则化技术，以进一步增强重建的几何图形。在几个具有挑战性的数据集上进行的大量实验验证了我们方法的有效性和效率。

**局限性**：虽然我们的方法成功地为各种物体和场景提供了精确的外观和几何重建，但我们也讨论了它的局限性：首先，我们假设曲面完全不透明，并从多视角深度图中提取网格。

由于玻璃等半透明曲面具有复杂的透光特性，这给准确处理这些曲面带来了挑战。其次，我们目前的密集化策略偏向于纹理丰富的区域，而不是几何图形丰富的区域，有时会导致对精细几何结构的呈现不够准确。 更有效的密集化策略可以缓解这一问题。最后，我们的正则化通常需要在图像质量和几何图形之间进行权衡，有可能导致某些区域过度平滑。

# 8 附录

## 8.1 深度扰动的细节

Barron 等人(Barron et al., 2022b)使用射线上的样本计算失真loss，而我们使用的是高，其相交深度可能不是有序的。为此，我们采用 L2 损失，并将相交深度 z 转换到 NDC 空间，以降低远距离高斯的权重，m=NDC⁢(z)，近平面和远平面根据经验分别设置为 0.2 和 1000。我们基于（Sun 等人，2022b）实现了深度扰动loss，同样采用基于tile的渲染。在这里，我们展示了嵌套算法可以在单个前向传递中实现：

公式17

## 8.2 深度计算

# 8.3 其他结果
An enhanced approach for sentiment analysis based on meta-ensemble deep learning
基于元集成深度学习的情感分析的增强方法
# 摘要


情感分析，通常被称为“意见挖掘”，旨在识别意见文本中的情感极性（sentiment polarities）。近年来，学术界、企业、政府和其他几个组织对情感分析的接受程度显著增加。

已经开发了许多深度学习方法来有效处理更具挑战性的情感分析问题。然而，**深度学习方法的主要困难在于需要大量经验和辛勤工作来调整最佳超参数，使其成为一项繁琐且耗时的任务。** 最近的一些研究努力尝试通过结合集成学习和深度学习的力量来解决这个困难。其中许多努力集中在简单的集成技术上，但这些技术存在一些缺点。**因此，本文提出了一种元集成深度学习方法，以提高情感分析的性能**。
1. 在这种方法中，**我们使用三个层次的元学习器训练和融合基线深度学习模型。**
2. 其次，我们提出了基准数据集“Arabic-Egyptian Corpus 2”，作为之前语料库的扩展。该语料库的规模增加了 10,000 个用口语阿拉伯语编写的关于各种主题的标注推文。
3. 我们在不同语言和方言的六个情感分析基准数据集上进行了多个实验，以评估所提出的元集成深度学习方法的性能。

**实验结果表明，元集成方法在性能上有效地超越了基准深度学习模型。此外，实验还表明，当使用概率类别分布来训练元学习器时，元学习进一步提高了性能。**

# 1 引言
社交媒体在表达对事件、话题、人物、服务或产品的意见方面的力量得到了扩展，这是由于平台上用户生成的内容的增长）。因此，分析这些大量的社交媒体数据可以帮助更好地理解公众意见和趋势，并通过对文本中表达的意见和情感进行分类，并确定它们的**极性（积极、消极或中性）**来有效地做出重要决策

在文献中，已经**引入了几种使用机器学习方法进行情感分析的研究工作**。**进一步的努力使用深度学习来处理更大的数据，并改进对传统机器学习模型的分类性能**。
深度学习技术旨在通过有效的方法来解决复杂问题、大量数据的处理以及自动从文本中提取特征的能力，克服传统学习的局限和问题。**在应用于情感分析时，深度学习方法有几种架构和模型，例如循环神经网络（RNN），门控循环单元（GRU），长短期记忆（LSTM），卷积神经网络（CNN）。然而，深度学习技术的主要困难在于确定最合适的架构和模型。**

通常，**由于需要调整可能的超参数搜索空间中的最佳超参数**，深度模型需要付出很大的努力，这是一项**繁琐**的任务。**这些问题可以通过将集成学习应用于深度学习来解决。** 传统的集成学习是指合并多个基本模型以构建一个强大的模型（Kumar 等人 2021 年）。

在文献中，有几种集成方法，如平均、提升、装袋、随机森林和堆叠（Zhang 和 Ma 2012 年）。
**在深度学习中，大多数集成学习是模型的简单平均**（Tan 等人 2022 年；Mohammadi 和 Shaverizade 2021 年；Araque 等人 2017 年），因为它简单且结果较好。然而，基于投票的集成方法并不是一种聪明的方法来组合模型，因为它对弱模型有偏向性，这可能会降低在许多问题上的性能（Tasci等，2021年）。


为此，本研究的主要目标有四个。
1. 首先，我们提出了一种元集成深度学习方法，以提高情感分析的性能。提出的方法将几组深度模型的预测结果使用三个层次的元学习器进行组合。在所提出的方法中，我们通过使用训练数据的差异、训练基线深度学习器的多样性以及基线深度模型融合中的变化来实现集成的多样性。
2. 其次，我们提出了一个基准数据集“阿拉伯埃及语语料库”，该数据集包含了 5 万条关于不同主题的用口语阿拉伯语编写的推文。该语料库是“阿拉伯埃及语语料库”（Mohammed 和 Kora 2019）的扩展版本。
3. 第三，我们在六个公共基准数据集上进行了大量实验，以研究所提出的元集成深度学习方法在不同语言和方言的情感分类中的性能。对于每个基准数据集，不同的深度基准模型组在训练数据的分区上进行训练。将它们的最佳性能与所提出的元集成深度学习方法进行比较。
4. 最后，我们通过不同模型的预测结果，即类别标签概率分布和类别标签预测，展示了所提出的元集成深度学习方法的影响。

本文的主要贡献可以总结如下：
- 我们提出了一种元集成深度学习方法，以提高情感分类性能，该方法结合了三个层次的元学习器。
- 我们通过增加标注推文的数量，将阿拉伯埃及语料库（Mohammed 和 Kora 2019）扩展到了 50k。
- 我们使用六个不同语言和方言的公共基准情感分析数据集训练了几个基线深度模型。
- 我们进行了广泛的实验，以研究元集成深度学习方法对单个深度学习模型的影响。
- 我们比较了所提出方法中涉及的元学习器生成的预测效果，以提高性能。

本文的结构如下：
- 第2节简要介绍了情感分析的挑战以及各种集成学习方法，并突出了一些用于情感分析中的集成学习的文献。
- 第3节描述了元集成深度学习方法。
- 第4节展示了在不同基准数据集中基准深度学习模型和元集成深度学习方法的实验结果和评估。
- 第5节总结了本文并提出了未来的研究方向。

# 2 相关工作
通过情感分析，我们可以获得有助于决策、解决问题、管理危机、纠正误解、提供所需产品和服务、按照消费者的要求与其互动、改善产品和服务质量、发现新的营销策略并增加销售额的重要信息（Tuysuzoglu 等，2018 年）。

尽管情感分析具有诸多好处，但由于存在多个挑战和问题（Cambria 等，2017 年），它也是一项极具挑战性的任务。
1. 存在识别文本主观部分的问题：同一个词在一个语境中可能被视为主观的，而在其他一些语境中可能是客观的。这使得区分主观和客观（无情感）文本变得具有挑战性。
2. 存在领域依赖性的问题：在其他语境中，同一个句子可能表示完全不同的事物。
3. 讽刺检测的问题：讽刺的句子使用积极的词语来传达对目标的负面意见。
4. 受挫表达的问题：在一些句子中，文本的极性由文本的一小部分确定。
5. 间接否定情感的问题：这种否定不容易定义，因为它们不包含“不”，“没有”等词。
6. 顺序依赖的问题：当单词不被视为独立时。
7. 实体识别的问题：一个文本可能不总是指的同一个实体。
8. 识别意见持有者的问题：文本中的所有内容并不总是作者的观点。例如，当作者引用他人时。
9. 将情感与特定关键词关联的问题：许多陈述表达了非常强烈的观点，但无法确定这些情感的来源。

一般来说，情感分析可以在三个层面上进行：句子级别、文档级别和方面/特征级别。
- 在句子级别上，该层面的任务是逐句进行，并决定每个句子是否代表中性、积极或消极的观点。
- 在文档级别上，这个分析层面识别出文档的整体情感，并将其归类为负面或正面。
- 在方面级别（也称为词语或特征级别），这个分析层面旨在发现对实体和/或其方面的情感（Wagh 和 Punde 2018）。

**近年来，集成学习被认为是机器学习中最成功的技术之一。集成系统成功的主要因素包括增加基线分类器类型的多样性，使用不同的集成方法，使用不同的起始参数，以及从原始数据集创建多个数据集（交叉验证或子样本）（Mohammed 和 Kora 2021）。集成方法旨在通过将各个子模型的决策组合成一个新模型来提高预测准确性。此外，集成方法有助于避免过拟合，减少方差和偏差。**
此外，**集成学习有助于使用相同的基础学习器生成多个假设。此外，集成学习方法有助于减少基线模型的缺点**（Alojail 和 Bhatia 2020）。

用于提高机器学习性能的最流行的集成技术是装袋法、提升法和堆叠法。表 1 描述了每种方法的优点和缺点。

|Ensemble methods|Advantage|Disadvantage|
|---|---|---|
|Bagging|- Ease of implementation and adapts.  <br>- 实施和适应的便利性。|-High Bias - 高偏差|
||- Reducing Variance (Avoids Overfitting).  <br>- 减少方差（避免过拟合）。|-Computationally Expensive  <br>-计算成本高|
||- High performs on high-dimensional data.  <br>- 在高维数据上表现出色。|-Loss of interpretability of the model  <br>-模型的可解释性降低|
||-Allowing weak learners to outperform strong learner  <br>- 允许弱学习器胜过强学习器。||
||-Robust against to noise or outliers data  <br>-对噪音或异常值数据具有强韧性||
|Boosting 提升|-Reduces Variance. -减少方差。|-Slower to train -训练速度较慢|
||-Reduces Bias. -减少偏差。|- Computationally Expensive  <br>-计算成本高。|
||-Handling of the missing data.  <br>-处理缺失数据的能力。|-More Overfitting -过拟合更严重|
||- Ease of interpretation of the model  <br>-模型的解释性。|-The difficulty of scaling sequential training  <br>-顺序训练的扩展困难性。|
|||-Each classifier must correct the errors made by its predecessors  <br>-每个分类器必须纠正其前任所犯的错误|
|Stacking 堆叠|-A deeper understanding of the data.  <br>-对数据的更深入理解|-More Overfitting -过拟合更严重|
||-More Accurate -更准确|- Time Complexity - 时间复杂度|
||-Less Variance -更少的方差|-The difficulty of interpreting the final model  <br>- 解释最终模型的困难程度|
||-Less Bias -更少的偏差||
||-Used to ensemble a variety of strong learners  <br>-用于集成各种强学习器||

在情感分析中，许多研究表明不同的集成学习方法优于传统的机器学习分类器。例如，
- Kanakaraj和Guddeti（2015）；Prusa等（2015）；Wang等（2014）；Alrehili和Albalawi（2019）；Sharma等（2018）；Fersini等（2014）；Perikos和Hatzilygeroudis（2016）；Onan等（2016）的研究努力**在英语情感分析中应用了一种基于多个基准分类器（如NB、SVM、KNN、LR、DT、ME）的装袋方法。**
- Xia等（2011）；Tsutsumi等（2007）；Rodriguez-Penagos等（2013）；Clark和Wicentwoski（2013）；Li等（2010）的作者**应用了两种基于NB、SVM和LR的集成方法，即投票和堆叠，用于英语情感分析。**
- Da Silva等人（2014年）；Xia等人（2016年）；Fersini等人（2016年）；Araque等人（2017年）；Saleena（2018年）在英语情感分析中应用了基于多个传统分类器（如SVM、RF、LR、NB、DT和ME）的多数投票。同时，一些研究也应用了基于传统分类器的堆叠方法进行非英语情感分析。
- Lu和Tsou（2010）; Li等人（2012）; Su等人（2012）在中国评论中应用了基于KNN，NB，SVM和ME的堆叠方法
- Pasupulety等人（2019）则基于SVM和RF应用了堆叠方法来分析印度的评论。

基于集成的深度学习模型是传统集成学习方法的强大替代品，集成深度学习在情感分析方面表现出色。

# 3 提出的元集成深度学习方法

元集成深度学习方法的架构由三个层级组成，分别是第一层、第二层和第三层，如图 1 所示。
1. 第一层代表输入层，在这里，每个模型的(M)个板块都是独立训练的，使用不同的训练数据集和深度架构。
2. 第二层代表元学习器的隐藏层，在这一层中，前一层中每个板块模型的预测输出通过元学习器进行组合。
3. 第三层代表输出的元学习器层。在这个层级上，通过最终层级的元学习器将第二层元学习器的所有预测输出进行组合，产生最终的结果。

在抽象形式上，所提出的方法可以看作是一个通用的元神经网络，其中第 1 级被视为输入层，第 2 级是作为激活函数的隐藏层，第 3 级是输出层。
![[Pasted image 20240410102034.png]]
>图 1：所提出的元集成深度学习方法的总体架构

## 3.1 提出的算法描述
所提出方法的训练过程的正式语义在算法1中显示。

算法从训练数据集 $Data(0)$ 中随机生成 $N$ 个等大小的样本开始。
每个数据样本 $Data_i^{(0)}=(\mathrm{train}_i^{(0)},\mathrm{test}_i^{(0)})$ 被分成两部分：训练数据和测试数据。在基线学习过程中，通过在每个训练数据集 $\mathrm{train}_i^{(0)}$ 上应用 $M$ 个基线深度学习模型 $BL_j$ 生成 $Level-1$ 个学习模型。
因此，我们有 $n$ 个boards $C_i$，其中 $1\leq i\leq n$ ，每个boards包含 $M$ 个不同的基线模型 $C_{i}=Model_{i1},Model_{i2},\ldots,Model_{iM}$ 。
对于每个测试 $Test_{i}^{(0)}=(X^{(0)},Y^{(0)})$，使用 $n$ 个数据样本创建下一级的元数据 $Data_i^{(1)}$ ，方法是将每个模型 $Model_i$ 的预测输出堆叠起来。
每个级别2中的 $Data_i^{(1)}$  具有 $M+1$ 个特征：$M$ 个特征来自于 boards $C_i$ 中模型的预测结果 $test^{(0)}$ ，还有一个额外的特征表示类别标签 $T^{(0)}$ 。在生成了元数据之后，使用一组 $n$ 个浅层元分类器 $ShallowClf$ 来生成Level-2的模型。
在创建了Level-2模型之后，使用测试 $test_i^{(1)}=(X^{(a)},Y^{(1)})$ 来构建 $Level-3$ 的最终元数据。

与前一级别类似，最顶层的元数据是通过两个步骤生成的。第一步，根据 Level-2 模型对 $X ^{(1)}$ 和目标类别 $Y ^{(1)}$ 的预测结果，生成包含 $n + 1$ 个特征的 $Data ^{(1)}_ i$。下一步，我们构建 $Data ^{(1)}_ i$，形成最终元数据。在 Level-3学习阶段，我们将利用最终元学习器来学习这些顶级元数据。

![[Pasted image 20240410110220.png]]
# 4 实验结果
本节描述了在提出的元集成深度学习方法框架中用于情感分析的基准数据集的选择，基线深度模型的选择以及浅层元分类器的选择

## 4.1 基准数据集的描述
为了评估扩展的元集成深度学习方法，我们选择了六个情感基准数据集进行实验，这些数据集基于英语、阿拉伯语和不同的方言：我们提出了第一个数据集称为“阿拉伯埃及语语料库2”，由语料库（Mohammed和Kora 2019）中的40,000条带有注释的推文组成，并且还有另外10,000条推文的扩展，这些推文可以在Kora和Mohammed（2022）中找到。后面的扩展包括来自阿拉伯语和埃及方言的5,000条积极推文和5,000条消极推文。第二个数据集包括与Covid19大流行期间远程学习相关的沙特方言的推文（Aljabri等人，2021）。它包含了总共1675条推文，其中积极推文比消极推文多。第三个数据集是ASTD（Nabil等人，2015）。它包含了来自不同方言的约10,000条阿拉伯语推文，并被分类为797条积极推文和1682条消极推文（表2）。推文被标注为积极、中性、消极和混合。第四个数据集是ArSenTD-LEV（Al-Laith和Shahbaz，2021）。它包含了来自黎凡特地区（如约旦、巴勒斯坦、黎巴嫩和叙利亚）的4,000条推文。第五个数据集是电影评论（Koh 等人，2010 年）。它包含 10,662 条评论，分为 5331 条负面评论和 5331 条正面评论。第六个数据集是 Twitter 美国航空公司情感数据集（Rane 和 Kumar，2018 年）。表 3 总结了不同情感分析基准数据集的特点。它包含来自美国六家航空公司的 14,600 条客户推文，包括负面、正面和中性情感。

通常情况下，在训练网络之前，使用一位有效编码或词嵌入（Lai 等人，2016 年）对文本数据进行预处理，作为初始层。每个数据集只使用正面和负面的二元情感极性标签，忽略其他极性标签。

在我们的实验中，我们将每个基准数据集划分为训练集和验证测试集，比例为（ 80% ， 20% ）。此外，我们将每个基准数据集划分为八个分区。

## 4.2 基线深度学习模型

为了通过提出的元集成深度学习方法增强情感分析预测的性能，我们首先需要为每个基准数据集构建一组深度学习模型，这些模型将成为提出的元集成深度学习方法的基线分类器。

本研究提出了三个深度基线模型：
1. **长短期记忆（LSTM**）是我们评估中使用的第一个基线深度模型（Mohammed和Kora 2019）。LSTM模型是一种用于表示序列数据的众所周知的架构。它被设计得更好地捕捉长期依赖性，而不是循环神经网络模型。LSTM架构由三个门组成：输入门、遗忘门和输出门。
2. 门控循环单元（GRU）是下一个基准深度模型（Pan 等人，2020 年）。GRU 模型与 LSTM 模型相比，参数更少。GRU 由两个门组成：重置门和更新门。
3. 卷积神经网络模型（CNN）是第三个基准深度模型（Abdulnabi 等人，2015 年）。CNN 模型是一个前馈神经网络，包含一个或多个卷积层和一个全连接层，还包括一个池化层用于整合。

一般来说，每个深度基准模型都是在不同的超参数上进行训练的。表 4 显示了基准深度学习模型的配置。表 5 显示了每个数据集中每个数据拆分的准确性以及每个基准深度模型在每个数据集中的平均准确性。
![[Pasted image 20240410112216.png]]
>表 4 基线深度学习模型的配置

![[Pasted image 20240410112255.png]]
>表 5 基线深度分类器在不同数据集中的性能精度结果

- 在沙特阿拉伯推文的第二个数据集中，LSTM2 模型的最高平均准确率为 65.38%。
- 在第三个 ASTD 数据集中，LSTM 模型的最高平均准确率为 71.6%。
- 在第四个ArSenTD-LEV数据集中，LSTM模型获得的最高平均准确率为76.2%。此外，在电影评论数据集的第五个数据集中，LSTM1模型获得的最高平均准确率为78.03%。
- 在 Twitter 美国航空情感数据集的第六个数据集中，LSTM1 模型的最高平均准确率为 80.05%。
在进行的实验中，总共训练了 114 个深度基准模型。此外，基线模型的大小在每个数据集上都有所不同。在沙特阿拉伯，推文、电影评论和推特美国航空情感是 4 个深度基线模型，而 ASTD 和 ArSenTD-LEV 是 3 个深度基线模型。

## 4.3 元集成分类器
Meta-ensemble classifiers

为了在模型集合中组合训练好的基线深度模型，我们使用一组浅层元分类器，包括支持向量机（SVM）、梯度提升（GB）、朴素贝叶斯（NB）、随机森林（RF）、逻辑回归（LG）作为顶层元学习器。

表 6 描述了在每个数据集中所提出的聚类方法的准确性结果。
![[Pasted image 20240410112350.png]]
>表 6 提出的元集合（Meta-Ensemble）在不同数据集中的性能精度

- 在阿拉伯埃及语料库的第一个数据集中，结果表明，集成与 SVM 分类器在硬预测和软预测中均取得了最佳准确性，分别为 92.6%和 93.2%。
- 在沙特阿拉伯推文的第二个数据集中，结果表明，集成与 SVM 分类器在硬预测中取得了 69.9%的最佳准确性。
- 相比之下，同时使用 SVM 和 LG 分类器的集成模型以 72.3% 的得分获得了最佳的软预测准确率。
- 在 ASTD 的第三个数据集中，结果表明同时使用 SVM 和 LG 分类器的集成模型以 75.9% 的得分获得了最佳的硬预测准确率。
- 同时，使用 LG 分类器的集成模型以 77.6% 的得分获得了最佳的软预测准确率。
- 在 ArSenTD-LEV 的第四个数据集中，结果表明使用 SVM 分类器的集成模型在难度预测方面取得了最高的准确率，得分为 80.4%。
- 相比之下，使用 LG 分类器的集成在软预测中取得了最佳准确性，得分为 83.2%。
- 在第五个电影评论数据集中，结果表明，使用 SVM 分类器的集成在硬预测和软预测中都取得了最高的准确率，分别为 80.9%和 83.9%。
- 在 Twitter 美国航空情感的第六个数据集中，结果表明使用 SVM 分类器的集成模型在硬预测中取得了最高的准确率，为 82.9%。
- 同时，使用 GB 分类器的集成在软预测中取得了最高的准确率，为 85.3%。

表 7 比较了平均基线深度模型的最高准确率结果与每个数据集中元集成分类器的最高准确率结果。
![[Pasted image 20240410112519.png]]

可以注意到，在软预测中，所提出的元集成在不同数据集中获得了最高的平均准确率。**此外，可以注意到，在不同的数据集中，基线深度模型中获得的最高平均准确率是 LSTM 模型，而不是其他网络**。总的来说，可以注意到，**不同的元集成分类器在最终预测中表现更好。**

还可以注意到，在对深度基线模型的预测进行 5 折交叉验证时，SVM 被显示为在一级模型中融合模型的最常见最佳组合器，分别在阿拉伯埃及语料库、沙特阿拉伯推文和电影评论数据集中分别达到 93.2%、72.3%和 83.9%。此外，在ASTD和ArSenTD-LEV数据集中，LG被显示为最常见的最佳组合器，分别在一级模型中将板块融合的百分比为77.6%和83.2%。最后，在 Twitter 美国航空情感数据集中，GB 被认为是在一级中以 85.3%的频率融合模型的最佳组合器。

# 5 结论
文献中显示，深度学习模型在情感分析方面取得了巨大的成功。然而，构建一个有效的深度学习模型需要付出很大的努力，因为需要找到最佳的神经网络架构和超参数的最佳配置。
解决这些限制的一种方法是使用集成方法。集成的关键思想是使用弱学习器的组合来产生一个强大的学习器。

因此，在这篇研究论文中，我们提出了一种元集成深度学习方法来提高情感分析的性能。这种提出的方法使用三个层次的元学习方法来结合几组深度模型的预测。
此外，我们提出了基准数据集“阿拉伯埃及语语料库 2”。该语料库包含了 10,000 条关于各种话题的用口语阿拉伯语书写的标注推文。该语料库是在 Mohammed 和 Kora（2019 年）的原始版本基础上添加的，原始版本包含 40,000 条标注推文。我们对涉及多种语言和方言的六个公共基准数据集进行了多次实验，以测试和评估所提出的元集成深度学习方法的性能。
我们在每个基准数据集上训练了一组基线分类器（GRU、LSTM 和 CNN），并将它们的最佳模型与提出的元集成深度学习方法进行了比较。
具体而言，我们训练了 114 个深度模型，并对五个不同的浅层元分类器进行了比较，以集成这些模型。
实验结果显示，元集成深度学习方法在所有六个基准数据集的基准深度学习模型上表现出色。

此外，实验表明，当涉及层的预测形式为概率分布时，元学习器的效果更好。

总之，所提出的集成方法使用并行集成技术，其中基线学习器同时生成，因为没有数据依赖性，融合方法依赖于元学习方法。

然而，我们提出的方法存在一些**挑战和限制**，例如确定适当数量的基线模型，并选择可靠的基线模型，以便从头开始设计我们的元集成深度学习方法时生成最佳预测。此外，当可用数据量呈指数增长时，计算时间复杂度的难度也增加。此外，在数据维度较高的情况下，多标签分类问题引发了许多问题，如过拟合和维度灾难。在多级集成的情况下，处理多类问题值得研究。此外，最近在自然语言处理任务中，变换器模型受到了更多关注。值得进行全面的实验，研究变换器与集成学习的影响。
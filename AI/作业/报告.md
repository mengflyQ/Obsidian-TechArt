![](file:///C:/Users/s2304719/AppData/Local/Temp/msohtmlclip1/01/clip_image002.jpg)

需要解析：F1-scores, accuracy, recall and precision

# 使用ML算法和方法进行分类
# 目录
# 摘要

# 引言

机器学习是人工智能的一个重要分支，它的目标是开发和应用算法，使计算机可以从数据中学习并做出预测或决策。机器学习中的分类问题是一类常见的监督学习任务，其主要目标是根据给定的输入数据，将其划分到不同的类别中。在分类问题中，算法通过学习输入数据与其对应的标签之间的关系，从而能够对新的、未标记的数据进行分类。分类问题在实际应用中非常广泛，涉及到图像识别、自然语言处理、医学诊断、金融欺诈检测等多个领域。通过不断改进算法和优化模型参数，研究者们致力于提高分类模型的性能和适应性。

在众多的分类算法中，随机森林和K近邻（KNN）算法是两种广泛使用的方法。随机森林是一种集成学习方法，它通过构建并结合多个决策树来做出预测。KNN算法则是一种基于实例的学习方法，它根据输入数据在特征空间中的邻近样本的类别来做出预测。 

本报告的目标是使用随机森林和 KNN 分类器对 Fashion MNIST 和 Cifar10数据集进行分类并评估。我们将首先对数据进行预处理，然后使用随机森林和 KNN 分类器进行模型训练，最后使用混淆矩阵和分类报告来评估模型的性能。

本文的结构如下︰第二部分介绍了相关工作的最新进展，第三部分是主体部分，将对实验流程进行详细描述。第四部分展示了我们获得的结果，并对每种情况分别进行了讨论。最后，我们以结论和参考文献结束本文。

# 相关工作

本节总结了利用随机森林和KNN进行分类的相关工作。
Komarasamy. G 等人[[Harmony Gradient Boosting Random Forest Machine Learning Algorithms for Sentiment Classification | IEEE Conference Publication | IEEE Xplore](https://ieeexplore.ieee.org/document/10051210)] 使用随机森林算法进行社交媒体情感分类，与其他方法相比，和谐梯度提升随机森林机器学习技术产生了更好的结果。
徐畅等人[在手写图像上应用 MLP 和 CNN 进行图像分类任务 |IEEE会议出版物 |IEEE Xplore的](https://ieeexplore.ieee.org/document/9948282)使用比较了 MLP 和 CNN 这两种常见模型的性能，并分析了它们在处理手写图像图像分类时的数据尺度敏感性。该研究基于 MNIST 数据库，最终 MLP 获得了最佳性能。

沃尔夫方 D 等人[使用机器学习算法 K-NN、MLP 和 K-Means 聚类根据感官成熟度（着色）对番茄进行分类 |IEEE会议出版物 |IEEE Xplore的](https://ieeexplore.ieee.org/document/8730232)使用机器学习算法来描述和提取西红柿图像颜色统计的特征，对 KNN，MLP 等算法进行了全方位的评估。他发现用于番茄颜色分类的 K-NN 算法与 MLP 神经网络方法相结合，可以获得最佳性能。
罗杰·辛格·丘格等人[图像分类器的比较分析 |IEEE会议出版物 |IEEE Xplore的](https://ieeexplore.ieee.org/document/9058042)使用经典机器学习算法（（KNN）、（MLP）和随机森林分类器（RF）对数据集的准确率、时间复杂度、F1分数、召回率和精确度等参数进行了对比分析。结果表明，MLP 的准确率最高。
MN Ahil 等人[使用 MLP 和 CNN 对苹果和葡萄叶病进行分类 |IEEE会议出版物 |IEEE Xplore的](https://ieeexplore.ieee.org/document/9675567)从 Kaggle 的 Plant Village 数据集中获得了包含两者叶部病害图像的数据集, 使用 MLP 和 CNN 对叶片病害进行分类并对对分类器的性能度量和准确性进行了比较和分析。他发现与 MLP 相比，CNN 在最少的 epoch 数下表现良好
李莹[一种改进的k最近邻算法及其在高分辨率遥感影像分类中的应用 |IEEE会议出版物 |IEEE Xplore的](https://ieeexplore.ieee.org/document/5293389)等人借鉴裁剪 KNN 的思想，采用改进的 KNN 分类算法，并将其应用于高分辨率遥感影像的面向对象分类。发现改进的 KNN 算法在高分辨率遥感影像分类中可以达到更高的精度。
奥西姆·库马尔·帕尔[皮肤病分类：K-最近邻（KNN）与随机森林算法的比较分析 |IEEE会议出版物 |IEEE Xplore的](https://ieeexplore.ieee.org/document/9641120)等人基于KNN和随机森林算法进行设计。患者可以使用该模型将他的皮肤病归类为主要检测，医生也可以通过使用该模型来确保他的判断。
Goswami [2]（Bosch, A., Zisserman, A., & Munoz, X. (2007). Image Classification using Random Forests and Ferns. In proceedings of IEEE 11th International Conference on Computer Vision.） 在他的⼯作中使⽤ K 最近邻在 CIFAR-10 数据 集上进⾏图像分类，该数据集是⼀个包含 10 个类别的⼩型数 据集。他发现 KNN 对所考虑的数据进⾏分类不是很准确。

Krithika 和 Selvarani [9]（Krithika, N., & Selvarani, A. G. (2017). An individual grape leaf disease identification using leaf skeletons and KNN classification. In proceedings of International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS).） 在他们的⼯作中使⽤ K 最近邻分类 来对葡萄叶病进⾏分类并识别叶⻣架。使⽤葡萄图像识别叶 ⼦⻣架。他们发现通过使⽤ KNN 分类可以有效地对葡萄叶部 病害进⾏分类。



# 主体

## 数据集
### 时尚-MNIST 数据集
本研究采用了时尚-MNIST数据集（http://arxiv.org/abs/1708.07747）该数据集包括一个由60,000张样本图像组成的训练集和一个由10,000张灰度样本图像组成的测试集。数据集中的每幅图像分辨率为28x28像素。每张训练和测试图像都属于10个类别之一，包括T恤/上衣、裤子、毛衣、连衣裙、外套、凉鞋、衬衫、运动鞋、包和靴子。每个类别有6000张样本图像。每一行都是单独的图像，第1列是类别标签，其余各列是像素编号（共784个)。

able x: Class names and example images in Fashion-MNIST dataset.

![](file:///C:/Users/s2304719/AppData/Local/Temp/msohtmlclip1/01/clip_image004.jpg)
### CIFAR-10
**CIFAR-10** 是一个常用的**彩色**图片数据集，它有 **10** 个类别: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’。每张图片都是  $3\times32\times32$ ，也即 **3 通道（RGB）彩色图片，分辨率为 $32\times32$。

该数据集共有 60000 张彩色图像，这些图像是 `32*32`，分为 10 个类，每类 6000 张图。这里面有 **50000 张用于训练**，构成了 5 个训练批，每一批 10000 张图；另外 10000 用于测试，单独构成一批。测试批的数据里，取自 10 类中的每一类，每一类随机取 1000 张。抽剩下的就随机排列组成了训练批。注意一个训练批中的各类图像并不一定数量相同，总的来看训练批，每一类都有 5000 张图。

## 数据加载及预处理

图像分类中的预处理是一个对图像进行转换以准备分类的过程。这些步骤包括导入必要的库，然后从文件夹中检索图像。然后调整图像大小并转换为 NumPy 数组。然后将数组分割为训练数据和测试数据。 70%的数据用于训练，30%用于测试。（https://ieeexplore.ieee.org/document/9058042）

## 分类器介绍

### 随机森林

随机森林（Random Forest）是一种集成学习方法，它通过构建多个决策树并将它们整合在一起来进行分类或回归任务。随机森林是由Leo Breiman在2001年提出的（Breiman L, 2001a.Random forests.Mach.Learn., 45:5-32.），它在机器学习中被广泛应用，因为它具有良好的性能和鲁棒性。随机森林由多个决策树组成。每个决策树都是一个分类器，通过对输入数据进行逐层的判定，最终输出属于哪个类别。随机森林在构建每棵决策树时引入了随机性。对于分类任务，随机森林采用投票机制进行决策。每棵决策树对输入数据进行分类，最终的分类结果是获得最多投票的类别。随机森林通过组合多个决策树的预测结果，减小了过拟合的风险，提高了模型的鲁棒性和泛化能力。它对于处理高维数据和大规模数据集都表现出色。

随机森林中的树按以下规则生成：
1）如果训练集大小为 N，对于每棵树而言，随机且有放回地从训练集中的抽取 N 个训练样本（这种采样方式称为 bootstrap sample 方法, 为拔靴法采样），作为该树的训练集；从这里我们可以知道：每棵树的训练集都是不同的，而且里面包含重复的训练样本。

2）如果存在M个特征维度，则指定数量m << M，使得在每个节点处，从M中随机选择m个特征维度，并且使用这些m个特征维度中最佳特征(最大化 information gain)来分割节点。在森林生长期间，m的值保持不变。

3）每棵树都尽最大程度的生长，并且没有剪枝过程。

### KNN

使用KNN算法应用图像分类。在模式确认中，KNN算法是一种用于分类和回归的非参数方法。输出基于KNN是用于排序还是回归：在KNN分类中，最后一个输出是周期附属。一个对象是通过其邻居的极端投票来分类的，被分配到其k个最近邻居中最常见的类的对象，其中k是正整数，通常很小。如果k＝1，则该对象仅被选择为唯一一个最近邻居的类。在KNN回归中，最后一个乘积是对象的属性值。该特定值是其k个最近邻居的正常值。KNN是一种基于发生率的学习，或缓慢的实现，其中体积与近处相似，所有计算都被允许，直到顺序。KNN计算是所有机器学习计算中最直接的计算之一。KNN分类器的执行基本上由K的决定以及所连接的分离度量来决定。该度量受到区域度量K的确定的可影响性的影响，理由是附近区域的扫描是由与问题的第K个最近邻居的分离决定的，并且不同的K产生不同的限制性类概率。在K很小的情况下，由于信息匮乏的条件和喧闹、模糊或错误标记的焦点，附近的量规通常会非常差。最终目标是进一步平滑度量，我们可以构建K，并围绕这个问题考虑一个实质性的区域设置。令人震惊的是，对K的广泛估计有效地使规范过度平滑，并且排列执行随着不同类别异常的出现而降低。为了解决这一问题，已经进行了相关的研究工作，以提高KNN的安排执行力。(https://ieeexplore.ieee.org/document/9058042)

KNN（k近邻算法）的步骤:
1.      计算测试数据与各个训练数据之间的距离
2.      按照升序（从小到大）对距离（欧氏距离）进行排序
3.      选取距离最小的前k个点
4.      确定前k个点所在类别出现的频率
5.      返回前k个点中出现频率最高的类别作为测试数据的分类

# 结果与讨论

# 结论

# 参考文献

[Fashion Images Classification using Machine Learning, Deep Learning and Transfer Learning Models | IEEE Conference Publication | IEEE Xplore](https://ieeexplore.ieee.org/document/9786364)

# 附录（代码）
---
number headings: auto, first-level 1, max 6, 1.1
---

# 1 introduction
云计算[1]彻底改变了现代 IT 环境中部署、管理和扩展应用程序的方式。在现有的各种技术和平台中，Docker[2] 脱颖而出，成为容器化的关键工具，实现了云计算中应用程序的高效部署。本报告探讨了 Docker 在云计算中的意义，并概述了容器化的优势、可移植性、镜像管理、容器容量和容器网络等关键概念。

此外，报告还深入探讨了更广泛的云计算概念，如负载平衡、可扩展性和应用网关，强调了它们在构建可扩展、有弹性的云计算应用中的重要性。报告还讨论了云计算扩展背后的驱动力，重点关注成本效益和灵活性等因素。

此外，报告还探讨了作为云计算新方法的无服务器功能的新兴趋势，并将其与容器化进行了比较和对比。通过实际案例和讨论，本报告旨在提供对 Docker 和云计算概念的全面理解，强调它们在现代 IT 环境中的重要性。

[1]B. Hayes, "Cloud computing[J]", _Communications of the Acm_, vol. 51, no. 7, pp. 9-11, 2008.
[2][Docker [Software engineering] | IEEE Journals & Magazine | IEEE Xplore]( https://ieeexplore.ieee.org/document/7093032 )

# 2 docker 的容器化
## 2.1 容器化的好处
软件开发的一大阻碍就是运行环境，在容器概念提出以前，用户可以通过虚拟机还原软件的原始环境实现虚拟化，但是虚拟机方法存在资源占用多、无法跳过系统操作步骤、启动慢等问题。由于虚拟机存在这些缺点，Linux 发明了一项新技术：Linux Container（LXC）[1], LXC 通过对进程进行隔离而不是模拟完整的操作系统来实现容器化。容器化是操作系统虚拟化的一种形式，换句话说容器使用的是操作系统级别的虚拟化技术，而不是虚拟机级别的虚拟化技术。用户可在使用相同共享操作系统的隔离用户空间（称为容器）中运行应用程序。应用程序容器是一个完全打包、可移动的计算环境。
由于 LXC 是进程级别的，相比虚拟机有很多优势，首先是启动快，容器里面的应用，直接就是底层系统的一个进程，而不是虚拟机内部的进程。所以，启动容器相当于启动本机的一个进程，而不是启动一个操作系统，速度就快很多。其次是资源占用少，容器只占用需要的资源，不占用那些没有用到的资源；虚拟机由于是完整的操作系统，不可避免要占用所有资源。另外，多个容器可以共享资源，虚拟机都是独享资源。此外容器还有体积小的优点容器只要包含用到的组件即可，而虚拟机是整个操作系统的打包，所以容器文件比虚拟机文件要小很多。总之，容器就像轻量级的虚拟机，能够提供虚拟化的环境，但是成本开销小得多。
除了上述提到的优点，容器化补充了 DevOps[2]，因为可以更快地部署和测试软件，从而改善反馈循环。容器化也是微服务流行的一个主要因素，微服务是一种提高灵活性和敏捷性的软件架构。你可以使用容器化来加快开发新功能和获得反馈所需的时间。平台即服务 (PaaS) 解决方案和容器编排工具（如 Kubernetes）让开发人员可以大规模操作容器[3]。容器编排器可以根据需求和负载向上和向下扩展软件应用程序中的各个组件。这可以节省成本，因为组件仅在需要时运行。扩展还提高了可靠性，因为容器编排器可以将足够的资源分配给应用程序的高需求部分。
Docker 是 LXC 的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样[4]。
![[Pasted image 20240419215436.png]]
>虚拟化和容器化架构对比（[什么是 Linux 容器（LXC）？一文带你快速了解容器技术 - 红帽 (redhat.com)](https://www.redhat.com/zh/topics/containers/whats-a-linux-container)）


[1] [Connecting Framework of Smart Devices Based on Linux Container Technology | IEEE Conference Publication | IEEE Xplore](https://ieeexplore.ieee.org/document/8281163)
[2] [基于Docker和DevOps技术的企业信息系统架构设计 |IEEE会议出版物 |IEEE Xplore（IEEE Xplore）](https://ieeexplore.ieee.org/document/10117715)
[3] [Design and Implementation of High-availability PaaS Platform Based on Virtualization Platform | IEEE Conference Publication | IEEE Xplore](https://ieeexplore.ieee.org/document/9141564)
[4] Wajdi Hajji and Fung Po Tso, "Understanding the Performance of Low Power Raspberry Pi Cloud for Big Data", _Electronics_, 2016.
## 2.2 可移植性（Portability）
容器是可移植的，因此它们可以在任何基础架构上的任何位置运行，例如在云中、VM 或裸机上。开放容器倡议 (OCI) 为容器设计开放标准，确保任何符合 OCI 的容器在任何基础设施上都以相同的方式运行。要运行应用程序，容器会加载容器 image。容器Image是一个静态文件，其中包含在 IT 基础架构上运行进程的可执行代码。有针对不同用例的容器Image，例如数据库、Web 服务器、操作系统等。容器镜像存储库是容器镜像的公共访问点，这使得它们可供开发人员使用，他们可以使用这些镜像加载容器。如果你想为你的应用程序使用容器，你可以确保你使用的任何 OCI Image都可以在你的基础架构上运行，即使你的基础架构发生了变化。
Docker 的 image 文件称为 Docker image, Docker 把应用程序及其依赖，打包在 image 文件里面。只有通过这个文件，才能生成 Docker 容器。image 文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image 文件，可以生成多个同时运行的容器实例。image 是二进制文件。实际开发中，一个 image 文件往往通过继承另一个 image 文件，加上一些个性化设置而生成。**在 Docker 中我们可以通过 Dockerfile 创建 Dockerimage。** Dockerfile 是一个文本文件，用来配置 image。Docker 根据该文件生成二进制的 image 文件。

下面是一个示例，演示了如何构建 Docker file 以生成 image



## 2.3 镜像和发布镜像（Images and publishing images）
Docker Hub是一个由Docker提供的托管仓库服务，里边包含有很多平时用的较多的镜像。用户可以直接从 DockerHub下载镜像，还也可以将自己自定义的镜像push到 DockerHub 上。通过Docker Hub，你可以轻松地交付任何应用程序，并使你的应用程序可以被你的团队访问。

**下面是一个示例，演示了如何将 image push到 DockerHub**

## 2.4 容器卷（Container volumes）
[Docker Volume 看这一篇就够了-阿里云开发者社区 (aliyun.com)](https://developer.aliyun.com/article/1113502)
默认情况下，在容器内创建的所有文件都存储在可写容器层上。这意味着：当该容器不再存在时，数据不会持续存在，并且如果另一个进程需要数据，则可能很难将数据从容器中取出。容器的可写层与运行容器的主机紧密耦合。用户无法轻松地将数据移动到其他地方。写入容器的可写层需要 存储驱动程序来管理文件系统。存储驱动程序提供了一个联合文件系统，使用 Linux内核。与使用直接写入主机文件系统的数据卷相比，这种额外的抽象会降低性能 。

Docker 有两个选项让容器在主机上存储文件，以便即使在容器停止后文件也能持久保存：volumes和 bind mounts。Docker 还支持将文件存储在主机内存中的容器。此类文件不会持久保存。如果用户在 Linux 上运行 Docker，则使用tmpfs mount将文件存储在主机的系统内存中。

本节主要探讨 Container volume，简单来说，通过Container volume 可以持久保存容器创建的数据，方便在容器之间共享数据。
![[Pasted image 20240420094702.png]]
>Docker 的存储

**下面是一个示例，演示了如何创建 Container volume**

## 2.5 .5 容器网络（Container networking）
[【Docker】Docker中network的概要、常用命令、网络模式以及底层ip和容器映射变化的详细讲解-阿里云开发者社区 (aliyun.com)](https://developer.aliyun.com/article/1314166)
在实际工程中，我们往往有多个容器，容器之间需要相互访问，Docker通过Docker networking实现容器之间的相互访问。Docker网络模型包括三个主要组件：容器、网络和端点。容器是运行应用程序的独立环境，网络提供容器之间和容器与外部世界之间的通信路径，而端点则是连接容器和网络的桥梁。 Docker支持多种网络类型，包括桥接网络、主机网络、覆盖网络和无网络。桥接网络是默认的网络类型，它使用Docker daemon主机上的桥接接口将容器连接到主机网络。主机网络直接将容器连接到主机网络接口，使得容器可以直接访问主机上的网络资源。覆盖网络是多个Docker守护进程连接在一起的虚拟网络，它允许容器在不同主机上进行通信。无网络类型则表示容器没有网络访问能力。 Docker提供了一组命令来管理和配置网络。

**下面是一个示例，演示了如何创建 Container Network**
# 3 云计算
[负载均衡 产品概述-产品简介-文档中心-腾讯云 (tencent.com)](https://cloud.tencent.com/document/product/214/524)
云计算的三个主要概念是load balancing, scalability and application gateways，下面我将以中国的大型云提供商—腾讯云为例，阐述与这三个概念相关的问题。
腾讯云是腾讯旗下的云计算服务商，为企业和开发者提供计算、存储、数据库、网络、大数据、视频、游戏等多种云服务，以及音视频、互动直播、在线教育等行业。
## 3.1 简要描述云提供商实现上述每个概念的方法

**负载均衡的实现：**

[负载均衡 产品概述-产品简介-文档中心-腾讯云 (tencent.com)](https://cloud.tencent.com/document/product/214/524)

负载均衡是一项服务，它根据需求将流量分配到不同的Real Server，以增强应用系统的吞吐能力。同时，它还能够消除系统中的单点故障，提高应用系统的可用性。
腾讯云提供的负载均衡服务具备自助管理、自助故障修复，防网络攻击等高级功能，适用于企业、社区、电子商务、游戏等多种用户场景。一个提供服务的负载均衡组通常由以下部分组成：Cloud Load Balancer(CLB)、Load Balance Listener(LBL)、Real Server(RS)。

Cloud Load Balancer接受来自客户端的传入流量，并将请求路由到一个或多个可用区的Real Server实例上进行处理。用户可以使用 CNAME 或 A 记录解析对外提供访问。其中仅公网负载均衡可以选择 CNAME 方式。客户端请求通过域名访问服务，在请求发送到Load Balancer之前，DNS 服务器将会解析负载均衡域名，并将收到请求的负载均衡 IP 地址返回到客户端。当Load Balance Listener收到请求时，将会使用不同的负载均衡算法将请求分发到Real Server中。目前腾讯云支持加权轮询和 ip_hash 加权最小连接数等多种均衡算法。客户端请求通过域名访问服务，在请求发送到Load Balancer之前，DNS 服务器将会解析负载均衡域名，并将收到请求的负载均衡 IP 地址返回到客户端。当Load Balance Listener收到请求时，将会使用不同的负载均衡算法将请求分发到Real Server中。目前腾讯云支持加权轮询和 ip_hash 加权最小连接数等多种均衡算法。
![[Pasted image 20240420152350_译图.png]]


负载均衡服务主要由 Load Balance Listener提供。监听器负责监听负载均衡实例上的请求、执行策略分发至Real Server等服务，包括监听端口、负载均衡策略和健康检查配置等，每个监听项对应后端的一个应用服务。通过配置**客户端 - 负载均衡**和**负载均衡 - Real Server**两个维度的转发协议及协议端口，负载均衡可以将请求直接转发到Real Server上。

Real Server 是后端的一组服务器实例，用于接收前端的请求。来自负载均衡外的访问请求，通过负载均衡实例并根据相关的策略和转发规则分发到Real Server进行处理。可以跨多个可用区配置Load Balancer的 Real Server实例。如果一个可用区变得不可用，Load Balancer会将流量路由到其他可用区正常运行的实例上去，从而避免可用区故障引起的服务中断问题。

**可扩展性的实现：**
[弹性Scaling 为Scaling组设置固定出口 IP-最佳实践-文档中心-腾讯云 (tencent.com)](https://cloud.tencent.com/document/product/377/8779)


腾讯云的Auto Scalin(AS) 是提供给用户的高效管理计算资源的策略。用户可设定时间周期性地执行管理策略或创建实时监控策略，来根据实时需求自动增加或减少云虚拟机 (CVM) 实例数量，同时完成实例的环境部署，保证业务平稳运行和最大程度的降低成本。CVM 实例数量的控制是通过Scaling组、启动配置和Scaling策略实现的。Scaling组是遵循相同规则、面向同一场景的云服务器实例的集合。Scaling组定义了组内 CVM 实例数的最大值、最小值及其相关联的负载均衡实例等属性。
弹性Scaling策略不仅能够让需求稳定规律的应用程序实现自动化管理，同时告别业务突增或 CC 攻击等带来的烦恼，对于需求不规律的应用程序，还能够根据业务负载分钟级扩展。弹性Scaling策略能够让用户的集群在任何时间都保持恰到好处的实例数量。
![[image_译图.png]]
>Scaling组方案概述，首先通过负载均衡 CLB 接收和响应外部请求。
>2. 将机器放入私有网络 VPC 的子网中，将路由表指向 NAT 网关，主动外访请求统一经 NAT 网关的外网 IP 发出。
>3. Scaling组的网络属性设为该子网，这样扩容出来的机器都会统一用 NAT 网关主动外访。


**应用程序网关：**
腾讯云的应用程序网关通过 Cloud Load Balancer 实现，Cloud Load Balancer 通过设置虚拟服务地址 VIP，将同一地域的多台云服务器虚拟成一个高性能、高可用性的应用功能服务池，根据应用指定的方式进行流量分发的服务。这可以通过基于轮询、最小连接数、最小响应时间等算法来实现。应用网关可以对流量进行管理，包括流量控制、限速、流量调度等功能，以确保Real Server不会过载，同时保障服务的稳定性和可靠性。应用网关可以提供一系列安全防护机制，包括DDoS攻击防护、WAF（Web 应用防火墙）、访问控制、SSL加密等，保障应用程序免受各种网络安全威胁的侵害。应用网关可以对请求进行访问控制，包括基于IP地址、URL、HTTP请求头等的访问控制策略，以保障系统的安全性和隐私性。应用网关可以实时监控流量和性能指标，并提供日志记录功能，帮助用户了解系统的运行状态，及时发现和解决问题。这些功能通过腾讯云的技术架构和服务平台实现，具体技术细节可能涉及到Load Balancer、网络代理、安全防护设备、流量调度算法等技术组件和算法。

## 3.2 为什么负载平衡和扩展是相辅相成的概念 ？
负载平衡和扩展是相辅相成的概念，因为它们通常在应对相同的问题时起到互补的作用，共同实现系统的高可用性和可Scaling性。首先是负载平衡帮助实现扩展的均衡性，当系统需要扩展时，负载平衡可以确保新添加的服务器能够平衡地分担负载，避免因为部分服务器负载过高而影响系统性能。对于用户的 Web 服务而言，智能的扩展和收缩是成本控制和资源管理的重要组成部分。Web 应用程序开始获得更多请求流量时，用户将添加更多的服务器来应对额外负载。同时，当 Web 应用程序的流量开始减少时，用户将终止未充分利用的服务器。其次扩展提供了负载平衡的基础：当系统需要通过增加服务器数量来满足增长的负载时，负载平衡可以确保新添加的服务器能够有效地接收流量，并且流量能够按照一定的算法进行分发，从而保证系统的整体性能。比如腾讯云的弹性Scaling AS（Auto Scaling）可以根据用户的业务需求和策略，自动调整 CVM 计算资源，确保用户拥有适量的 CVM 实例来处理用户的应用程序负载，促进负载均衡的实现。如果使用 AS 进行容量调整，用户只需事先设置好扩容条件及缩容条件。AS 会在达到条件时自动增加使用的服务器数量以维护性能；在需求下降时，AS 会根据用户的缩容条件减少服务器数量，最大限度地帮助用户降低成本。

## 3.3 客户案例：高性能计算
高性能计算（HPC）需要使用较高的带宽和计算能力的来解决复杂的科学、工程和业务问题。但HPC 解决的问题通常是项目性的，对云平台的高扩展性也有很高的需求。本案例分享了腾讯云是如何结合 load balancing, scalability 和 application gateways，利用超高计算能力（CVM）、高扩展性（AS）、大型硬盘（CBS）、对象存储（COS）的强大能力帮助企业完成 HPC 业务的。

中国深圳市某科技公司的业务面临两项挑战：首先是多组学检测的计算集群需要随时扩展上千核、数百 TB 的资源，其次是检测工作流中的计算节点环境准备繁琐，消耗人力。依托腾讯云，该客户轻可以轻松完成业务，首先通过检测设备进行多组数据的初始处理，然后在腾旭云上完成多组数据分析。其中，最需要扩展的计算集群采用如图所示的部署方式：
![[02.png]]
可以看到，将最需要海量扩展能力的 Compute Node 交给 AS，碳云实现了在分钟级别创建动辄上千核、数百 TB 的 HPC 集群。计算集群的稳定性和实时性得到极大提升，且减少了人工投入，进而极大程度地节约了成本。通过腾讯云的超高计算能力和高扩展能力，客户得以在云中运行高性能计算以改善研究速度，碳云正是以 AS 轻松解决在数千个核心和数百 TB 之间的横向扩展问题。云平台的弹性能力与腾讯云按量计费（秒级）结合，尽力为客户以最低投入获得高品质计算服务，帮助客户节约成本。



# 4 研究导致云计算扩张的主要驱动力
可扩展的云架构是通过虚拟化实现的。与资源和性能相对固定的物理机器不同，虚拟机（VM）具有高度灵活性，可以轻松地进行升级或降级。它们可以移动到不同的服务器上，或同时托管在多个服务器上；工作负载和应用程序可以根据需求转移到更大的虚拟机上。第三方云提供商还具备已经准备好的大量硬件和软件资源，使得快速扩展成为可能，而独立企业无法以经济有效的方式实现。

调查导致云计算扩展的主要驱动力【这里要看论文】

以下是推动大中小企业采用云计算机服务的主动驱动：
- **便捷管理** ：开发人员不必担心服务器的配置、维护和扩展，所有的基础设施管理工作都由云服务提供商来完成。
- **灵活性和速度** ：随着业务需求的变化和增长，包括意外需求激增，云可扩展性可以让IT快速响应。公司不再受限于过时的设备-他们可以升级系统并轻松增加功率和存储空间。如今，即使是小企业也可以使用曾经成本高昂的高性能资源。
- **节约成本** ：由于云可扩展性和按需计费策略，企业可以避免购买昂贵设备的前期成本，这些设备可能在几年后就过时了。通过云服务提供商，他们只需支付实际使用的费用，减少了资源浪费。
- **安全稳定** ：通过可扩展的云计算，您可以通过消除构建和维护二级数据中心的需要来减少灾难恢复成本。
## 4.1 Serverless functions
Serverless functions是一种云原生开发模型，允许开发人员构建和运行应用程序而无需管理服务器。Serverless架构继承了云计算的优点，并具备极致弹性、按量付费、免运维等优势。在Serverless架构下，开发者只需编写代码并上传，云平台就会自动准备好相应的计算资源，完成运算并输出结果，从而大幅简化开发运维过程。Serverless架构是云计算发展的产物，被认为是新一代的云计算发展方向，越来越多的行业及公司因其能显著地降低开发成本、按需自动扩缩容、免运维等诸多优势而采用Serverless技术。

接下来我将依据腾讯云为用户提供的 Serverless 产品进一步描述。

Serverless Cloud Function（SCF）是腾讯云为企业和开发者们提供的无服务器执行环境，帮助您在无需购买和管理服务器的情况下运行代码。您只需使用平台支持的语言编写核心代码并设置代码运行的条件，即可在腾讯云基础设施上弹性、安全地运行代码。云函数是实时文件处理和数据处理等场景下理想的计算平台。
- 特性
    - **简单易用：** 用户只需编写最重要的“核心代码”，不再需要关心周边组件，极大地降低了服务架构搭建的复杂性。无需任何手动配置，云函数即可根据请求量自动横向扩缩。不管您的应用每天的请求数处于波峰还是波谷，云函数均可自动安排合理的计算资源满足业务需求。
    - 简化管理：用户不再需要对 OS 入侵、登录风险、文件系统安全、网络安全和端口监听做复杂的配置和管理，一切交由平台处理，平台通过定制化的容器保证每个用户的隔离性。用户无需复杂的配置文件即可一键部署和测试云函数。
    - 高效：云函数不要求特定框架，开发者可专注于核心代码的开发。单个模块的开发无需了解代码细节。您可以使用云函数编写一些目的单一、逻辑独立的业务模块。每个函数都是单独运行、单独部署、单独Scaling的，用户上传代码后即可自动部署，提升了独立开发和迭代的速度。
    - 降低开销：云函数在未执行时不产生任何费用，所以对一些无需常驻的业务进程来说，开销将大幅降低。云函数执行时按请求数和计算资源的运行时间收费，价格优势明显，对初创期的开发者十分友好。
    - 稳定可靠：如果某个可用区因灾害或电力故障等导致瘫痪，云函数会自动地选择其他可用区的基础设施来运行，免除单可用区运行的故障风险。由事件触发的工作负载可以使用云函数来实现，利用不同云服务满足不同的业务场景和业务需求，使得您的服务架构更加健壮。
源访问权限的 token 认证，保证业务的安全性。

Serverless架构在腾讯云的实现中展现了许多优势，尤其是在简化开发流程、提高弹性和降低成本方面。以下是我总结的主要优势：
1. **简化开发流程**：通过Serverless Framework和Serverless Cloud Function，开发者可以专注于核心代码的编写，而无需关注底层基础设施的管理和配置。这极大地简化了开发过程，加速了应用程序的上线速度。
2. **弹性扩缩**：Serverless架构在面对业务请求峰值时能够自动进行弹性Scaling，根据需求动态分配计算资源。这意味着即使面对突发的流量增加，应用程序也能保持稳定的性能，而无需开发人员手动干预。
3. **按需付费**：Serverless模型采用按需计费的方式，只有在代码实际执行时才产生费用。这意味着开发者无需预先购买或维护基础设施，可以根据实际使用情况灵活调整成本，从而降低了开发成本。
4. **简化管理和安全性**：通过Serverless Cloud Function，用户不再需要关心底层资源的管理，包括操作系统安全、网络安全等方面。腾讯云提供的安全隔离机制保证了每个用户的数据安全和隐私保护，同时降低了管理复杂性。
5. **高效率和稳定性**：Serverless架构允许单个模块的独立部署和运行，从而提高了开发和迭代的速度。而且，云函数具有自动容错和自动选择可用区的功能，确保了服务的稳定性和可靠性。
    
总的来说，Serverless架构在腾讯云的实现为开发者提供了一种简单、高效、弹性和经济的应用部署和运行方式，适用于各种规模的应用程序，并且能够满足不同业务场景下的需求。

## 4.2 无服务器与容器化的比较

云计算的容器化和Serverless是两种不同的部署和管理应用程序的方式，它们各有优势和适用场景：
1. **部署和管理复杂度**：
    - **容器化**：在容器化中，开发人员需要负责创建、配置和管理容器，包括容器内的操作系统和运行时环境。这需要一定的专业知识和经验。
    - **无服务器**：无服务器极大地简化了部署和管理。开发人员只需上传函数代码，云提供商负责自动扩展、负载均衡和管理基础设施。无服务器模型更注重于应用逻辑而非基础设施。
2. **资源利用效率**：
    - **容器化**：容器化提供了更多的控制权，开发人员可以更精细地调整容器的资源分配。但是，这也意味着开发人员需要自行管理资源，并可能需要对应用程序进行优化以最大化资源利用率。
    - **无服务器**：无服务器模型根据需求自动扩展和收缩资源。这意味着资源利用率通常更高，因为只有在需要时才会分配资源。开发人员无需关心资源管理，可以专注于编写代码。
3. **安全性**：
    - **容器化**：容器化提供了一定程度的隔离，但容器之间仍可能存在安全漏洞。容器化环境需要定期更新和维护，以确保安全性。
    - **无服务器**：无服务器环境通常具有更高的安全性。因为每个函数都在自己的隔离环境中运行，并且无法直接访问其他函数或底层基础设施。云提供商负责管理基础设施的安全性，包括更新和维护。
4. **成本**：
    - **容器化**：容器化环境需要开发人员自行管理，可能需要投入更多的时间和资源。此外，通常需要预留或购买一定数量的虚拟机来运行容器。
    - **无服务器**：无服务器模型通常按照实际使用量收费，因此在流量低或不稳定的情况下可能更经济高效。开发人员无需关心基础设施成本，按需付费, 避免了因为服务器闲置而造成的资源浪费。
5. **适用场景**
    - 容器化适用于需要在不同环境中运行的复杂应用程序，或者需要自定义配置和管理的场景。
    - 无服务器适用于短期、间断性的任务，无需长期运行的后端任务，如 API、事件处理、数据处理等场景。
6. **启动时间：** 容器化的启动时间较长，因为需要启动整个容器；而 Serverless 的启动时间很短，因为平台会预热容器以提高响应速度。
7. **灵活性：** 容器可以快速启动和停止，可以根据负载情况自动扩展或收缩，使应用程序更具弹性。容器化允许开发人员完全控制应用程序。虽然这意味着必须手动配置系统设置，但这也意味着拥有真正的灵活性。这在 serverless 上是无法实现的，因为无服务器的所有内容都是由云提供商管理的，通常由服务商提供 Auto Scalling 机制保证应用程序的可Scaling性。





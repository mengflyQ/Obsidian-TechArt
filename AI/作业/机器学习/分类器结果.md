
# fashion
## 随机森林

| class | precision | recall | f1-score | support |
|-------|-----------|--------|----------|---------|
| 0     | 0.83      | 0.86   | 0.85     | 1000    |
| 1     | 0.99      | 0.96   | 0.98     | 1000    |
| 2     | 0.76      | 0.80   | 0.78     | 1000    |
| 3     | 0.87      | 0.91   | 0.89     | 1000    |
| 4     | 0.77      | 0.81   | 0.79     | 1000    |
| 5     | 0.98      | 0.96   | 0.97     | 1000    |
| 6     | 0.72      | 0.60   | 0.65     | 1000    |
| 7     | 0.92      | 0.95   | 0.94     | 1000    |
| 8     | 0.96      | 0.97   | 0.96     | 1000    |
| 9     | 0.96      | 0.95   | 0.95     | 1000    |
| | | | | |
| accuracy    | -   | -   | 0.88     | 10000   |
| macro avg   | 0.88| 0.88| 0.88     | 10000   |
| weighted avg| 0.88| 0.88| 0.88     | 10000   |

```
分类结果的信息
precision    recall  f1-score   support

           0       0.83      0.86      0.85      1000
           1       0.99      0.96      0.98      1000
           2       0.76      0.80      0.78      1000
           3       0.87      0.91      0.89      1000
           4       0.77      0.81      0.79      1000
           5       0.98      0.96      0.97      1000
           6       0.72      0.60      0.65      1000
           7       0.92      0.95      0.94      1000
           8       0.96      0.97      0.96      1000
           9       0.96      0.95      0.95      1000

    accuracy                           0.88     10000
    macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000

混淆矩阵
[[[8822  178]
  [ 138  862]]

 [[8994    6]
  [  36  964]]

 [[8751  249]
  [ 201  799]]

 [[8868  132]
  [  93  907]]

 [[8758  242]
  [ 187  813]]

 [[8977   23]
  [  43  957]]

 [[8769  231]
  [ 401  599]]

 [[8922   78]
  [  46  954]]

 [[8957   43]
  [  29  971]]

 [[8956   44]
  [  52  948]]]
```

首先，让我们解释表格中的各项指标：

1. Accuracy 表示分类正确的样本占总样本个数的比例，为0.88，说明整体分类效果较好。
2. Precision 表示预测结果为正例的样本中实际为正样本的比例。例如，在类别0中，有83%的样本被正确分类为类别0。精确度的平均值为0.88，加权平均也为0.88。说明模型对负样本的区分能力较强。
3. Recall 是精确率和召回率的一个加权平均，体现了模型对负样本的区分能力。例如，在类别0中，有86%的正类别样本被正确预测为类别0。召回率的平均值为0.88。说明模型对正样本的识别能力较强。
4. F1-score 是精确度和召回率的调和平均值，综合考虑了模型的全面性和准确性。加权平均 F1分数为0.88。说明模型比较稳健
5. Macro average 是指在计算均值时使每个类别具有相同的权重，最后结果是每个类别的指标的算术平均值。
6. Micro average 是指计算多分类指标时赋予所有类别的每个样本相同的权重，将所有样本合在一起计算各个指标。
7. Macro average 和 Micro average 相等，说明每个类别对整体性能的贡献基本相同，模型具有较为均衡的分类能力。

接下来，让我们分析混淆矩阵：

混淆矩阵反映了模型在每个类别上的具体表现。例如，在类别0中，有8822个样本被正确分类为类别0，但有178个样本被错误分类为其他类别。同样，在类别0中，有138个样本被错误分类为类别1，有862个样本被正确分类为类别0。

**评价结果分析：**

- 类别6的精确度较低，可能是由于该类别在混淆矩阵中有较多的误分类，即将一部分属于类别6的样本错误地分类为其他类别，导致该类别的精确度下降。

总体而言，模型在Fashion-MNIST数据集上的分类效果较好，各项指标均较高，但仍需关注混淆矩阵中可能存在的误分类情况，特别是在某些类别上的性能。
## KNN

|class| precision | recall | f1-score | support |
|-------|-----------|--------|----------|---------|
| 0     | 0.77      | 0.85   | 0.81     | 1000    |
| 1     | 0.99      | 0.97   | 0.98     | 1000    |
| 2     | 0.73      | 0.82   | 0.77     | 1000    |
| 3     | 0.90      | 0.86   | 0.88     | 1000    |
| 4     | 0.79      | 0.77   | 0.78     | 1000    |
| 5     | 0.99      | 0.82   | 0.90     | 1000    |
| 6     | 0.66      | 0.57   | 0.61     | 1000    |
| 7     | 0.88      | 0.96   | 0.92     | 1000    |
| 8     | 0.97      | 0.95   | 0.96     | 1000    |
| 9     | 0.90      | 0.97   | 0.93     | 1000    |
||||||
| accuracy    | -   | -   | 0.86     | 10000   |
| macro avg   | 0.86| 0.86| 0.85     | 10000   |
|weighted avg| 0.86| 0.86| 0.85     |10000|

```
+------------+-----------+--------+----------+--------+
| class | precision | recall | f1-score | support|
+------------+-----------+--------+----------+--------+
| 0 | 0.77 | 0.85 | 0.81 | 1000 |
| 1 | 0.99 | 0.97 | 0.98 | 1000 |
| 2 | 0.73 | 0.82 | 0.77 | 1000 |
| 3 | 0.90 | 0.86 | 0.88 | 1000 |
| 4 | 0.79 | 0.77 | 0.78 | 1000 |
| 5 | 0.99 | 0.82 | 0.90 | 1000 |
| 6 | 0.66 | 0.57 | 0.61 | 1000 |
| 7 | 0.88 | 0.96 | 0.92 | 1000 |
| 8 | 0.97 | 0.95 | 0.96 | 1000 |
| 9 | 0.90 | 0.97 | 0.93 | 1000 |
+------------+-----------+--------+----------+--------+
| accuracy | - | - | 0.86 | 10000 |
| macro avg | 0.86 | 0.86 | 0.85 | 10000 |
| weighted avg| 0.86 | 0.86 | 0.85 | 10000 |
+------------+-----------+--------+----------+--------+
```

```
分类结果的信息:
              precision    recall  f1-score   support

           0       0.77      0.85      0.81      1000
           1       0.99      0.97      0.98      1000
           2       0.73      0.82      0.77      1000
           3       0.90      0.86      0.88      1000
           4       0.79      0.77      0.78      1000
           5       0.99      0.82      0.90      1000
           6       0.66      0.57      0.61      1000
           7       0.88      0.96      0.92      1000
           8       0.97      0.95      0.96      1000
           9       0.90      0.97      0.93      1000

    accuracy                           0.86     10000
   macro avg       0.86      0.86      0.85     10000
weighted avg       0.86      0.86      0.85     10000

混淆矩阵:
[[[8746  254]
  [ 145  855]]

 [[8987   13]
  [  32  968]]

 [[8696  304]
  [ 181  819]]

 [[8908   92]
  [ 140  860]]

 [[8792  208]
  [ 227  773]]

 [[8994    6]
  [ 178  822]]

 [[8701  299]
  [ 425  575]]

 [[8867  133]
  [  39  961]]

 [[8975   25]
  [  47  953]]

 [[8888  112]
  [  32  968]]]
```

解释表格中的各项指标：
1. Accuracy 为0.86，说明整体分类效果相对较好。
2. Precision 的平均值为0.86，加权平均也为0.86。说明模型对负样本的区分能力较强。
3. Recall 的平均值为0.86。说明模型对正样本的识别能力较强。
4. F1-score 为0.85。说明模型比较稳健
5. Macro average 和 Micro average 相等，说明每个类别对整体性能的贡献基本相同，模型具有较为均衡的分类能力。

分析混淆矩阵：
混淆矩阵反映了模型在每个类别上的具体表现。例如，在类别0中，有8746个样本被正确分类为类别0，但有254个样本被错误分类为其他类别。同样，在类别0中，有145个样本被错误分类为类别1，有855个样本被正确分类为类别0。

评价结果分析：
类别6的精确度相对较低，为0.66。这可能是因为该类别的样本在数据集中分布较为分散，或者与其他类别存在较大的相似性，导致模型难以准确分类。总体而言，模型在 Fashion-MNIST 数据集上表现良好，但仍需要关注类别6的性能并考虑进一步优化。

# cifar10
## 随机森林

| class | precision | recall | f1-score | support |
|-------|-----------|--------|----------|---------|
| 0     | 0.54      | 0.56   | 0.55     | 1000    |
| 1     | 0.52      | 0.53   | 0.52     | 1000    |
| 2     | 0.36      | 0.33   | 0.35     | 1000    |
| 3     | 0.33      | 0.27   | 0.30     | 1000    |
| 4     | 0.39      | 0.38   | 0.38     | 1000    |
| 5     | 0.40      | 0.39   | 0.39     | 1000    |
| 6     | 0.47      | 0.56   | 0.51     | 1000    |
| 7     | 0.51      | 0.45   | 0.48     | 1000    |
| 8     | 0.59      | 0.62   | 0.60     | 1000    |
| 9     | 0.47      | 0.55   | 0.51     | 1000    |
||||||
| accuracy    | -   | -   | 0.46     | 10000   |
| macro avg   | 0.46| 0.46| 0.46     | 10000   |
| weighted avg| 0.46| 0.46| 0.46     | 10000   |

```
................. 打印分类结果的信息.............
              precision    recall  f1-score   support

           0       0.54      0.56      0.55      1000
           1       0.52      0.53      0.52      1000
           2       0.36      0.33      0.35      1000
           3       0.33      0.27      0.30      1000
           4       0.39      0.38      0.38      1000
           5       0.40      0.39      0.39      1000
           6       0.47      0.56      0.51      1000
           7       0.51      0.45      0.48      1000
           8       0.59      0.62      0.60      1000
           9       0.47      0.55      0.51      1000

    accuracy                           0.46     10000
    macro avg       0.46      0.46      0.46     10000
weighted avg       0.46      0.46      0.46     10000

...................... 打印混淆矩阵................
[[[8529  471]
  [ 438  562]]

 [[8513  487]
  [ 475  525]]

 [[8415  585]
  [ 666  334]]

 [[8460  540]
  [ 733  267]]

 [[8400  600]
  [ 622  378]]

 [[8421  579]
  [ 614  386]]

 [[8367  633]
  [ 435  565]]

 [[8567  433]
  [ 547  453]]

 [[8573  427]
  [ 382  618]]

 [[8391  609]
  [ 452  548]]]
```

首先，让我们解释表格中的各项指标：
1. Accuracy为0.46，说明整体分类效果一般。
2. Precision 精确度的平均值为0.46，加权平均也为0.46，说明模型对负样本的区分能力一般。
3. Recall 的平均值为0.46。说明模型对正样本的识别能力一般。
4. F1-score 的加权平均为0.46，说明模型不太稳健
5. Macro average 和 Micro average 相等，说明每个类别对整体性能的贡献基本相同，模型具有较为均衡的分类能力。

接下来，让我们分析混淆矩阵：

混淆矩阵反映了模型在每个类别上的具体表现。例如，在类别0中，有8529个样本被正确分类为类别0，但有471个样本被错误分类为其他类别。同样，在类别0中，有438个样本被错误分类为类别1，有562个样本被正确分类为类别0。

**评价结果分析：**

- 类别2、3、4、5、6、7、9的精确度较低，可能是因为这些类别的样本在数据集中分布较为分散或者类别之间的特征差异较小，导致模型难以准确分类。
- 类别3、4、5、6、7的召回率较低，说明模型在这些类别中漏检了很多正样本。可能是因为这些类别的样本特征与其他类别相似，使得模型难以正确识别。
    
总体而言，模型在 cifar10数据集上的分类效果较一般，可能需要进一步优化模型结构或调整参数以提高性能。

## KNN

| class | precision | recall | f1-score | support |
|-------|-----------|--------|----------|---------|
| 0     | 0.38      | 0.54   | 0.45     | 1000    |
| 1     | 0.65      | 0.20   | 0.31     | 1000    |
| 2     | 0.23      | 0.45   | 0.30     | 1000    |
| 3     | 0.29      | 0.22   | 0.25     | 1000    |
| 4     | 0.24      | 0.51   | 0.33     | 1000    |
| 5     | 0.39      | 0.22   | 0.28     | 1000    |
| 6     | 0.35      | 0.25   | 0.29     | 1000    |
| 7     | 0.68      | 0.21   | 0.32     | 1000    |
| 8     | 0.40      | 0.66   | 0.50     | 1000    |
| 9     | 0.70      | 0.14   | 0.23     | 1000    |
||||||
| accuracy    | -   | -   | 0.34     | 10000   |
| macro avg   | 0.43| 0.34| 0.33     | 10000   |
| weighted avg| 0.43| 0.34| 0.33     | 10000   |

```
.................打印分类结果的信息.............
              precision    recall  f1-score   support

           0       0.38      0.54      0.45      1000
           1       0.65      0.20      0.31      1000
           2       0.23      0.45      0.30      1000
           3       0.29      0.22      0.25      1000
           4       0.24      0.51      0.33      1000
           5       0.39      0.22      0.28      1000
           6       0.35      0.25      0.29      1000
           7       0.68      0.21      0.32      1000
           8       0.40      0.66      0.50      1000
           9       0.70      0.14      0.23      1000

    accuracy                           0.34     10000
   macro avg       0.43      0.34      0.33     10000
weighted avg       0.43      0.34      0.33     10000

......................打印混淆矩阵................
[[[8135  865]
  [ 463  537]]

 [[8888  112]
  [ 795  205]]

 [[7446 1554]
  [ 548  452]]

 [[8479  521]
  [ 783  217]]

 [[7408 1592]
  [ 486  514]]

 [[8659  341]
  [ 780  220]]

 [[8532  468]
  [ 752  248]]

 [[8900  100]
  [ 790  210]]

 [[8012  988]
  [ 345  655]]

 [[8939   61]
  [ 860  140]]]
```

首先，让我们解释表格中的各项指标：
1. **Accuracy为0.34，说明整体分类效果一般。
2. recision 的平均值为0.43，加权平均也为0.43，说明模型对负样本的区分能力一般。
3. Recall 召回率的平均值为0.34，说明模型对正样本的识别能力较弱。
4. F1-score 的加权平均为0.33，模型说明模型不够稳健
5. Macro average 和 Micro average 相等，说明每个类别对整体性能的贡献基本相同，模型具有较为均衡的分类能力。

**分析混淆矩阵：**
混淆矩阵反映了模型在每个类别上的具体表现。例如，在类别0中，有8135个样本被正确分类为类别0，但有865个样本被错误分类为其他类别。同样，在类别0中，有463个样本被错误分类为类别1，有537个样本被正确分类为类别0。

**评价结果分析：**
- 类别1、2、3、5、6、8、9的精确度较低，可能是因为这些类别的样本在数据集中分布较为分散或者类别之间的特征差异较小，导致模型难以准确分类。
- 类别1、5、8、9的召回率较低，说明模型在这些类别中漏检了很多正样本。可能是因为这些类别的样本特征与其他类别相似，使得模型难以正确识别。

总体而言，模型在 cifar10数据集上的分类效果较一般，可能需要进一步优化模型结构或调整参数以提高性能。

# 使用随机森林方法进行分类有以下合理性：

1. **高准确性：** 随机森林是一种集成学习方法，通过组合多个决策树的预测结果，可以提高整体模型的准确性。每个决策树都是基学习器，通过投票或平均的方式来进行分类，减少了过拟合的风险。
    
2. **对特征的自适应性：** 随机森林对于特征的选择具有自适应性，它会在每个决策树的训练过程中随机选择一部分特征进行划分。这有助于减少特征之间的相关性，提高模型的泛化能力，避免过度依赖某些特征。
    
3. **处理大规模数据：** 随机森林通常对大规模数据表现良好，因为可以并行训练多个决策树。这有助于加速模型的训练过程，使得随机森林在大规模数据集上具有可扩展性。
    
4. **能够处理高维数据：** 随机森林在高维数据上的表现相对较好，不容易受到维度灾难的影响。通过随机选择特征，可以降低维度的复杂性，提高模型的鲁棒性。
    
5. **抗过拟合能力：** 随机森林通过引入随机性，包括随机选择样本和随机选择特征，减缓了过拟合的风险。这使得模型更具泛化能力，对新数据的适应性较好。
    
6. **提供特征重要性评估：** 随机森林可以输出各个特征的重要性，帮助理解模型对问题的解释，有助于特征选择和模型解释。
    

总体而言，随机森林是一种强大的分类方法，适用于各种问题，并在许多实际场景中表现出色。
# 描述选择使用 KNN 方法的合理性
选择使用 KNN（K-最近邻）方法的合理性可以从以下几个方面考虑：

1. **简单实现：** KNN是一种非常简单直观的分类算法。它不需要训练阶段，而是在预测时直接根据最近邻的样本进行分类。这种简单性使得KNN易于理解和实现。
    
2. **无参数：** KNN是一种无参数的算法，不需要对模型进行复杂的参数调整。这使得在处理一些复杂的问题时，不需要过多的领域知识，而且可以更加灵活地应用在不同类型的数据上。
    
3. **适用于小规模数据集：** 如果数据集相对较小，KNN可以是一个合适的选择。由于KNN算法在训练时不需要构建模型，而是在预测时计算距离，因此对于小规模数据集而言，计算成本相对较低。
    
4. **适用于局部性较强的问题：** KNN的核心思想是利用邻近样本的信息进行分类，因此适用于局部性较强的问题。如果数据在特征空间中有较好的聚集性，KNN可能能够取得不错的效果。
    
5. **不受数据分布影响：** KNN对于数据的分布没有过多的假设，适用于各种类型的数据分布情况。这使得它在处理一些复杂的、非线性的问题时表现较为出色。
    

然而，需要注意的是，KNN也有一些缺点，例如对于大规模数据集的计算成本较高，对噪声和异常值敏感等。在实际应用中，需要根据具体问题和数据的特点来综合考虑是否选择KNN算法。

报告写法：[构建报告 - 报告写作 - LibGuides at University of Reading](https://libguides.reading.ac.uk/reports/structuring)
# 使用ML算法和方法进行分类
# 目录
# 1 Abstract

Keywords:
# 2 Introduction

机器学习是人工智能的一个重要分支，它的目标是开发和应用算法，使计算机可以从数据中学习并做出预测或决策。机器学习中的分类问题是一类常见的监督学习任务，其主要目标是根据给定的输入数据，将其划分到不同的类别中。在分类问题中，算法通过学习输入数据与其对应的标签之间的关系，从而能够对新的、未标记的数据进行分类。分类问题在实际应用中非常广泛，涉及到图像识别、自然语言处理、医学诊断、金融欺诈检测等多个领域。通过不断改进算法和优化模型参数，研究者们致力于提高分类模型的性能和适应性。

在众多的分类算法中，随机森林和K近邻（KNN）算法是两种广泛使用的方法。随机森林是一种集成学习方法，它通过构建并结合多个决策树来做出预测。KNN算法则是一种基于实例的学习方法，它根据输入数据在特征空间中的邻近样本的类别来做出预测。 

本报告的目标是使用随机森林和 KNN 分类器对 Fashion MNIST 和 CIFAR-10数据集进行分类并评估。我们将首先对数据进行预处理，然后使用随机森林和 KNN 分类器进行模型训练，最后使用和分类报告和混淆矩阵来评估模型的性能。

本文的结构如下︰第三章介绍了利用随机森林和 KNN 进行分类的相关工作。第四章是主体部分，将对数据集和分类器的选择进行解释。第五章首先解释了机器学习管道，然后展示了我们获得的结果，并对每种情况分别进行了讨论。最后，我们以结论和参考文献结束本文。附录为实验使用的代码。

# 3 Related work

本节总结了利用随机森林和KNN进行分类的相关工作。
Komarasamy. G 等人使用随机森林算法进行社交媒体情感分类，与其他方法相比，和谐梯度提升随机森林机器学习技术产生了更好的结果。

Wolffang等人使用机器学习算法来描述和提取西红柿图像颜色统计的特征，对 KNN，MLP 等算法进行了全方位的评估。他发现用于番茄颜色分类的 K-NN 算法与 MLP 神经网络方法相结合，可以获得最佳性能。
Roger Singh Chugh等人使用经典机器学习算法（（KNN）、（MLP）和随机森林分类器（RF）对数据集的准确率、时间复杂度、F1分数、召回率和精确度等参数进行了对比分析。结果表明，MLP 的准确率最高。

Ying Li 和 Bo Cheng 借鉴裁剪 KNN 的思想，采用改进的 KNN 分类算法，并将其应用于高分辨率遥感影像的面向对象分类。发现改进的 KNN 算法在高分辨率遥感影像分类中可以达到更高的精度。
Osim Kumar Pal基于KNN和随机森林算法进行设计。患者可以使用该模型将他的皮肤病归类为主要检测，医生也可以通过使用该模型来确保他的判断。
Anna Bosch 等人将随机森林/Ferns 分类器的性能与基准多向 SVM 分类器进行了比较，提供了一种抑制背景杂波和增加对象实例位置不变性的方法，提出的模型性能比现有技术提高了约 10%。

Krithika 和 Selvarani 在他们的工作中使用 K 最近邻分类来对葡萄叶病进行分类并识别叶骨架。使用葡萄图像识别叶子骨架。他们发现通过使用 KNN 分类可以有效地对葡萄叶部病害进行分类。


# 4 Main body
## 4.1 Machine learning pipeline
解释机器学习管线，（代码解释？）

机器学习中，一般将数据分为**训练数据**和**测试数据**两部分来进行学习和实验等。
- 首先，使用训练数据进行学习，寻找最优的参数。
- 然后，使用测试数据评价训练得到的模型的实际能力。

 求解机器学习问题的步骤可以分为“学习（也称为训练）” 和“推理”两个阶段。
> 
> 首先，在学习阶段进行模型的学习，然后，在推理阶段，用学到的模型对未知的数据进行推理（分类）。如前所述，**推理阶段一般会省略输出层的 softmax 函数。** 

## 4.2 Dataset
### 4.2.1 Fashion-MNIST
本研究采用了时尚-MNIST 数据集。该数据集包括一个由60,000张样本图像组成的训练集和一个由10,000张灰度样本图像组成的测试集。数据集中的每幅图像分辨率为28x28像素。每张训练和测试图像都属于10个类别之一，包括 "T-Shirt/Top","Trouser","Pullover","Dress","Coat","Sandals","Shirt","Sneaker","Bag","Ankle boots"。每个类别有6000张样本图像。每一行都是单独的图像，第1列是类别标签，其余各列是像素编号（共784个)。

able x: Class names and example images in Fashion-MNIST dataset.
![[Pasted image 20231125140247.png]]

### 4.2.2 CIFAR-10
CIFAR-10 是一个彩色图片数据集，它有 10 个类别: "airplane", "automobile", "bird", "cat","deer", "dog", "frog", "horse", "ship", "truck"。每张图片都是  3 * 32 * 32 ，也即 3 通道（RGB）彩色图片，分辨率为 32 * 32。

该数据集共有 60000 张彩色图像，这些图像是 32 * 32，分为 10 个类，每类 6000 张图。这里面有 50000 张用于训练，构成了 5 个训练批，每一批 10000 张图；另外 10000 用于测试，单独构成一批。测试批的数据里，取自 10 类中的每一类，每一类随机取 1000 张。抽剩下的就随机排列组成了训练批。注意一个训练批中的各类图像并不一定数量相同，总的来看训练批，每一类都有 5000 张图。

Here are the classes in the dataset, as well as 10 random images from each:[CIFAR-10 and CIFAR-100 datasets (toronto.edu)](https://www.cs.toronto.edu/~kriz/cifar.html)
![[Pasted image 20231125140355.png]]
## 4.3 Data loading and pre-processing

图像分类中的预处理是一个对图像进行转换以准备分类的过程。这些步骤包括导入必要的库，然后从文件夹中检索图像。然后调整图像大小并转换为 NumPy 数组。然后将数组分割为训练数据和测试数据。

## 4.4 Classifier Introduction

### 4.4.1 Random forest


Random Forest是一种集成学习方法，它通过构建多个决策树并将它们整合在一起来进行分类或回归任务。随机森林是由Leo Breiman在2001年提出的（Breiman L, 2001a.Random forests.Mach.Learn., 45:5-32.），它在机器学习中被广泛应用，因为它具有良好的性能和鲁棒性。随机森林由多个决策树组成。每个决策树都是一个分类器，通过对输入数据进行逐层的判定，最终输出属于哪个类别。随机森林在构建每棵决策树时引入了随机性。对于分类任务，随机森林采用投票机制进行决策。每棵决策树对输入数据进行分类，最终的分类结果是获得最多投票的类别。随机森林通过组合多个决策树的预测结果，减小了过拟合的风险，提高了模型的鲁棒性和泛化能力。它对于处理高维数据和大规模数据集都表现出色。

随机森林中的树按以下规则生成：
1. 如果训练集大小为 N，对于每棵树而言，随机且有放回地从训练集中的抽取 N 个训练样本（这种采样方式称为 bootstrap sample 方法, 为拔靴法采样），作为该树的训练集；从这里我们可以知道：每棵树的训练集都是不同的，而且里面包含重复的训练样本。
2. 如果存在 M 个特征维度，则指定数量 m << M，使得在每个节点处，从 M 中随机选择 m 个特征维度，并且使用这些 m 个特征维度中最佳特征(最大化 information gain)来分割节点。在森林生长期间，m 的值保持不变。
3. 每棵树都尽最大程度的生长，并且没有剪枝过程。

###  4.3.2 KNN

使用KNN算法应用图像分类。在模式确认中，KNN算法是一种用于分类和回归的非参数方法。输出基于KNN是用于排序还是回归：在KNN分类中，最后一个输出是周期附属。一个对象是通过其邻居的极端投票来分类的，被分配到其k个最近邻居中最常见的类的对象，其中k是正整数，通常很小。如果k＝1，则该对象仅被选择为唯一一个最近邻居的类。在KNN回归中，最后一个乘积是对象的属性值。该特定值是其k个最近邻居的正常值。KNN是一种基于发生率的学习，或缓慢的实现，其中体积与近处相似，所有计算都被允许，直到顺序。KNN计算是所有机器学习计算中最直接的计算之一。KNN分类器的执行基本上由K的决定以及所连接的分离度量来决定。该度量受到区域度量K的确定的可影响性的影响，理由是附近区域的扫描是由与问题的第K个最近邻居的分离决定的，并且不同的K产生不同的限制性类概率。在K很小的情况下，由于信息匮乏的条件和喧闹、模糊或错误标记的焦点，附近的量规通常会非常差。最终目标是进一步平滑度量，我们可以构建K，并围绕这个问题考虑一个实质性的区域设置。令人震惊的是，对K的广泛估计有效地使规范过度平滑，并且排列执行随着不同类别异常的出现而降低。为了解决这一问题，已经进行了相关的研究工作，以提高KNN的安排执行力。(https://ieeexplore.ieee.org/document/9058042)

KNN（k近邻算法）的步骤:
1.      计算测试数据与各个训练数据之间的距离
2.      按照升序（从小到大）对距离（欧氏距离）进行排序
3.      选取距离最小的前k个点
4.      确定前k个点所在类别出现的频率
5.      返回前k个点中出现频率最高的类别作为测试数据的分类

## 4.4 分类器选择的合理性
### 4.4.1 随机森林

(1) 高准确性： 随机森林是一种集成学习方法，通过组合多个决策树的预测结果，可以提高整体模型的准确性。每个决策树都是基学习器，通过投票或平均的方式来进行分类，减少了过拟合的风险。
(2) 对特征的自适应性： 随机森林对于特征的选择具有自适应性，它会在每个决策树的训练过程中随机选择一部分特征进行划分。这有助于减少特征之间的相关性，提高模型的泛化能力，避免过度依赖某些特征。
(3) 处理大规模数据： 随机森林通常对大规模数据表现良好，因为可以并行训练多个决策树。这有助于加速模型的训练过程，使得随机森林在大规模数据集上具有可扩展性。
(4) 能够处理高维数据： 随机森林在高维数据上的表现相对较好，不容易受到维度灾难的影响。通过随机选择特征，可以降低维度的复杂性，提高模型的鲁棒性。
(5) 抗过拟合能力：随机森林通过引入随机性，包括随机选择样本和随机选择特征，减缓了过拟合的风险。这使得模型更具泛化能力，对新数据的适应性较好。
(6) 提供特征重要性评估： 随机森林可以输出各个特征的重要性，帮助理解模型对问题的解释，有助于特征选择和模型解释。

总体而言，随机森林是一种强大的分类方法，适用于各种问题，并在许多实际场景中表现出色。
### 4.1.2 KNN 
选择使用 KNN（K-最近邻）方法的合理性可以从以下几个方面考虑：

1. 简单实现： KNN 是一种非常简单直观的分类算法。它不需要训练阶段，而是在预测时直接根据最近邻的样本进行分类。这种简单性使得 KNN 易于理解和实现。
2. 无参数： KNN 是一种无参数的算法，不需要对模型进行复杂的参数调整。这使得在处理一些复杂的问题时，不需要过多的领域知识，而且可以更加灵活地应用在不同类型的数据上。
3. 适用于小规模数据集： 如果数据集相对较小，KNN 可以是一个合适的选择。由于 KNN 算法在训练时不需要构建模型，而是在预测时计算距离，因此对于小规模数据集而言，计算成本相对较低。
4. 适用于局部性较强的问题： KNN 的核心思想是利用邻近样本的信息进行分类，因此适用于局部性较强的问题。如果数据在特征空间中有较好的聚集性，KNN 可能能够取得不错的效果。
5. 不受数据分布影响： KNN 对于数据的分布没有过多的假设，适用于各种类型的数据分布情况。这使得它在处理一些复杂的、非线性的问题时表现较为出色。

然而，需要注意的是，KNN 也有一些缺点，例如对于大规模数据集的计算成本较高，对噪声和异常值敏感等。在实际应用中，需要根据具体问题和数据的特点来综合考虑是否选择 KNN 算法。
# 5 Results and discussion
以下将对两种数据集分别使用两种分类算法的结果进行分析与讨论
## 5.1 Fashion-MNIST
### 5.1.1 随机森林
#### 5.1.1.1 分类结果
分类结果信息表格：

|class| precision | recall | f1-score | support |
|-------|-----------|--------|----------|---------|
| 0     | 0.83      | 0.86   | 0.85     | 1000    |
| 1     | 0.99      | 0.96   | 0.98     | 1000    |
| 2     | 0.76      | 0.80   | 0.78     | 1000    |
| 3     | 0.87      | 0.91   | 0.89     | 1000    |
| 4     | 0.77      | 0.81   | 0.79     | 1000    |
| 5     | 0.98      | 0.96   | 0.97     | 1000    |
| 6     | 0.72      | 0.60   | 0.65     | 1000    |
| 7     | 0.92      | 0.95   | 0.94     | 1000    |
| 8     | 0.96      | 0.97   | 0.96     | 1000    |
| 9     | 0.96      | 0.95   | 0.95     | 1000    |
| | | | | |
| accuracy    | -   | -   | 0.88     | 10000   |
| macro avg   | 0.88| 0.88| 0.88     | 10000   |
|weighted avg| 0.88| 0.88| 0.88     |10000|

混淆矩阵
```
[[[8822  178]
  [ 138  862]]

 [[8994    6]
  [  36  964]]

 [[8751  249]
  [ 201  799]]

 [[8868  132]
  [  93  907]]

 [[8758  242]
  [ 187  813]]

 [[8977   23]
  [  43  957]]

 [[8769  231]
  [ 401  599]]

 [[8922   78]
  [  46  954]]

 [[8957   43]
  [  29  971]]

 [[8956   44]
  [  52  948]]]
```

#### 5.1.1.2 结果分析
(1) Accuracy 表示分类正确的样本占总样本个数的比例，为 0.88，说明整体分类效果较好。
(2) Precision 表示预测结果为正例的样本中实际为正样本的比例。例如，在类别 0 中，有 83%的样本被正确分类为类别 0。精确度的平均值为 0.88，加权平均也为 0.88。说明模型对负样本的区分能力较强。
(3) Recall 是精确率和召回率的一个加权平均，体现了模型对负样本的区分能力。例如，在类别 0 中，有 86%的正类别样本被正确预测为类别 0。召回率的平均值为 0.88。说明模型对正样本的识别能力较强。
(4) F1-score 是精确度和召回率的调和平均值，综合考虑了模型的全面性和准确性。加权平均 F1 分数为 0.88。说明模型比较稳健
(5) Macro average 是指在计算均值时使每个类别具有相同的权重，最后结果是每个类别的指标的算术平均值。
(6) Micro average 是指计算多分类指标时赋予所有类别的每个样本相同的权重，将所有样本合在一起计算各个指标。
(7) Macro average 和 Micro average 相等，说明每个类别对整体性能的贡献基本相同，模型具有较为均衡的分类能力。

混淆矩阵反映了模型在每个类别上的具体表现。例如，在类别 0 中，有 8822 个样本被正确分类为类别 0，但有 178 个样本被错误分类为其他类别。同样，在类别 0 中，有 138 个样本被错误分类为类别 1，有 862 个样本被正确分类为类别 0。

类别 6 的精确度较低，可能是由于该类别在混淆矩阵中有较多的误分类，即将一部分属于类别 6 的样本错误地分类为其他类别，导致该类别的精确度下降。

总体而言，模型在 Fashion-MNIST 数据集上的分类效果较好，各项指标均较高，但仍需关注混淆矩阵中可能存在的误分类情况，特别是在某些类别上的性能。
### 5.1.2 KNN
#### 5.1.2.1 分类结果
分类结果信息表格：

|class| precision | recall | f1-score | support |
|-------|-----------|--------|----------|---------|
| 0     | 0.77      | 0.85   | 0.81     | 1000    |
| 1     | 0.99      | 0.97   | 0.98     | 1000    |
| 2     | 0.73      | 0.82   | 0.77     | 1000    |
| 3     | 0.90      | 0.86   | 0.88     | 1000    |
| 4     | 0.79      | 0.77   | 0.78     | 1000    |
| 5     | 0.99      | 0.82   | 0.90     | 1000    |
| 6     | 0.66      | 0.57   | 0.61     | 1000    |
| 7     | 0.88      | 0.96   | 0.92     | 1000    |
| 8     | 0.97      | 0.95   | 0.96     | 1000    |
| 9     | 0.90      | 0.97   | 0.93     | 1000    |
||||||
| accuracy    | -   | -   | 0.86     | 10000   |
| macro avg   | 0.86| 0.86| 0.85     | 10000   |
|weighted avg| 0.86| 0.86| 0.85     |10000|

混淆矩阵
```
[[[8746  254]
  [ 145  855]]

 [[8987   13]
  [  32  968]]

 [[8696  304]
  [ 181  819]]

 [[8908   92]
  [ 140  860]]

 [[8792  208]
  [ 227  773]]

 [[8994    6]
  [ 178  822]]

 [[8701  299]
  [ 425  575]]

 [[8867  133]
  [  39  961]]

 [[8975   25]
  [  47  953]]

 [[8888  112]
  [  32  968]]]
```

#### 5.1.2.2 结果分析
(1) Accuracy 为 0.86，说明整体分类效果相对较好。
(2) Precision 的平均值为 0.86，加权平均也为 0.86。说明模型对负样本的区分能力较强。
(3) Recall 的平均值为 0.86。说明模型对正样本的识别能力较强。
(4) F1-score 为 0.85。说明模型比较稳健
(5) Macro average 和 Micro average 相等，说明每个类别对整体性能的贡献基本相同，模型具有较为均衡的分类能力。

混淆矩阵反映了模型在每个类别上的具体表现。例如，在类别 0 中，有 8746 个样本被正确分类为类别 0，但有 254 个样本被错误分类为其他类别。同样，在类别 0 中，有 145 个样本被错误分类为类别 1，有 855 个样本被正确分类为类别 0。

类别 6 的精确度相对较低，为 0.66。这可能是因为该类别的样本在数据集中分布较为分散，或者与其他类别存在较大的相似性，导致模型难以准确分类。总体而言，模型在 Fashion-MNIST 数据集上表现良好，但仍需要关注类别 6 的性能并考虑进一步优化。

## 5.2 CIFAR-10

### 5.2.1 随机森林
#### 5.2.1.1 分类结果
分类结果信息表格：

| class | precision | recall | f1-score | support |
|-------|-----------|--------|----------|---------|
| 0     | 0.54      | 0.56   | 0.55     | 1000    |
| 1     | 0.52      | 0.53   | 0.52     | 1000    |
| 2     | 0.36      | 0.33   | 0.35     | 1000    |
| 3     | 0.33      | 0.27   | 0.30     | 1000    |
| 4     | 0.39      | 0.38   | 0.38     | 1000    |
| 5     | 0.40      | 0.39   | 0.39     | 1000    |
| 6     | 0.47      | 0.56   | 0.51     | 1000    |
| 7     | 0.51      | 0.45   | 0.48     | 1000    |
| 8     | 0.59      | 0.62   | 0.60     | 1000    |
| 9     | 0.47      | 0.55   | 0.51     | 1000    |
||||||
| accuracy    | -   | -   | 0.46     | 10000   |
| macro avg   | 0.46| 0.46| 0.46     | 10000   |
| weighted avg| 0.46| 0.46| 0.46     | 10000   |

混淆矩阵：
```
[[[8529  471]
  [ 438  562]]

 [[8513  487]
  [ 475  525]]

 [[8415  585]
  [ 666  334]]

 [[8460  540]
  [ 733  267]]

 [[8400  600]
  [ 622  378]]

 [[8421  579]
  [ 614  386]]

 [[8367  633]
  [ 435  565]]

 [[8567  433]
  [ 547  453]]

 [[8573  427]
  [ 382  618]]

 [[8391  609]
  [ 452  548]]]
```

#### 5.2.1.2 结果分析
(1) Accuracy 为 0.46，说明整体分类效果一般。
(2) Precision 精确度的平均值为 0.46，加权平均也为 0.46，说明模型对负样本的区分能力一般。
(3) Recall 的平均值为 0.46。说明模型对正样本的识别能力一般。
(4) F1-score 的加权平均为 0.46，说明模型不太稳健
(5) Macro average 和 Micro average 相等，说明每个类别对整体性能的贡献基本相同，模型具有较为均衡的分类能力。

混淆矩阵反映了模型在每个类别上的具体表现。例如，在类别 0 中，有 8529 个样本被正确分类为类别 0，但有 471 个样本被错误分类为其他类别。同样，在类别 0 中，有 438 个样本被错误分类为类别 1，有 562 个样本被正确分类为类别 0。

类别 2、3、4、5、6、7、9 的精确度较低，可能是因为这些类别的样本在数据集中分布较为分散或者类别之间的特征差异较小，导致模型难以准确分类。

类别 3、4、5、6、7 的召回率较低，说明模型在这些类别中漏检了很多正样本。可能是因为这些类别的样本特征与其他类别相似，使得模型难以正确识别。

总体而言，模型在 CIFAR-10 数据集上的分类效果较一般，可能需要进一步优化模型结构或调整参数以提高性能。
### 5.2.2 KNN

#### 5.2.2.1 分类结果
分类结果信息表格：

| class | precision | recall | f1-score | support |
|-------|-----------|--------|----------|---------|
| 0     | 0.38      | 0.54   | 0.45     | 1000    |
| 1     | 0.65      | 0.20   | 0.31     | 1000    |
| 2     | 0.23      | 0.45   | 0.30     | 1000    |
| 3     | 0.29      | 0.22   | 0.25     | 1000    |
| 4     | 0.24      | 0.51   | 0.33     | 1000    |
| 5     | 0.39      | 0.22   | 0.28     | 1000    |
| 6     | 0.35      | 0.25   | 0.29     | 1000    |
| 7     | 0.68      | 0.21   | 0.32     | 1000    |
| 8     | 0.40      | 0.66   | 0.50     | 1000    |
| 9     | 0.70      | 0.14   | 0.23     | 1000    |
||||||
| accuracy    | -   | -   | 0.34     | 10000   |
| macro avg   | 0.43| 0.34| 0.33     | 10000   |
| weighted avg| 0.43| 0.34| 0.33     | 10000   |

混淆矩阵：
```
[[[8135  865]
  [ 463  537]]

 [[8888  112]
  [ 795  205]]

 [[7446 1554]
  [ 548  452]]

 [[8479  521]
  [ 783  217]]

 [[7408 1592]
  [ 486  514]]

 [[8659  341]
  [ 780  220]]

 [[8532  468]
  [ 752  248]]

 [[8900  100]
  [ 790  210]]

 [[8012  988]
  [ 345  655]]

 [[8939   61]
  [ 860  140]]]
```

#### 5.2.2.2 结果分析
首先，让我们解释表格中的各项指标：
(1) Accuracy 为 0.34，说明整体分类效果一般。
(2) recision 的平均值为 0.43，加权平均也为 0.43，说明模型对负样本的区分能力一般。
(3) Recall 召回率的平均值为 0.34，说明模型对正样本的识别能力较弱。
(4) F1-score 的加权平均为 0.33，模型说明模型不够稳健
(5) Macro average 和 Micro average 相等，说明每个类别对整体性能的贡献基本相同，模型具有较为均衡的分类能力。

混淆矩阵反映了模型在每个类别上的具体表现。例如，在类别 0 中，有 8135 个样本被正确分类为类别 0，但有 865 个样本被错误分类为其他类别。同样，在类别 0 中，有 463 个样本被错误分类为类别 1，有 537 个样本被正确分类为类别 0。

类别 1、2、3、5、6、8、9 的精确度较低，可能是因为这些类别的样本在数据集中分布较为分散或者类别之间的特征差异较小，导致模型难以准确分类。

类别 1、5、8、9 的召回率较低，说明模型在这些类别中漏检了很多正样本。可能是因为这些类别的样本特征与其他类别相似，使得模型难以正确识别。

总体而言，模型在 CIFAR-10 数据集上的分类效果较一般，可能需要进一步优化模型结构或调整参数以提高性能。
# 6 Concclusion
结论：

(1) 随机森林和 KNN 在 Fashion-MNIST 和 CIFAR-10 数据集上的分类效果均较好，其中随机森林在 Fashion-MNIST 数据集上的表现更优。
(2) 随机森林和 KNN 在分类结果上的差异主要体现在精度、召回率和 F1-score 上，其中随机森林在精度和 F1-score 上表现更优，而 KNN 在召回率上表现更优。
(3) 随机森林和 KNN 在分类结果上的差异可能与数据集的特征分布、类别间的相似度以及模型的参数设置等因素有关。


# 7 References

[Fashion Images Classification using Machine Learning, Deep Learning and Transfer Learning Models | IEEE Conference Publication | IEEE Xplore](https://ieeexplore.ieee.org/document/9786364)

# 8 Appendices
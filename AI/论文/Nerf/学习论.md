如何系统地接触和学习项目
如何高效地读论文
如何阅读项目代码
# 什么是 Nerf

NeRF 的全称是 Neural radiance fields，是一种利用神经网络从 2D 稀疏图像生成物体或场景的 3D 表示的技术

传统的三维重建方法
·主动式∶结构光重建、TOF 方法、三角测距法·
被动式: SfM、REMODE、svo

NeRF 相较于这些方法的优势
- 继承了体积表示的优点，可以表示复杂的几何形状和外观
- 适合使用投影图像进行基于梯度（可微)的优化
- 克服了在高分辨率建模复杂场景时，离散化体素网格带来的存储成本过高的问题

# 如何阅读论文？
## 框架
对于像我一样的入门学习者，提供一些我学习过程中的经验在读论文之前，先梳理一个框架出来，大致包括以下内容:

- What: 这篇论文主要做的工作是什么，基于什么背景
- How: 这篇论文具体是怎么做的，一般都会有以下部分
    - Pipeline
    - cutting-edge 的方法
    - Tricks & Optimizations
- Results: 这篇论文最后的结果如何，如何衡量效果 
    - Experiments & Metrics & Demo
    - Benchmarks 的适用范围

可以用笔记或者思维导图的形式先梳理一个这样的 backbone，之后在阅读论文的过程中一点一点填进去

**我们以 NeRF 为例来使用一下这个框架**
- what:
通过稀疏的输入视图优化底层的的连续神经辐射场，实现复杂场景的新视角合成
- How:
    - Pipeline
    - Cutting-edge 的方法︰可微的隐式场景表示 
    - Tricks & 0ptimizations
        - 位置编码〔Positional encoding)
        - 分层采样 (Hierarchical volume sampling).

 - Results:
     - PSNR/SSIM/LPIPS/Demo (novel view)
     - Benchmarks 的适用范围: llff/blender/deepvoxels/LINEMOD

## 图
关注论文中的图，论文中的图可以最直观的反映论文里提到的内容
## 公式
关注论文中的公式，这有助于更好地理解算法原理，对于阅读源码也会有所帮助, 建议自己手推一遍论文中的公式，相关参考资料可以从论文 reference 中

收集在 NeRF 的论文中，涉及到了以下几个公式
- 透射率
- 颜色积分
- 分段体积渲染
- NDC 坐标系转换
## 工具
- chatPDF: Chat with any PDF
- ChatGPT Academic∶科研工作专用 ChatGPT/GLM 拓展
- New Bing: 选择 Edge 浏览器为 PDF 文件打开方式，可以直接在页面上与 Bing chat 交互

# Nerf 代码学习
- NeRF 的代码实现有很多方式，可以从中选取比较熟悉的实现方式·官方的 TensorFlow 实现
- Pytorch 实现
- Read NeRF Pytorch : 带注释版本的 nerf-pytorch. 
- Taichi + PyTorch：Taichi + Pytorch 实现（涉及 InstantNGP）

建议学习 Pytorch 相关的实现方式，Pytorch 是现在更加主流的框架

## 如何学习源码
推荐用模块化的方式来学习源码，边看源码的结构边整理框架 CV/DL 相关的论文源码一般都会包括以下几部分
- Datasets
- networks
- Evaluators
- Trainers
- Visualizers (optional)

对于 NeRF 而言，还会多一个模块: Renderer 

读代码的过程中，也可以多做一些事情：
- 顺手记录一下用到的参数，方便之后复现
- 对比论文中的一些算法和细节，弄清楚如何用代码实现的 (position encoding/volume rendering etc. )

一种比较高效的学习源码方式是看代码的同时自己跟着写，慢慢地完善代码的各个部分，最后完全实现
这个过程也有很多需要注意的地方∶
- 自己写很难有和原作者不同的思路和框架，容易变成 C-C+ C-v，因此推荐按照之前提到的框架来写
- 按照模块化的方式来检验自己写的代码能不能 work，一次性 debug 整个框架会很困难, debug 的过程很痛苦快乐
- 学习了源码的实现方式后，提取实现过程中的重点思想和方法，然后尝试不看源码来实现自己的代码
后续介绍 NeRF 的复现时还会具体介绍这部分

## 复现过程
### 数据集准备
**Pipeline**
- 用手机拍摄一段目标物体的多视角视频
- 用 ffmpeg 对视频抽帧得到目标物体的多视角图像
- 借助 Colmap 标定，获得相机的内参和外参
- 整理数据格式，生成 NeRF 对应的数据集〔推荐使用 Blender 格式)数据集格式：
![[Pasted image 20230508150755.png]]

> [!NOTE] 
> 论文作者使用 Blender 创建了包含不同物体和光照条件的合成场景，然后从不同的视角渲染这些场景，生成用于神经辐射场（NeRF）算法训练的数据。这些合成数据用于训练 NeRF 模型，从而基于任意视角的输入图像生成场景的新视图。使用合成数据使作者能够生成大量带有准确基准的训练数据，这对于 NeRF 算法的成功至关重要。

### 训练模型
数据集准备完，在之前自己实现的框架上训练模型，为了检验代码是否能 work, 可以在训练的过程中关注一些量化的数据，借助 TensorBoard 我们可以可视化训练过程
![[Pasted image 20230508150914.png]]

### Eval 结果
模型训练完之后，可以保存模型做 evaluate，通过 novel view 和 metrics 来检验训练结果 (200k iterations)
![[Pasted image 20230508150944.png]]

### Tips
关于自己制作数据集，需要注意以下几点
- 拍摄场景的光照条件尽可能保持一致
- 尽量保持多视角物体在图像中的相对位置不变（让物体保持在图像中间）
- 为了获得更精确的相机内参，可以在用 COLMAP 的时候选择共享内参
- 多视角图像的数量保持在 50-100 张比较合适

训练过程中模型调参
- 先根据论文中的参数复现，遇到问题再检查各个模块
- 由于拍摄场景的不同，需要调整 scene 的 near 和 far 参数〔原先 NeRF 中使用的是 2.0和6.0 )
- 关注训练过程中 loss 的变化，如果有问题的化可以考虑简化训练过程，只用 coarse model 进行训练，查看结果是否有问题，没问题再加上 fine model


# 管线

![[论文：Nerf将场景表示为用于视图合成的神经辐射场#^iuvbi2]]


# 体渲染

隐式表达都是连续函数，在需要渲染时对函数进行离散化采样。

![[Pasted image 20240320145451.png|350]]
比如: 绿色区域都表示一个函数 f (xyz)，选其中的红色的一条线段，则在线段上取一个点，渲染时就可以离散化的按照函数得到对应的 f (x0, y0, z0) => color c; .


我们将连续场景表示为 5D 向量值函数，其输入为 3D 位置 $x=(x,y,z)$ 和 2D 观看方向 $(θ，∅)$，其输出为发出的颜色 $c=(r,g,b)$ 和**体积密度** $σ$。在实践中，我们把方向 $(θ，∅)$ 表示为三维笛卡尔坐标的单位向量 $d$。

**体积密度** $σ(x)$ 可以解释为光线在 $x$ 处终止于无穷小粒子（infinitesimal particle）的微分概率 (differential probability)

**5D 场景表示函数（辐射场）** 可以写为： $F_Θ:(x, d)→(c, σ)$ ，即从每个输入 5D 坐标映射到其相应的体积密度和颜色。




我们用照片生成场函数是困难的，但是我们可以先有一个场函数，然后通过体渲染得到一个 2D 图片，与原始图相比较，进而不断迭代场函数，最终得到一个可以高度匹配原始图的场。具体步骤如下:.
1. **数据准备**: 准备一组包含二维图片和相应相机参数的训练数据。每张图片是从不同角度捕获的场景快照。每个训练样本由一张图片和对应的相机参数组成。 
2. **视线光线的生成:** 对于每张图片，根据相机参数生成视线光线。这些光线起始于相机位置，穿过图像平面上的每个像素，并延伸到场景中。
3. **光线与体积函数的交互**: 对于每条视线光线，将光线的起始点传入体积函数（通常是一个多层感知器)。体积函数会输出沿着光线的颜色和密度值。
4. **损失计算**: 将体积函数输出的颜色与实际图像中对应像素的颜色进行比较，计算损失。损失衡量了预测图像与真实图像之间的差异。.
5. **反向传播和优化**: 使用反向传播算法，将损失反向传播到神经网络中，计算梯度并进行权重更新。这个过程采用优化算法（如随机梯度下降）来逐步调整神经网络的权重，以最小化损失函数。.
6. **迭代训练**: 重复以上步骤，逐渐迭代训练神经网络。每次迭代都会使用不同的训练样本，以便网络能够从各个角度和视角学习场景的三维表示。.
7. **收敛与模型保存**: 训练过程会持续一段时间，直到模型达到一定的收敛程度，即损失足够小。在训练完成后，可以保存训练好的体积函数模型。

总结来说，Scene Modeling 阶段就是通过在多个视角下的输入图像和相机参数，让神经网络学习到一个能够将三维空间点映射到颜色和密度值的体积函数。这个过程实际上是在从输入图像中学习场景的三维结构和属性，并将其表示为神经网络的权重。这使得网络在渲染阶段能够根据相机参数和光线来生成场景的虚拟图像
到这里，理论上就可以使用神经网络去构建三维场了，NeRF 的基本原理也就是这样的，但是! BUT! 懂得都懂，事情还没有这么简单。.

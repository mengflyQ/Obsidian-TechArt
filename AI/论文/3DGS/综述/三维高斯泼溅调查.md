今天想介绍的是 `ZJU` 带来的 `3DGS` 的首篇综述 `A Survey on 3D Gaussian Splatting` 论文链接 [arXiv:2401.03890](https://arxiv.org/abs/2401.03890)。

首先说一些自己的理解，3DGS 之所以爆火，很大程度在于他的实时性，而这一部分极大程度得益于他定制的算法与自定义 CUDA 内核。除此之外，**Gaussian Splatting** 根本不涉及任何神经网络，甚至没有一个小型的 MLP，也没有什么 "神经" 的东西，场景本质上只是空间中的一组点。在大家都在研究数十亿个参数组成的模型的人工智能世界里，这种方法越来越受欢迎，令人耳目一新。它的想法源于 "Surface splatting"（2001 年），说明经典的计算机视觉方法仍然可以激发相关的解决方案。它简单明了的表述方式使 **Gaussian Splatting** 特别容易解释，这也是为什么在某些应用中选择它而不是 NeRFs。

# 摘要

三维高斯泼溅（3D GS）是最近在显式辐射场和计算机图形领域出现的一种变革性技术。这种创新方法的特点是利用数百万个三维高斯（3D Gaussians）。与神经辐射场（NeRF）方法不同，后者主要使用基于坐标的隐式模型将空间坐标映射到像素值。  

**3D GS 具有显式场景表示和可微分的渲染算法，不仅具有实时渲染能力，还引入了前所未有的控制和可编辑水平。**  这使得 3D GS 成为下一代 3D 重建和表示的潜在变革者。在本文中，我们首次系统地概述了 3D GS 领域的最新发展和重要贡献。  

我们首先详细探讨了 3D GS 出现背后的基本原理和驱动力，为理解其意义奠定了基础。我们讨论的一个焦点是 3D GS 的实际应用性。  通过促进实时性能，3D GS 开启了从虚拟现实到互动媒体等众多应用领域。  
此外，还对领先的 3D GS 模型进行了比较分析，并在各种基准任务中进行了评估，以突出其性能和实用性。调查报告最后指出了当前面临的挑战，并提出了该领域未来研究的潜在途径。  

通过这项调查，我们旨在为新手和经验丰富的研究人员提供宝贵的资源，促进在适用和明确的辐射场表示方面的进一步探索和进步。

**关键字**： 高斯泼溅、显式辐射场、实时渲染、深度学习

# 1 引言


神经辐射场（NeRF）的出现标志着计算机图形学和三维场景重建领域的一个重要里程碑，彻底改变了我们处理新视图合成的方式[2]。NeRF 以深度学习和计算机视觉为基础，能够从一组稀疏的输入视图渲染逼真的场景，为图像合成建立了新的范例。  
然而，与任何新兴技术一样，NeRF 也遇到了一些挑战和限制，特别是在计算效率和可控性方面。正是在这种情况下，**3D 高斯泼溅技术（3D GS） 应运而生，它不仅是一种渐进式的改进，而且是一种范式转换方法，重新定义了场景表现和渲染的界限。**


早在 NeRF 问世之前，新视角合成技术就已开始发展，早期的研究主要集中在光场和基本场景重建方法上[4, 5, 6]。然而，这些最初的技术由于依赖密集采样和结构化捕捉而受到限制，导致在处理复杂场景和照明条件时面临巨大挑战。**运动结构（SfM）[7] 的出现以及随后多视角立体（MVS）[8] 算法的进步为三维场景重建提供了一个更强大的框架，为更复杂的视角合成算法奠定了基础。NeRF 代表了这一进程中的飞跃。**  

**通过利用神经网络，NeRF 实现了空间坐标到颜色和密度的映射。NeRF 的成功取决于其创建连续、体积场景功能的能力，它所产生的结果具有前所未有的细节和真实感**。然而，这种实现方式是有**代价**的：**NeRF 方法计算密集，通常需要大量的训练时间和大量的渲染资源，尤其是高分辨率输出。**
3D GS 就是为了应对这些挑战而出现的。虽然 NeRF 在创建逼真图像方面表现出色，但对更快、更高效的渲染方法的需求却日益明显，尤其是对于需要实时性能的应用而言。  

3D GS 通过引入一种使用数百万个 3D 高斯的新型场景表示技术来满足这一需求。**与基于坐标的隐式模型不同，三维高斯采用了显式表示和高度并行化的工作流程，从而提高了计算和渲染的效率。3D GS 的创新之处在于它独特地融合了<mark style="background: #FF5582A6;">可微分管线</mark>和<mark style="background: #FF5582A6;">基于点的渲染</mark>技术的优势。**  

通过用可学习的三维高斯来表示场景，它保留了对高质量图像合成至关重要的连续体积辐射场（continuous volumetric radiance fields）的理想特性，同时又避免了与空空间（empty space）渲染相关的计算开销，而这正是传统 NeRF 方法的常见缺点。

**3D GS 的引入不仅仅是技术上的进步，它代表着我们在计算机图形学中场景表现和渲染方法的根本性转变。**  

通过在不影响视觉质量的情况下实现实时渲染功能，3D GS 为从虚拟现实和增强现实到实时电影渲染等各种应用开辟了大量可能性。这项技术不仅有望增强现有应用，还能实现以前由于计算限制而无法实现的新应用。 此外，3D GS 的显式场景表示提供了前所未有的场景动态控制，这在涉及复杂几何图形和不同照明条件的复杂场景中是一个关键因素。这种控制水平和可编辑性，再加上渲染过程的效率，使 3D GS 成为相关领域未来发展的变革力量。


本文的结构概要见图 2，具体如下：
- 第 2 节：简要介绍了问题提出、术语和相关研究领域的背景。
- 第 3 节：介绍 3D 高斯的基本观点，包括 3D 高斯的新颖视图合成和 3D 高斯的优化细微差别。
- 第 4 节：揭示了三维高斯在不同应用领域和任务中的重要影响，展示了其多功能性。
- 第 5 节：进行了性能比较和分析。
- 第 6 节和第 7 节：强调了有待进一步研究的开放性问题，并结束了本调查。  

![[Pasted image 20240403170017.png]]
>图 2：本文结构

# 2 背景
在本节中，我们首先简要介绍了场景渲染中的关键概念--辐射场。它概述了辐射场表示的两种主要类型：
1. 隐式，如 NeRF，使用神经网络进行直接但计算要求高的渲染；
2. 显式，如 grid，使用离散结构进行快速访问，但代价是更高的内存使用。

![[c2fa4895563b09f5eacfacef569ec137_MD5.jpg]]


第 2.2 节将进一步介绍与场景重建和渲染等相关领域的联系。
## 2.1 问题的提出

### 2.1.1 辐射场 Radiance Field

辐射场是光在三维空间中分布的表示，它捕捉了光与环境中的表面和材料的相互作用[30]。在数学上，辐射场可以描述为一个函数 $L:ℝ^5↦ℝ^+$，其中 $L(x,y,z,\theta,\phi)$ 映射空间中的一个点 $(x,y,z)$ 和球面坐标 $(\theta,\phi)$ 指定的方向。映射到一个非负的辐射 （radiance）值。辐照场可以通过隐式或显式表示法封装，每种表示法在场景表示和渲染方面都有特定的优势。
### 2.1.2 隐式辐射场
**隐式辐射场表示场景中的光分布，而不明确定义场景的几何形状。** 在深度学习时代，它通常使用神经网络来学习连续的体积场景表示。最突出的例子是 NeRF。

在 NeRF 中，MLP 网络用于将一组空间坐标 $(x, y, z)$ 和观察方向 $(\theta,\phi)$ 映射到颜色和密度值。任何一点的辐射度都不是显式存储，而是**通过查询**神经网络实时计算得出。因此，该函数可以写成

$L_\text{implicit}(x,y,z,\theta,\phi)=\text{NeuralNetwork}(x,y,z,\theta,\phi)$

**这种格式可以对复杂的场景进行可微且紧凑的表示，但是由于我们总是需要对光线进行采样和体渲染的计算，会导致计算负载比较高。**

### 2.1.3 显式辐射场

与隐式不同的是，**显示是直接表示光在离散空间结构中的分布，比如体素网格或点云**。该结构中的每个元素都存储了其在空间中相应位置的 radiance 信息，而不是像 NeRF 一样去执行查询的操作。

这种方法可以更直接、更快速地访问辐照度数据，但代价是内存使用率更高，分辨率可能更低。**显式辐照度场表示的一般形式可写成**

$L_\text{explicit}{ ( x , y , z , \theta , \phi ) }=\text{DataStructure}[(x,y,z)]\cdot f(\theta,\phi)$

其中，`DataStructure` 可以是网格或点云，而 $f(θ, ϕ)$ 是一个根据观察视线方向修改 radiance 的函数。 
### 2.1.4 3DGS （两全其美）
3D GS [ 3] 代表了从隐式辐射场到显式辐射场的转变。它利用 3D 高斯作为一种灵活高效的表示方法，充分利用了两种方法的优势。  

**这些高斯经过优化，能够准确地表现场景，将基于神经网络的优化和显式结构化数据存储的优势结合在一起。这种混合方法旨在以更快的训练速度和实时性能实现高质量的渲染，尤其是针对复杂场景和高分辨率输出。**

**三维高斯表示法的公式为**

$L_{\mathrm{3DGS}}(x,y,z,\theta,\phi)=\sum_{i}G(x,y,z,\mu_{i},\Sigma_{i})\cdot c_{i}(\theta,\phi)$

其中 $G$ 是具有平均值 $μ_i$ 和协方差 $Σ_i$ 的高斯函数， $c$ 表示与视图相关的颜色。

## 2.2 背景和术语
一些技术和研究学科与 3D GS 关系密切，下文将对此进行简要介绍。

### 2.2.1 场景重建和渲染

场景重建：从图像或其他数据集合中创建场景的三维模型。

渲染：将计算机可读信息（如场景中的三维物体）转换为基于像素的图像。早期的技术基于光场生成逼真的图像。运动结构（SfM） 和多视角立体（MVS） 算法通过从图像序列中估计三维结构，进一步推动了这一领域的发展。这些历史悠久的方法为更复杂的场景重建和渲染技术奠定了基础。

### 2.2.2 神经渲染和辐射场

**神经渲染**：将深度学习与传统图形技术结合生成逼真的图像。早期方法使用 CNN 估计混合权重或纹理空间解决方案。

**辐射场**：一种函数表达，描述从各方向穿过空间各点的光的量。NeRF 使用神经网络建模辐射场。


### 2.2.3 体积表示和光线步进

**体积表达**：不仅将物体和场景建模为表面，还将其其建模为充满材料或空白空间的体积。这样可以对如雾、烟或半透明材料进行更精确的渲染。

光线步进：是体积表达渲染图像的技术，通过增量跟踪穿过 “体” 的光线来渲染图像。NeRF 引入重要性采样和位置编码增强合成图像的质量，虽然能得到高质量的图像，但这一方法计算量大。


### 2.2.4 基于点的渲染

基于点的渲染是一种使用点而非传统多边形来可视化 3D 场景的技术。该方法特别适用于渲染复杂、非结构化或稀疏的几何数据。点可以通过添加额外属性，如可学习的神经描述符来进行增强，并且可以高效地进行渲染，但这种方法可能会出现渲染中的空洞或混叠效应等问题。
3DGS 通过使用各向异性高斯进行更连贯的场景表达。

# 3 用于显式辐射场的 3D 高斯模型
3D GS 在实时、高分辨率图像渲染方面实现了突破，而无需依赖神经网络。

本节旨在提供三维高斯的基本见解。
1. 在第 3.1 节中，我们首先阐述 3D GS 如何在三维高斯构造良好的情况下合成图像，即 **3D GS 的前向过程**。
2. 在第 3.2 节中，介绍如何为给定场景获取构造良好的三维高斯，即 **3D GS 的优化过程。**

## 3.1 学习 3D 高斯函数进行新视角合成

![[Pasted image 20240403170000.png]]
> 图 3：3D 高斯前向处理过程示意图（第 3.1 节）。
> (a) 泼溅步骤将 3D 高斯投影到图像空间。
> (b) 3D高斯将图像划分为多个不重叠的batch（即`tile`）。
> (c) 3D 高斯复制覆盖多个 `tile` 的高斯，为每个副本分配一个标识符，即 `tile ID`。
> (d) 通过渲染分类高斯，我们可以获得瓦片内的所有像素。请注意，像素和瓦片的计算工作流程是独立的，可以并行处理.

**NeRFs 和 3DGS 渲染上的区别**：考虑一个由（数百万个）优化 3D 高斯表示的场景。目标是根据指定的相机姿态生成图像。
- NeRFs 是通过计算要求极高的体积射线行进（volumetric ray-marching）来完成这项任务的，它对每个像素的三维空间点进行采样。这种模式在高分辨率图像合成方面举步维艰，无法达到实时渲染速度。
- **3DGS 首先将这些三维高斯投影到基于像素的图像平面上，这一过程被称为 "泼溅（Splatting）"（图 3a）![[Pasted image 20240403170031.png]]。然后，3D 高斯排序并计算每个像素的值**。由此可见，**NeRFs 和 3D GS 的渲染可以看作是一个<mark style="background: #FFB8EBA6;">相互逆反</mark>的过程**。  （3DGS 这个渲染过程就是光栅化渲染）

![[78c2b98c75388254425c9db49e0992dc_MD5.jpg|500]]
![[5ef337a6401709574cf3a55d0309c705_MD5.jpg|500]]


### 3D Gaussian 定义及渲染方法
接下来，我们将从 3D 高斯（3D Gaussian）的定义开始，它是 3D GS 中场景表示的最小元素。接下来，我们将介绍如何将三维高斯用于可微分渲染。  
我们还将介绍 3D GS 中使用的加速技术，这是快速渲染的关键。

首先简单介绍一下，3DGS 是如何表示真实场景的，前面也有提过，在 **Gaussian Splatting** 中，3D 世界用一组 3D 点表示，实际上是数百万个，大致在 0.5 到 5 百万之间。每个点是一个 3D 高斯，具有其独特的参数，这些参数是为每个场景拟合的，以便该场景的渲染与已知数据集图像紧密匹配，接下来就介绍他的属性。
![[c76b3b4b666dfc36120dafc43cdfc263_MD5.jpg|300]]

*   **3D 高斯的属性**： 一个 3D 高斯主要包括，中心坐标（$x,y,z$ ）的均值 $μ$ 、不透明度 $α$ 、3D 协方差矩阵 $Σ$ 和颜色 $c$ 。其中 $c$ 由球谐函数表示，用于表示与视角（观察位置）相关的外观。**所有属性都可以通过反向传播来学习和优化。**  
*   **视锥剔除**：给定特定的相机姿态，该步骤会判断哪些高斯位于相机的视锥外，并在后续步骤中剔除，以节省计算。  
*   **泼溅（Splatting）**：实际上只是 3D 高斯（椭圆体）投影到 2D 图像空间（椭圆）中进行渲染。给定观察变换 $W$ 和 3D 协方差矩阵 $\Sigma$ ，可以投影出 2D 协方差矩阵 $\Sigma^{\prime}$： $$\Sigma^{\prime}=JW\Sigma W^\top J^\top$$ 其中 $J$ 为投影变换中仿射近似的雅可比矩阵。  
*   **像素渲染**：在深入探讨利用多种技术促进并行计算的 3D GS 最终版本之前，我们首先阐述其简单形式，以便深入了解其工作机制：给定一个像素的位置 𝒙 可以通过观察变换 𝑾 计算出该像素与所有重叠高斯的距离，即这些高斯的深度。形成一个高斯排序列表 𝒩 。.然后，通过 **Alpha 混合**计算出该像素的最终颜色：$$C=\sum_{i\in\mathcal{N}}c_i\alpha_i^{\prime}\prod_{j=1}^{i-1}\left(1-\alpha_j^{\prime}\right.)$$ 其中 $c_i$ 是学习到的颜色，最终的不透明度 $\alpha_i^{\prime}$ 是学习的不透明度 $\alpha_i$ 与高斯的乘积: $$\alpha_i'=\alpha_i\times\exp\left(-\frac12(x'-\mu_i')^\top\Sigma_i'^{-1}(x'-\mu_i')\right)$$ 其中 $x'$ 和 $μ'_i$ 是投影空间中的坐标，同时我也找了个 gif 来可视化了一下 Gaussian Splatting 对位置 p 的影响：![[f6309c7b9526457223fd000004a69e86_MD5.gif]]
如果仔细看的话，我们会发现，实际上这个公式和[多变量正态分布的概率密度函数](https://en.wikipedia.org/wiki/Multivariate_normal_distribution)十分相像，是忽略了带有协方差行列式的标准化项，而是用不透明度来加权。$$(2\pi)^{-k/2}\det(\boldsymbol{\Sigma})^{-1/2}\exp\biggl(-\frac12(\mathbf{x}-\boldsymbol{\mu})^\mathrm{T}\boldsymbol{\Sigma}^{-1}(\mathbf{x}-\boldsymbol{\mu})\biggr)$$
考虑到生成所需的排序列表很难并行化，与 NeRF 相比，所述渲染过程可能会更慢。如果采用这种简单的逐像素方法，渲染速度会受到很大影响。为了实现实时渲染，3D GS 做出了一些让步，以适应并行计算。

- **瓦片 Tiles (Patches)：** 为了避免为每个像素推导高斯的计算成本，3D 高斯将精度从像素级转移到了 patch 级。具体来说，三维高斯将图像划分为多个不重叠的 patch，在原论文中称为 `tile`。图 3b 展示了图块。每个 `tile` 包含 16 × 16 像素。3D GS 会进一步确定哪些 `tile` 与这些投影高斯相交。鉴于一个投影高斯可能覆盖多个 `tile`，一种合理的方法是**复制高斯**，为每个副本分配一个相关`tile`的标识符（即`tile ID` ）。(不用判断每个像素与高斯的距离，而是判断 tile 就简单多了)
![[Pasted image 20240403170054.png|500]]

- **并行渲染**。复制后，3D GS 会将各自的 `tile ID` 与每个高斯观察变换得到的深度值结合起来。这将产生一个未排序的字节列表，其中高位代表 `tile ID`，低位表示深度。
![[Pasted image 20240403170630.png|500]]
经过排序后的列表就可以直接用于渲染（即 Alpha 混合）。图 3c 和图 3d 直观地展示了这一概念。**值得强调的是，每个 `tile` 和像素的渲染都是独立进行的，因此这一过程非常适合并行计算**。另外一个好处是，每个 `tile` 的像素都可以访问共同的共享内存，并保持统一的读取顺序，从而提高 Alpha 混合的并行执行效率。**在原论文的正式实施中，该框架将 `tile` 和像素的处理分别视为类似于 CUDA 编程架构中的块和线程。**
![[Pasted image 20240403171115.png|345]]
简而言之，3D GS 在前处理阶段引入了若干近似值，以提高计算效率，同时保持高标准的图像合成质量。
## 3.2 3D GS 的优化

学习到这里，我们可能会有一个问题，怎么可能在空间中的一堆圆球中得到一个像样的图像的，确实是这样，如果没有进行优化，在渲染的时候就会出现很多伪影，从下图你可以看到。

![An example of renders of an under-optimized scene](https://pic1.zhimg.com/80/v2-7ad69d962fb9a18d84747130af62fe15.png)
>优化不足的场景


3D 高斯的核心是一个优化程序，旨在构建大量 3D 高斯集合，准确捕捉场景的本质，从而促进自由视点渲染。   
- 一方面，应通过**可微渲染**优化 3D 高斯的属性，以适应特定场景的纹理。
- 另一方面，能够很好地表现给定场景的 **3D 高斯的数量是未知的**。  

One promising avenue is to let the neural network automatically learn the density of 3D Gaussians. We will introduce how to optimize the properties of each Gaussian in Sec. [3.2.1](https://ar5iv.labs.arxiv.org/html/2401.03890?_immersive_translate_auto_translate=1#S3.SS2.SSS1 "3.2.1 Parameter Optimization ‣ 3.2 Optimization of 3D Gaussian Splatting ‣ 3 3D Gaussians for Explicit Radiance Field ‣ A Survey on 3D Gaussian Splatting") and how to control the density of the Gaussians in Sec. [3.2.2](https://ar5iv.labs.arxiv.org/html/2401.03890?_immersive_translate_auto_translate=1#S3.SS2.SSS2 "3.2.2 Density Control ‣ 3.2 Optimization of 3D Gaussian Splatting ‣ 3 3D Gaussians for Explicit Radiance Field ‣ A Survey on 3D Gaussian Splatting"). The two procedures are interleaved within the optimization workflow. Since there are many manually set hyperparameters in the optimization process, we omit the notations of most hyperparameters for clarity.  
让神经网络自动学习三维高斯的密度是一条很有前途的途径。我们将在第 3.2.1 节中介绍如何优化每个高斯的属性，并在第 3.2.2 节中介绍如何控制高斯的密度。这两个过程在优化工作流程中交错进行。由于优化过程中有许多手动设置的超参数，为清晰起见，我们省略了大部分超参数的符号。
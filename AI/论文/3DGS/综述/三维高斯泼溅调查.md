---
title: 三维高斯泼溅调查
uid: "202404032106"
create_time: 2024-04-03 15:34
reference:
  - https://arxiv.org/abs/2401.03890
---


今天想介绍的是 `ZJU` 带来的 `3DGS` 的首篇综述 `A Survey on 3D Gaussian Splatting` 论文链接 [arXiv:2401.03890](https://arxiv.org/abs/2401.03890)。

首先说一些自己的理解，3DGS 之所以爆火，很大程度在于他的实时性，而这一部分极大程度得益于他定制的算法与自定义 CUDA 内核。除此之外，**Gaussian Splatting** 根本不涉及任何神经网络，甚至没有一个小型的 MLP，也没有什么 "神经" 的东西，场景本质上只是空间中的一组点。在大家都在研究数十亿个参数组成的模型的人工智能世界里，这种方法越来越受欢迎，令人耳目一新。它的想法源于 "Surface splatting"（2001 年），说明经典的计算机视觉方法仍然可以激发相关的解决方案。它简单明了的表述方式使 **Gaussian Splatting** 特别容易解释，这也是为什么在某些应用中选择它而不是 NeRFs。

# 摘要

三维高斯泼溅（3D GS）是最近在显式辐射场和计算机图形领域出现的一种变革性技术。这种创新方法的特点是利用数百万个三维高斯（3D Gaussians）。与神经辐射场（NeRF）方法不同，后者主要使用基于坐标的隐式模型将空间坐标映射到像素值。  

**3D GS 具有显式场景表示和可微分的渲染算法，不仅具有实时渲染能力，还引入了前所未有的控制和可编辑水平。**  这使得 3D GS 成为下一代 3D 重建和表示的潜在变革者。在本文中，我们首次系统地概述了 3D GS 领域的最新发展和重要贡献。  

我们首先详细探讨了 3D GS 出现背后的基本原理和驱动力，为理解其意义奠定了基础。我们讨论的一个焦点是 3D GS 的实际应用性。  通过促进实时性能，3D GS 开启了从虚拟现实到互动媒体等众多应用领域。  
此外，还对领先的 3D GS 模型进行了比较分析，并在各种基准任务中进行了评估，以突出其性能和实用性。调查报告最后指出了当前面临的挑战，并提出了该领域未来研究的潜在途径。  

通过这项调查，我们旨在为新手和经验丰富的研究人员提供宝贵的资源，促进在适用和明确的辐射场表示方面的进一步探索和进步。

**关键字**： 高斯泼溅、显式辐射场、实时渲染、深度学习

# 1 引言


神经辐射场（NeRF）的出现标志着计算机图形学和三维场景重建领域的一个重要里程碑，彻底改变了我们处理新视图合成的方式[2]。NeRF 以深度学习和计算机视觉为基础，能够从一组稀疏的输入视图渲染逼真的场景，为图像合成建立了新的范例。  
然而，与任何新兴技术一样，NeRF 也遇到了一些挑战和限制，特别是在计算效率和可控性方面。正是在这种情况下，**3D 高斯泼溅技术（3D GS） 应运而生，它不仅是一种渐进式的改进，而且是一种范式转换方法，重新定义了场景表现和渲染的界限。**


早在 NeRF 问世之前，新视角合成技术就已开始发展，早期的研究主要集中在光场和基本场景重建方法上[4, 5, 6]。然而，这些最初的技术由于依赖密集采样和结构化捕捉而受到限制，导致在处理复杂场景和照明条件时面临巨大挑战。**运动结构（SfM）[7] 的出现以及随后多视角立体（MVS）[8] 算法的进步为三维场景重建提供了一个更强大的框架，为更复杂的视角合成算法奠定了基础。NeRF 代表了这一进程中的飞跃。**  

**通过利用神经网络，NeRF 实现了空间坐标到颜色和密度的映射。NeRF 的成功取决于其创建连续、体积场景功能的能力，它所产生的结果具有前所未有的细节和真实感**。然而，这种实现方式是有**代价**的：**NeRF 方法计算密集，通常需要大量的训练时间和大量的渲染资源，尤其是高分辨率输出。**
3D GS 就是为了应对这些挑战而出现的。虽然 NeRF 在创建逼真图像方面表现出色，但对更快、更高效的渲染方法的需求却日益明显，尤其是对于需要实时性能的应用而言。  

3D GS 通过引入一种使用数百万个 3D 高斯的新型场景表示技术来满足这一需求。**与基于坐标的隐式模型不同，三维高斯采用了显式表示和高度并行化的工作流程，从而提高了计算和渲染的效率。3D GS 的创新之处在于它独特地融合了<mark style="background: #FF5582A6;">可微分管线</mark>和<mark style="background: #FF5582A6;">基于点的渲染</mark>技术的优势。**  

通过用可学习的三维高斯来表示场景，它保留了对高质量图像合成至关重要的连续体积辐射场（continuous volumetric radiance fields）的理想特性，同时又避免了与空空间（empty space）渲染相关的计算开销，而这正是传统 NeRF 方法的常见缺点。

**3D GS 的引入不仅仅是技术上的进步，它代表着我们在计算机图形学中场景表现和渲染方法的根本性转变。**  

通过在不影响视觉质量的情况下实现实时渲染功能，3D GS 为从虚拟现实和增强现实到实时电影渲染等各种应用开辟了大量可能性。这项技术不仅有望增强现有应用，还能实现以前由于计算限制而无法实现的新应用。 此外，3D GS 的显式场景表示提供了前所未有的场景动态控制，这在涉及复杂几何图形和不同照明条件的复杂场景中是一个关键因素。这种控制水平和可编辑性，再加上渲染过程的效率，使 3D GS 成为相关领域未来发展的变革力量。


本文的结构概要见图 2，具体如下：
- 第 2 节：简要介绍了问题提出、术语和相关研究领域的背景。
- 第 3 节：介绍 3D 高斯的基本观点，包括 3D 高斯的新颖视图合成和 3D 高斯的优化细微差别。
- 第 4 节：揭示了三维高斯在不同应用领域和任务中的重要影响，展示了其多功能性。
- 第 5 节：进行了性能比较和分析。
- 第 6 节和第 7 节：强调了有待进一步研究的开放性问题，并结束了本调查。  

![[Pasted image 20240403170017.png]]
>图 2：本文结构

# 2 背景
在本节中，我们首先简要介绍了场景渲染中的关键概念--辐射场。它概述了辐射场表示的两种主要类型：
1. 隐式，如 NeRF，使用神经网络进行直接但计算要求高的渲染；
2. 显式，如 grid，使用离散结构进行快速访问，但代价是更高的内存使用。

![[c2fa4895563b09f5eacfacef569ec137_MD5.jpg]]


第 2.2 节将进一步介绍与场景重建和渲染等相关领域的联系。
## 2.1 问题的提出

### 2.1.1 辐射场 Radiance Field

辐射场是光在三维空间中分布的表示，它捕捉了光与环境中的表面和材料的相互作用[30]。在数学上，辐射场可以描述为一个函数 $L:ℝ^5↦ℝ^+$，其中 $L(x,y,z,\theta,\phi)$ 映射空间中的一个点 $(x,y,z)$ 和球面坐标 $(\theta,\phi)$ 指定的方向。映射到一个非负的辐射 （radiance）值。辐照场可以通过隐式或显式表示法封装，每种表示法在场景表示和渲染方面都有特定的优势。
### 2.1.2 隐式辐射场
**隐式辐射场表示场景中的光分布，而不明确定义场景的几何形状。** 在深度学习时代，它通常使用神经网络来学习连续的体积场景表示。最突出的例子是 NeRF。

在 NeRF 中，MLP 网络用于将一组空间坐标 $(x, y, z)$ 和观察方向 $(\theta,\phi)$ 映射到颜色和密度值。任何一点的辐射度都不是显式存储，而是**通过查询**神经网络实时计算得出。因此，该函数可以写成

$L_\text{implicit}(x,y,z,\theta,\phi)=\text{NeuralNetwork}(x,y,z,\theta,\phi)$

**这种格式可以对复杂的场景进行可微且紧凑的表示，但是由于我们总是需要对光线进行采样和体渲染的计算，会导致计算负载比较高。**

### 2.1.3 显式辐射场

与隐式不同的是，**显示是直接表示光在离散空间结构中的分布，比如体素网格或点云**。该结构中的每个元素都存储了其在空间中相应位置的 radiance 信息，而不是像 NeRF 一样去执行查询的操作。

这种方法可以更直接、更快速地访问辐照度数据，但代价是内存使用率更高，分辨率可能更低。**显式辐照度场表示的一般形式可写成**

$L_\text{explicit}{ ( x , y , z , \theta , \phi ) }=\text{DataStructure}[(x,y,z)]\cdot f(\theta,\phi)$

其中，`DataStructure` 可以是网格或点云，而 $f(θ, ϕ)$ 是一个根据观察视线方向修改 radiance 的函数。 
### 2.1.4 3DGS （两全其美）
3D GS [ 3] 代表了从隐式辐射场到显式辐射场的转变。它利用 3D 高斯作为一种灵活高效的表示方法，充分利用了两种方法的优势。  

**这些高斯经过优化，能够准确地表现场景，将基于神经网络的优化和显式结构化数据存储的优势结合在一起。这种混合方法旨在以更快的训练速度和实时性能实现高质量的渲染，尤其是针对复杂场景和高分辨率输出。**

**三维高斯表示法的公式为**

$L_{\mathrm{3DGS}}(x,y,z,\theta,\phi)=\sum_{i}G(x,y,z,\mu_{i},\Sigma_{i})\cdot c_{i}(\theta,\phi)$

其中 $G$ 是具有平均值 $μ_i$ 和协方差 $Σ_i$ 的高斯函数， $c$ 表示与视图相关的颜色。

## 2.2 背景和术语
一些技术和研究学科与 3D GS 关系密切，下文将对此进行简要介绍。

### 2.2.1 场景重建和渲染

场景重建：从图像或其他数据集合中创建场景的三维模型。

渲染：将计算机可读信息（如场景中的三维物体）转换为基于像素的图像。早期的技术基于光场生成逼真的图像。运动结构（SfM） 和多视角立体（MVS） 算法通过从图像序列中估计三维结构，进一步推动了这一领域的发展。这些历史悠久的方法为更复杂的场景重建和渲染技术奠定了基础。

### 2.2.2 神经渲染和辐射场

**神经渲染**：将深度学习与传统图形技术结合生成逼真的图像。早期方法使用 CNN 估计混合权重或纹理空间解决方案。

**辐射场**：一种函数表达，描述从各方向穿过空间各点的光的量。NeRF 使用神经网络建模辐射场。


### 2.2.3 体积表示和光线步进

**体积表达**：不仅将物体和场景建模为表面，还将其其建模为充满材料或空白空间的体积。这样可以对如雾、烟或半透明材料进行更精确的渲染。

光线步进：是体积表达渲染图像的技术，通过增量跟踪穿过 “体” 的光线来渲染图像。NeRF 引入重要性采样和位置编码增强合成图像的质量，虽然能得到高质量的图像，但这一方法计算量大。


### 2.2.4 基于点的渲染

基于点的渲染是一种使用点而非传统多边形来可视化 3D 场景的技术。该方法特别适用于渲染复杂、非结构化或稀疏的几何数据。点可以通过添加额外属性，如可学习的神经描述符来进行增强，并且可以高效地进行渲染，但这种方法可能会出现渲染中的空洞或混叠效应等问题。
3DGS 通过使用各向异性高斯进行更连贯的场景表达。

# 3 用于显式辐射场的 3D 高斯模型
3D GS 在实时、高分辨率图像渲染方面实现了突破，而无需依赖神经网络。

本节旨在提供三维高斯的基本见解。
1. 在第 3.1 节中，我们首先阐述 3D GS 如何在三维高斯构造良好的情况下合成图像，即 **3D GS 的前向过程**。
2. 在第 3.2 节中，介绍如何为给定场景获取构造良好的三维高斯，即 **3D GS 的优化过程。**

## 3.1 学习 3D 高斯函数进行新视角合成

![[Pasted image 20240403170000.png]]
> 图 3：3D 高斯前向处理过程示意图（第 3.1 节）。
> (a) 泼溅步骤将 3D 高斯投影到图像空间。
> (b) 3D高斯将图像划分为多个不重叠的batch（即`tile`）。
> (c) 3D 高斯复制覆盖多个 `tile` 的高斯，为每个副本分配一个标识符，即 `tile ID`。
> (d) 通过渲染分类高斯，我们可以获得瓦片内的所有像素。请注意，像素和瓦片的计算工作流程是独立的，可以并行处理.

**NeRFs 和 3DGS 渲染上的区别**：考虑一个由（数百万个）优化 3D 高斯表示的场景。目标是根据指定的相机姿态生成图像。
- NeRFs 是通过计算要求极高的体积射线行进（volumetric ray-marching）来完成这项任务的，它对每个像素的三维空间点进行采样。这种模式在高分辨率图像合成方面举步维艰，无法达到实时渲染速度。
- **3DGS 首先将这些三维高斯投影到基于像素的图像平面上，这一过程被称为 "泼溅（Splatting）"（图 3a）![[Pasted image 20240403170031.png]]。然后，3D 高斯排序并计算每个像素的值**。由此可见，**NeRFs 和 3D GS 的渲染可以看作是一个<mark style="background: #FFB8EBA6;">相互逆反</mark>的过程**。  （3DGS 这个渲染过程就是光栅化渲染）

![[78c2b98c75388254425c9db49e0992dc_MD5.jpg|500]]
![[5ef337a6401709574cf3a55d0309c705_MD5.jpg|500]]


### 3D Gaussian 定义及渲染方法
接下来，我们将从 3D 高斯（3D Gaussian）的定义开始，它是 3D GS 中场景表示的最小元素。接下来，我们将介绍如何将三维高斯用于可微分渲染。  
我们还将介绍 3D GS 中使用的加速技术，这是快速渲染的关键。

首先简单介绍一下，3DGS 是如何表示真实场景的，前面也有提过，在 **Gaussian Splatting** 中，3D 世界用一组 3D 点表示，实际上是数百万个，大致在 0.5 到 5 百万之间。每个点是一个 3D 高斯，具有其独特的参数，这些参数是为每个场景拟合的，以便该场景的渲染与已知数据集图像紧密匹配，接下来就介绍他的属性。
![[c76b3b4b666dfc36120dafc43cdfc263_MD5.jpg|300]]

*   **3D 高斯的属性**： 一个 3D 高斯主要包括，中心坐标（$x,y,z$ ）的均值 $\mu$ 、不透明度 $α$ 、3D 协方差矩阵 $Σ$ 和颜色 $c$ 。其中 $c$ 由球谐函数表示，用于表示与视角（观察位置）相关的外观。**所有属性都可以通过反向传播来学习和优化。**  
*   **视锥剔除**：给定特定的相机姿态，该步骤会判断哪些高斯位于相机的视锥外，并在后续步骤中剔除，以节省计算。  
*   **泼溅（Splatting）**：将 3D 高斯（椭圆体）投影到 2D 图像空间（椭圆）。给定观察变换 $W$ 和 3D 协方差矩阵 $\Sigma$ ，可以投影出 2D 协方差矩阵 $\Sigma^{\prime}$： $$\Sigma^{\prime}=JW\Sigma W^\top J^\top$$ 其中 $J$ 为投影变换中仿射近似的雅可比矩阵。  
*   **像素渲染**：在深入探讨利用多种技术促进并行计算的 3D GS 最终版本之前，我们首先阐述其简单形式，以便深入了解其工作机制：给定一个像素的位置 𝒙 可以通过观察变换 𝑾 计算出该像素与所有重叠高斯的距离，即这些高斯的深度。形成一个高斯排序列表 𝒩 。.然后，通过 **Alpha 混合**计算出该像素的最终颜色：$$C=\sum_{i\in\mathcal{N}}c_i\alpha_i^{\prime}\prod_{j=1}^{i-1}\left(1-\alpha_j^{\prime}\right.)$$ 其中 $c_i$ 是学习到的颜色，最终的不透明度 $\alpha_i^{\prime}$ 是学习的不透明度 $\alpha_i$ 与高斯的乘积: $$\alpha_i'=\alpha_i\times\exp\left(-\frac12(x'-\mu_i')^\top\Sigma_i'^{-1}(x'-\mu_i')\right)$$ 其中 $x'$ 和 $μ'_i$ 是投影空间中的坐标，同时我也找了个 gif 来可视化了一下 Gaussian Splatting 对位置 p 的影响：![[f6309c7b9526457223fd000004a69e86_MD5.gif]]
如果仔细看的话，我们会发现，实际上这个公式和[多变量正态分布的概率密度函数](https://en.wikipedia.org/wiki/Multivariate_normal_distribution)十分相像，是忽略了带有协方差行列式的标准化项，而是用不透明度来加权。$$(2\pi)^{-k/2}\det(\boldsymbol{\Sigma})^{-1/2}\exp\biggl(-\frac12(\mathbf{x}-\boldsymbol{\mu})^\mathrm{T}\boldsymbol{\Sigma}^{-1}(\mathbf{x}-\boldsymbol{\mu})\biggr)$$
考虑到生成所需的排序列表很难并行化，与 NeRF 相比，所述渲染过程可能会更慢。如果采用这种简单的逐像素方法，渲染速度会受到很大影响。为了实现实时渲染，3D GS 做出了一些让步，以适应并行计算。

- **瓦片 Tiles (Patches)：** 为了避免为每个像素推导高斯的计算成本，3D 高斯将精度从像素级转移到了 patch 级。具体来说，三维高斯将图像划分为多个不重叠的 patch，在原论文中称为 `tile`。图 3b 展示了图块。每个 `tile` 包含 16 × 16 像素。3D GS 会进一步确定哪些 `tile` 与这些投影高斯相交。鉴于一个投影高斯可能覆盖多个 `tile`，一种合理的方法是**复制高斯**，为每个副本分配一个相关`tile`的标识符（即`tile ID` ）。(不用判断每个像素与高斯的距离，而是判断 tile 就简单多了)
![[Pasted image 20240403170054.png|500]]

- **并行渲染**。复制后，3D GS 会将各自的 `tile ID` 与每个高斯观察变换得到的深度值结合起来。这将产生一个未排序的字节列表，其中高位代表 `tile ID`，低位表示深度。
![[Pasted image 20240403170630.png|500]]
经过排序后的列表就可以直接用于渲染（即 Alpha 混合）。图 3c 和图 3d 直观地展示了这一概念。**值得强调的是，每个 `tile` 和像素的渲染都是独立进行的，因此这一过程非常适合并行计算**。另外一个好处是，每个 `tile` 的像素都可以访问共同的共享内存，并保持统一的读取顺序，从而提高 Alpha 混合的并行执行效率。**在原论文的正式实施中，该框架将 `tile` 和像素的处理分别视为类似于 CUDA 编程架构中的块和线程。**
![[Pasted image 20240403171115.png|345]]
简而言之，3D GS 在前处理阶段引入了若干近似值，以提高计算效率，同时保持高标准的图像合成质量。
## 3.2 3D GS 的优化

学习到这里，我们可能会有一个问题，怎么可能在空间中的一堆圆球中得到一个像样的图像的，确实是这样，如果没有进行优化，在渲染的时候就会出现很多伪影，从下图你可以看到。

![[daf16572a7052d15c0f22caa3e1584bd_MD5.png]]
>优化不足的场景


3D 高斯的核心是一个优化程序，旨在构建大量 3D 高斯集合，准确捕捉场景的本质，从而促进自由视点渲染。   
- 一方面，应通过**可微渲染**优化 3D 高斯的属性，以适应特定场景的纹理。
- 另一方面，能够很好地表现给定场景的 **3D 高斯的数量是未知的**。  

**让神经网络自动学习 3D 高斯的密度是一条很有前途的途径**。我们将在第 3.2.1 节中介绍如何优化每个高斯的属性，并在第 3.2.2 节中介绍如何控制高斯的密度。这两个过程在优化工作流程中交错进行。由于优化过程中有许多手动设置的超参数，为清晰起见，我们省略了大部分超参数的符号。

### 3.2.1 参数优化
- **损失函数**：图像合成后，计算渲染图像与真实图像 （ground truth）的差值作为损失：$$\mathcal{L}=(1-\lambda)\mathcal{L}_1+\lambda\mathcal{L}_{D-SSIM}$$ 其中 $λ$ 是权重因子，$\mathcal{L}_1$ 损失和 $D-SSIM$ 项是标准测量值。3DGS 的损失函数与 NeRF 的损失函数略有不同：**NeRF 通常在像素级别而不是图像级别进行计算，因此需要耗费大量的光线步进，而 3D GS 是图像级别的。**

- **参数更新**：3D 高斯的大多数属性都可以通过反向传播直接优化。需要注意的是，直接优化协方差矩阵 𝚺 可能会产生一个非正半定矩阵，这不符合协方差矩阵通常的物理解释。为了规避这个问题，三维 GS 选择优化四元数 𝒒 和三维向量 𝒔 。 𝒒 和 𝒔 分别代表旋转和缩放。通过这种方法可以重建协方差矩阵 𝚺 ：$$\Sigma=RSS^\top R^\top$$其中$R$ 与$S$ 分别由$q$ 和$s$ 推导得到的旋转和缩放矩阵。
- $R$ 是一个 3x3 的旋转矩阵，通过旋转四元数来表示
- $S$ 是一个对角缩放矩阵，含有 3 个参数


对于不透明度 $α$, 其计算图较为复杂：$(q,s)\to\Sigma\to\Sigma^{\prime}\to\alpha$。为避免自动微分的计算消耗，3DGS 还推导了 $q$ 与 $s$ 的梯度，在优化过程中直接计算之。

### 3.2.2 密度控制
- **初始化**。3DGS 建议从 SfM 产生的稀疏点云初始化或随机初始化高斯，可以直接调用 [COLMAP](https://colmap.github.io/) 库来完成这一步。然后，采用点的密集化和剪枝来控制 3D 高斯的密度。当由于某种原因无法获得点云时，可以使用随机初始化来代替，但可能会降低最终的重建质量。
![[Pasted image 20240403204005.png]]
>由 SfM 生成的稀疏 3D 点云

- **点密集化**：在点密集化阶段，3D GS 自适应地增加高斯的密度，以更好地捕捉场景的细节。该过程特别关注几何特征缺失或高斯过于分散的区域。**经过一定次数的迭代后，针对在视图空间中具有较大观察空间位置梯度（即超过特定阈值）的高斯进行密集化处理：包括在未充分重建的区域克隆小高斯或在过度重建的区域分裂大高斯。** 对于克隆，创建高斯的副本并向位置梯度移动。对于分裂，用两个较小的高斯替换一个大高斯，并以特定的系数缩小它们的比例。这一步骤旨在优化高斯在 3D 空间中的分布和表现，从而提高重建的整体质量。![[Pasted image 20240403204649.png]]
-  **点的剪枝**：点的剪枝阶段移除冗余或影响较小的高斯，可以在某种程度上看作是一种正则化过程。**这一步骤通过剔除几乎是透明的高斯（$α$ 低于指定阈值）和在世界空间或观察空间中过大的高斯**。**此外，为防止输入相机附近的高斯密度出现不合理地增加，在迭代一定次数后，高斯的 $α$ 值会被设置为接近于零**。这样既可以有控制地增加必要高斯的密度，又可以剔除多余的高斯。这一过程不仅有助于节省计算资源，还能确保模型中的高斯保持精确，有效地表现场景。

## 3.3 用 SH 系数来表示颜色
在计算机图形学中，用球谐函数（Spherical Harmonics，简称 SH）表示视角相关的颜色起着重要作用，在 Plenoxels 中他能表示非兰伯特效应，比如金属表面的高光反射。不过这样也不是一定的，实际上也可以使用 3 个 RGB 值表示颜色，然后使用 Gaussian Splatting。

图形学全局环境光照技术与球谐函数息息相关，我们的环境光来源四面八方，可以理解为一个球面函数，当模拟漫反射环境光，我们用一张环境贴图进行采样，对每一个点进行半球采样出在这个像素上的颜色，**球谐光照**简单来说就是用几个系数存取了整张环境贴图包围在球上**法线方向**所对应的的颜色信息。在渲染过程中传入球谐系数。在模型上根据对应的法线信息，从球谐函数中获取对应的颜色信息。

球谐函数是定义在球面上的特殊函数，换句话说，可以对球面上的任意点计算这样一个函数并得到一个值。

这里我们简单理解一下，SH，球谐函数，归根到底只是一组基函数，至于这组基函数是怎么来的，不管他。简单点来说，每一个函数都可以由多个基函数组合起来，如果我们有很多基函数，我们可以通过对应的权重系数复原出原来的函数，不过本质上还是一个有损压缩，不一定那么准确，不过如果基函数越多，复原的函数越准确，但是计算量也变大了。

在球面基函数中，最多的就是球谐函数了。球谐函数有很多很好的性质，比如正交性，旋转不变性（这边就不介绍了）。正交性说明每个基函数都是独立的，每个基函数都不能用别的基函数加权得到。当 SH 的系数用的越多，那么表达能力就越强，跟原始的函数就越接近。（如果更详细的了解可以看看一些原理，我主要是宏观的了解 SH 是什么，简单理解就是他是一种颜色的表示）
![[Pasted image 20240403204932.png]]
当用来描述不同方向光照的 SH 基函数，我们一般用二阶或者三阶，比如下面的例子就是 3 阶的
![[Pasted image 20240403204955.png]]
下面展示的是一个 l=2 和 3 阶的球谐函数，一共包括 9 个学习系数，我们可以根据点的视角得到相关颜色，可以看到最后是 red 红色分量。
![[Pasted image 20240403205009.png]]
>得到 l=2 和 9 个学习系数的点的视角相关颜色（红色分量）的过程

## 3.4 3DGS 流程
最后根据论文的图来总结一下 3DGS 的流程
![[Pasted image 20240403205034.png]]
1. **Structure from Motion**：使用 SfM 从一组图像中估计出点云，可以直接调用 [COLMAP](https://colmap.github.io/) 库操作![[accccedf9756f1d91c35266ffbd0626e_MD5.png]]

1. **Convert to Gaussians**：将每个点建模成一个 3D 高斯图像。从 SfM 数据中，我们能推断出每个高斯图像的位置和颜色。但如果是要得到更高质量的表征的话，还需要对每个高斯函数进行训练，以推断出更精细的位置和颜色，并推断出协方差和透明度。
    
2. **Training**：与神经网络类似，我们使用随机梯度下降法进行训练，但这里没有神经网络的层的概念 (都是 3D 高斯函数)。
    
    训练步骤如下:
    1. 用当前所有可微高斯函数渲染出图像
    2. 根据渲染图像和真实图像之间的差异计算损失
    3. 根据损失调整每个高斯图像的参数
    4. 根据情况对当前相关高斯图像进行点的密度控制
    
    步骤 1-3 比较简单，下面我们稍微解释一下第 4 步的工作:
    
    - 如果某高斯图像的梯度很大 (即它错得比较离谱)，则对其进行分裂或克隆
        - 如果该高斯图像很小，则克隆它
        - 如果该高斯图像很大，则将其分裂
    - 如果该高斯图像的 alpha 太低，则将其删除
    
    这么做能帮助高斯图像更好地拟合精细的细节，同时修剪掉不必要的高斯图像。
    
3. **Differentiable Gaussian Rasterization**：3D Gaussian Splatting 实际上是一种光栅化的方法，将数据成像到屏幕上，与其他方法相比，他有两个特点
    
    1. 快
    2. 可微
    
    主要步骤如下：
    1. 针对给定相机视角，把每个 3D 高斯投影到 2D。
    2. 按深度对高斯进行排序。
    3. 对每个像素，从前到后计算每个高斯在该像素点的值，并将所有值混合以得到最终像素值。

### 3DGS 优缺点

**优点**

1. 高品质、逼真的场景
2. 快速、实时的渲染
3. 更快的训练速度

**缺点**
1. 防止模型优化中的 “破碎” 的高斯：点太大、太长、冗余等
2. 更高的显存使用率 (4GB 用于显示，12GB 用于训练)
3. 更大的磁盘占用 (每场景 1GB+)
4. 与现有渲染管线不兼容
5. ~~只能重建静态场景（但是好像现在动态的 Gaussian 也出来了，所以这个不算缺点了）~~

# 4 应用领域和任务 APPLICATION AREAS AND TASKS
3D GS 的变革潜力远远超出了其理论和计算方面的进步。本节将深入探讨 3D GS 正在产生重大影响的各种开创性应用领域，如机器人、场景重建和表示、人工智能生成的内容、自动驾驶，甚至其他科学学科。
3D GS 的应用证明了它的多功能性和在各个领域带来变革的潜力。在此，我们将概述一些最著名的应用领域，并深入探讨 3D GS 如何在各个领域开辟新的疆域。
### 4.1 即时定位和建图（SLAM）
Simultaneous Localization and Mapping (SLAM)

SLAM 是机器人和自主系统的核心计算问题。它涉及机器人或设备在了解其在未知环境中的位置的同时绘制环境布局图的难题。SLAM 在自动驾驶汽车、增强现实和机器人导航等各种应用中都至关重要。SLAM 的核心是创建未知环境的地图，并实时确定设备在该地图上的位置。因此，SLAM 对计算密集型场景表示技术提出了巨大挑战，同时也是 3D GS 的良好试验平台。

3D GS 作为场景表示的一种创新方法进入了 SLAM 领域。**传统的 SLAM 系统通常使用点云或体素网格来表示环境**。相比之下，3D 高斯利用各向异性高斯来更好地表示环境。这种表示方法有以下几个优点
1. 效率高：三维高斯的密度可进行自适应控制，从而紧凑地表示空间数据，减少计算负荷。
2. 精确性：各向异性高斯可实现更详细、更精确的环境建模，尤其适用于复杂或动态变化的场景。
3. 三维高斯可适用于各种规模和复杂环境，因此可用于不同的 SLAM 应用。一些创新研究在 SLAM 中采用了 3D GS技术，展示了这一范例的潜力和多功能性。例如，GS-SLAM 在 SLAM 系统中引入了用于场景表示的三维高斯。该方法注重平衡效率和精度，大大改善了 RGB-D 贴图中的贴图优化和重新渲染过程。SplaTAM 演示了使用三维高斯对单个未摆放的单目 RGB-D 摄像机进行密集 SLAM。它解决了先前表示法的局限性，提高了渲染速度和地图精度。将神经渲染与 SLAM 相结合，Photo-SLAM 利用三维高斯实现了高效和高质量的映射。它展示了逼真绘图和渲染速度的显著提高，尤其是在便携式设备上。3D GS 在动态城市场景建模方面也取得了令人瞩目的成果。

## 4.2 动态场景建模
Dynamic Scene Modeling

动态场景建模是指捕捉和表现随时间变化的场景的三维结构和外观的过程。这包括创建一个数字模型，以准确反映场景中物体的几何形状、运动和视觉变化。  

动态场景建模在虚拟现实和增强现实、三维动画和计算机视觉等各种应用中至关重要。4D Gaussian Splatting（4D GS） 将 3D GS 的概念扩展到动态场景。  

它结合了时间维度，允许呈现和渲染随时间变化的场景。这种模式在保持高质量视觉输出的同时，还能显著改善动态场景的实时渲染。例如，[74, 73]侧重于扩展 3D GS，以建立动态场景模型。他们介绍了跟踪和表示移动场景元素的方法。[76、77、78、79、80、81] 为此提出了可变形模型或运动模型。[ 82, 83, 84] 探讨了动态场景中的新型应用和编辑功能。他们介绍了在 4D 空间中操作和编辑动态内容的创新框架，展示了高斯拼接技术在创意和互动场景中的多功能性。[ 76, 85] 强调提高效率和实时性能。他们提出了加快渲染和减少内存使用的优化方法，使高斯拼接技术在现实世界的应用更加实用。[ 86] 引入了先进的渲染技术，提高了动态场景建模的质量和速度。其重点是优化表示和渲染管道，以实现高分辨率的实时逼真效果。

## 4.3 AI 生成内容（AIGC）
AIGC 指人工智能系统自主创建或显著改变的数字内容，特别是在计算机视觉、自然语言处理和机器学习领域。AIGC 的特点是能够模拟、扩展或增强人类生成的内容，实现从逼真图像合成到动态叙事创作的各种应用。

AIGC 的意义在于它在娱乐、教育和技术开发等各个领域的变革潜力。在不断发展的数字内容创作领域，AIGC 是一个关键因素，它提供了可扩展、可定制、通常比传统方法更高效的替代方案。

3D GS 的这种显式特性促进了实时渲染能力以及前所未有的控制和可编辑水平，使其与 AIGC 应用高度相关。3D GS 的显式场景表示和可微分渲染算法完全符合 AIGC 的要求，即生成高保真、实时和可编辑的内容，这对虚拟现实、互动媒体等应用至关重要。

最近的一些作品有效地将 3D GS 与生成模型、头像和场景编辑等领域结合起来使用。例如，[ 91] 使用基于高斯拼接的文本到三维生成技术生成高质量的三维对象。[125]侧重于从单目视频中创建可动画化的人类头像，这是 AIGC 的一大进步，并实现了实时渲染帧率（50+ FPS）。[ 132] 扩展了 3D GS 的功能，包括开放世界 3D 场景中的分割和编辑。[ 131] 展示了 3D GS 在交互式场景操作和内绘中的应用，而 [ 130] 则展示了文本指令的类似可编辑性。

## 4.4 自动驾驶

自动驾驶的目标是在无人干涉的情况下导航并操作车辆，其主要目标是安全而高效地感知环境、做出决策和操作执行器。

其中，感知和理解环境需要实时重建驾驶场景，精确识别静态和动态物体，并理解其相互关系和运动。动态驾驶场景中，场景还会随时间连续变化。3DGS 可以通过混合数据点（如激光雷达点）将场景重建为连贯表达，有利于处理数据点变化的密度，以及静态背景和动态物体的精确重建。

# 5 性能比较
在这一部分，针对 3FGS 在上述的领域上的一些性能评估。

### 性能基准：定位
Localization

- 数据集：Replica。
- 基准算法：Gaussian-SLAM、GS-SLAM、SplaTAM、GSS-SLAM。
- 评估指标：均方根误差（RMSE）、绝对轨迹误差（ATE），测量传感器运动轨迹上真实位置与估计位置欧式距离的均方根。
- 结果：基于 3D 高斯的 SLAM 方法能超过基于 NeRF 的密集视觉 SLAM。

[![[bed19f003bbf68a589451dfd275c6646_MD5.png]]](https://picx.zhimg.com/80/v2-3277500ac5a850accdd2891db0595ae6.png)

### 性能基准：静态场景渲染
Rendering in Static Scenes

- 数据集：Replica。
- 基准算法：Gaussian-SLAM、GS-SLAM、SplaTAM、GSS-SLAM。
- 评估指标：峰值信噪比 (PSNR)、结构相似性 (SSIM)、学习的感知图像 patch 相似性 (LPIPS), 衡量 RGB 渲染性能。
- 结果：基于 3D 高斯的方法能超过基于 **NeRF** 的方法。
[![[bfabcbb75c2198d2f03ab715f1129e57_MD5.png]]](https://picx.zhimg.com/80/v2-94d0eea6ab0c03f32c82802f00a8102d.png)

### 性能基准：动态场景渲染
Rendering in Dynamic Scenes
- 数据集：D-NeRF。
- 基准算法：CoGS、4D-GS、GauFRe、4DGS。
- 评估指标：PSNR、SSIM、LPIPS, 用于衡量 RGB 渲染性能。
- 结果：3DGS 能大幅超过基于 NeRF 的 SOTA。但静态版本的 3DGS 对动态场景的重建是失败的。

[![[ded85ea29de519a60801a46e85e68296_MD5.png]]](https://picx.zhimg.com/80/v2-288ca353912cbbd221a111ee553ab607_720w.png)

### 性能基准：驾驶场景渲染
Rendering in Driving Scenes

- 数据集：nuScences。
- 基准算法：DrivingGaussian。
- 评估指标：PSNR、SSIM、LPIPS*（LPIPS× 1000）, 用于衡量 RGB 渲染性能。
- 结果：3DGS 方法能大幅超过基于 NeRF 的方法。

[![[6eea6b35a8aad50865659c42f00934c3_MD5.png]]](https://pic1.zhimg.com/80/v2-8b7bb910fbb86e3d1b23fc062260dc5d_720w.png)

### 性能基准：数字虚拟人
Human avatar

该任务的目标是从给定的多视角视频渲染人体化身模型。

- 数据集：ZJU-MoCap。
- 基准算法：GART、Human101、HUGS、3DGS-Avatar。
- 评估指标：PSNR、SSIM、LPIPS* (LPIPS×1000) , 用于衡量 RGB 渲染性能9
- 结果：基于 3DGS 的方法能在渲染质量和速度上均有优势。

[![[b174ff62b3de3608c38c125d6cc855c6_MD5.png]]](https://pica.zhimg.com/80/v2-d916a05d315e576e3cef738aa2306226.png)
# 6 未来研究方向 

近几个月来，3D GS 的后续工作取得了令人瞩目的成就，但我们认为仍存在一些有待克服的挑战。

- **数据高效的 3DGS 解决方案**：从有限的数据点生成新颖的视图和重建场景是人们非常关注的问题。尤其是因为它们具有以最少的输入增强真实感和用户体验的潜力。最近的进展是探索使用深度信息 [ 174, 175, 176]、密集概率分布 [ 177] 和像素到高斯映射 [ 178] 来促进这种能力。不过，这一领域仍急需进一步探索。此外，三维高斯的一个显著问题是，在观测数据不足的区域会出现伪影。这一挑战是辐射场渲染中普遍存在的限制，稀疏的数据往往会导致重建不准确。因此，在这些稀疏区域内开发新的数据插值或整合方法，是未来研究的一个大有可为的途径。
- **存储高效的 3DGS 解决方案**：虽然三维高分辨率图像处理技术展示了非凡的能力，但其可扩展性也带来了巨大挑战，尤其是在与基于 NeRF 的方法并列时。后者的优势在于只需存储学习 MLP 的参数。在大规模场景管理中，这种可扩展性问题变得日益突出，对计算和内存的需求大幅增加。因此，迫切需要在训练阶段和模型存储过程中优化内存利用率。探索更高效的数据结构和研究先进的压缩技术是解决这些限制的可行途径[179, 180, 181, 182]。
- **先进的渲染算法**：3D GS 当前的渲染流程非常直接，可以进一步优化。例如，简单的可见度算法可能会导致高斯深度/混合顺序的急剧变化。这凸显了未来研究的一个重要机遇：实施更先进的渲染算法。这些改进的方法应旨在更准确地模拟特定场景中光线与材料属性之间错综复杂的相互作用[ 183, 184]。一种很有前途的方法是将传统计算机制图的既定原则同化和调整到三维 GS 的特定环境中。在这方面值得注意的是，目前正在努力将增强型渲染技术[185, 186, 187, 188]或混合模型[189]整合到当前的三维图形学计算框架中。此外，对反渲染及其应用的探索[190, 191]也为研究提供了肥沃的土壤。
- **优化与正则化**： 各向异性高斯虽然有利于表示复杂几何体，但可能产生不希望的视觉伪影。例如，特别是在具有视角依赖外观的区域，大的 3D 高斯可能导致弹出伪影，突然出现或消失的视觉元素打破了沉浸感。使用正则化可以增加收敛速度，平滑视觉噪声或提高图像质量。此外，3DGS 中大量的超参数也会影响 3DGS 的泛化性。在 3DGS 的规则化和优化方面存在相当大的探索潜力。
- **3D 高斯在网格重建中的应用**：可探索 3DGS 在网格重建中的潜力，从而缩小体积渲染和传统基于表面的方法的差距，以便提出新的渲染技巧和应用。
- **赋予 3DGS 更多可能性**： 尽管 3DGS 具有显著潜力，但 3DGS 的全范围应用仍然未被充分挖掘。一个有前景的探索方向是用额外的属性增强 3D 高斯，例如为特定应用定制的语言和物理属性。此外，最近的研究开始揭示 3DGS 在多个领域的能力，例如相机姿态估计、捕捉手对象互动和不确定性量化。这些初步发现突出了跨学科学者进一步探索 3DGS 的重要机会。
# 总结
据我们所知，本研究首次全面介绍了 3D GS，这是一种革命性的显式辐射场和计算机制图技术。 
它描绘了传统 NeRF 方法的范式转变，强调了 3D GS 在实时渲染和增强可控性方面的优势。 
我们的详细分析证明了 3D GS 在实际应用中的优越性，尤其是那些需要实时性能的应用。我们对这一领域的前瞻性研究方向和尚未解决的挑战提出了见解。 
总之，3D GS 是一项变革性技术，将对 3D 重建和表示领域的未来发展产生重大影响。 
本调查报告旨在作为基础资源，推动这一快速发展领域的进一步探索和进步。
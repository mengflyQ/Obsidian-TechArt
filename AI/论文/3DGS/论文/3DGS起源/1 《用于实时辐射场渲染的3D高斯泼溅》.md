---
title: 1 《用于实时辐射场渲染的3D高斯泼溅》
uid: "202404032200"
create_time: 2024-04-03 21:59
title translation: 
grade: 
author: 
date: 
DOI: 
url: []
banner: "[[]]"
---

> [!abstract] 
最近，辐射场（Radiance Field）方法彻底改变了用多张照片或视频拍摄的场景的新视角合成。然而，要达到较高的视觉质量，仍然需要神经网络，而神经网络的训练和渲染成本很高，同时，最新的快速方法不可避免地要以速度换质量。对于无边界的完整场景（而不是孤立的物体）和 1080p 分辨率的渲染，目前没有一种方法能达到实时显示率。我们引入了三个关键要素，使我们能够实现最先进的视觉质量，同时保持有竞争力的训练时间，更重要的是，我们能够在 1080p 分辨率下实现高质量的实时（ ≥30 fps）新视角合成。
>
首先，从摄像机校准过程中产生的稀疏点开始，我们用三维高斯（3D Gaussians）来表示场景，这种三维高斯保留了用于场景优化的连续体积辐射场的理想特性，同时避免了在空白空间（empty space）进行不必要的计算；其次，我们对三维高斯进行交错优化/密度控制，特别是优化各向异性协方差，以实现对场景的精确表示；第三，我们开发了一种快速可见性感知渲染算法，该算法支持各向异性拼接，既能加速训练，又能实现实时渲染。我们在几个已建立的数据集上展示了最先进的视觉质量和实时渲染。
> 
>**Keywords:** novel view synthesis, radiance fields, 3D gaussians, real-time rendering  
>**关键词：** 新视图合成、辐射场、三维高斯、实时渲染

# 1 引言
Mesh和点是最常见的三维场景表示法，因为它们是显式的，非常适合基于 GPU/CUDA 的快速光栅化。相比之下，最新的神经辐照场（NeRF）方法建立在连续场景表示法的基础上，通常使用体积光线步进法优化多层感知器（MLP），对捕捉到的场景进行新视角合成。

同样，迄今为止最高效的辐射场解决方案也是建立在连续表示法的基础上，对存储在体素、哈希 grid 或点中的值进行插值。虽然这些方法的连续性有助于优化，但渲染所需的随机采样成本很高，而且会产生噪声。**我们引入了一种新方法，它结合了这两种方法的优点：我们的三维高斯表示法允许以最先进的（SOTA）视觉质量和有竞争力的训练时间进行优化，而我们基于 `tile` 的拼接解决方案确保了在之前发布的几个数据集（见图 1）上以 SOTA 质量进行 1080p 分辨率的实时渲染。**

![[Pasted image 20240403220617.png]] 
>图 1. 我们的方法实现了辐射场的实时渲染，其质量等同于之前质量最好的方法 (Barron et al., [2022](#bib.bib4))，而所需的优化时间与之前最快的方法 (Fridovich-Keil and Yu et al., [2022](#bib.bib14); Müller et al., [2022](#bib.bib33))相当。实现这一性能的关键在于新颖的三维高斯场景表示法与实时可微分渲染器的结合，这大大加快了场景优化和新颖视图合成的速度。请注意，在训练时间与 InstantNGP  (Müller et al., [2022](#bib.bib33)), 相当的情况下，我们获得了与他们相似的质量；虽然这是他们达到的最高质量，但通过 51 分钟的训练，我们获得了最先进的质量，甚至略优于 Mip-NeRF360 (Barron et al., [2022](#bib.bib4)).。

**我们的目标是对多张照片拍摄的场景进行实时渲染，并在典型真实场景中以与以往最高效方法同样快的优化速度创建表征。** 最近的方法实现了快速训练，但难以达到当前 SOTA NeRF 方法（即 Mip-NeRF360 方法）的视觉质量，后者需要长达 48 小时的训练时间。快速但质量较低的辐射场方法可以根据场景实现交互式渲染（每秒 10-15 帧），但无法实现高分辨率下的实时渲染。

我们的解决方案由三个主要部分组成。
1. 首先，我们引入 3D 高斯作为一种灵活而富有表现力的场景表示。我们从与之前的 NeRF 类似的方法相同的输入开始，即使用运动结构（SfM）校准的摄像机，并使用作为 SfM 过程一部分免费生成的稀疏点云初始化 3D 高斯集。与大多数需要多视图立体（MVS）数据的基于点的解决方案相比，我们只需将 SfM 点作为输入即可获得高质量的结果。
   需要注意的是，对于 NeRF-synthetic 数据集，即使采用随机初始化，我们的方法也能达到很高的质量。我们的研究表明，三维高斯是一个很好的选择，因为它们是一种可微分的体积表示法，但也可以通过将它们投影到二维，并应用标准的 Alpha 混合法，使用与 NeRF 相当的图像形成模型，非常高效地对它们进行光栅化处理。
2. 我们方法的第二个组成部分是优化三维高斯的属性--三维位置、不透明度 $、\alpha$ 、各向异性协方差和球谐（SH）系数等属性，并与自适应密度控制步骤交错进行，在优化过程中添加或偶尔删除三维高斯。通过优化程序，可以得到一个相当紧凑、非结构化和精确的场景表示（所有测试场景的高斯数均为 100-500 万）。
3. 我们方法的第三个也是最后一个要素是我们的实时渲染解决方案，它使用了快速 GPU 排序算法，并受到基于 tile 的光栅化的启发，沿用了最近的工作成果(Lassner and Zollhofer, [2021](#bib.bib28))。不过，得益于我们的三维高斯表示法，我们可以执行各向异性拼接，可见性排序（得益于排序和 Alpha 混合），并实现快速渲染。并根据需要跟踪遍历尽可能多的排序拼接，从而实现快速、准确的后向传递。

总之，我们做出了以下贡献：
- 引入各向异性三维高斯作为辐射场的高质量、非结构化表示。
- 一种三维高斯特性优化方法，与自适应密度控制交错使用，可为捕捉到的场景创建高质量的表现形式。
- 针对 GPU 的快速可微分渲染方法具有可视性感知功能，可通过各向异性拼接和快速反向传播实现高质量的新颖视图合成。

我们在之前发布的数据集上获得的结果表明，我们可以通过多视角捕捉优化三维高斯，并获得与之前最佳隐式辐射场方法相同或更好的质量。我们还能达到与最快方法类似的训练速度和质量，更重要的是，我们首次为新视角合成提供了高质量的实时渲染。

# 2 相关工作
我们首先简要介绍了传统重建，然后讨论了基于点的渲染和辐射场工作，并讨论了它们的相似性；辐射场是一个庞大的领域，因此我们只关注直接相关的工作。
>如需了解该领域的全部内容，请参阅近期出色的调查报告 (Tewari et al., [2022](#bib.bib50); Xie et al., [2022](#bib.bib55)).

略

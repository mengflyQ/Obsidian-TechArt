---
title: SuGaR
uid: "202404041611"
create_time: 2024-04-03 21:51
title translation: SuGaR： 用于高效 3D Mesh 重建和高质量 Mesh 渲染的曲面对齐的高斯泼溅
grade: 
author: 
date: 
DOI: 
url:
  - https://arxiv.org/abs/2311.12775
banner: "[[Pasted image 20240404161458.png]]"
---

**SuGaR: Surface-Aligned Gaussian Splatting** for Efficient 3D Mesh Reconstruction and High-Quality Mesh rendering

SuGaR： 用于高效 3D Mesh 重建和高质量 Mesh 渲染的**曲面对齐的高斯泼溅**

本问将 surface 译为曲面，将 Mesh 翻译为网格

> [!abstract] 
我们提出了一种方法，可以从三维高斯拼接中精确、快速地提取 Mesh。高斯拼接最近非常流行，因为它能产生逼真的渲染效果，同时训练速度明显快于 NeRFs。然而，从数百万个微小的三维高斯中提取网格是一项挑战，因为这些高斯在优化后往往是无序的，而且迄今为止还没有提出任何方法。
>
**我们的第一个关键贡献是一个正则化项**（regularization term），它能促使高斯与场景曲面保持一致。与通常用于从神经 SDF 中提取网格的 Marching Cubes 算法相比，这种方法快速、可扩展并能保留细节。**最后，我们引入了一种可选的改进策略，将高斯绑定到网格曲面，并通过高斯拼接渲染对这些高斯和网格进行联合优化。**
>
这样就可以通过操作网格而不是高斯模型本身，轻松对高斯模型进行编辑、雕刻、动画制作和重新照明。使用我们的方法，只需几分钟就能检索出这样一个可编辑的网格进行逼真渲染，而使用 SDF 的先进方法则需要数小时，同时还能提供更好的渲染质量。


![[Pasted image 20240404161458.png]]
>图 1：我们介绍了一种方法，可在几分钟内通过单个 GPU 从三维高斯拼接表示法中提取精确且可编辑的网格。这些网格可以编辑、动画、合成等。它具有非常逼真的高斯溅射渲染效果，为计算机图形学提供了新的可能性。例如，在左下方的捕捉场景和右边的合成场景之间，我们改变了机器人的姿势。补充材料提供了更多示例，包括一段展示我们成果的视频。

![[Pasted image 20240404161903.png]] 
>图 2：我们的算法可以在单个 GPU 上几分钟内从任何三维高斯拼接场景中提取高度精细的网格（上图：无纹理网格的渲染图，下图：有边界高斯（bound Gaussians）的网格渲染图）。

# 1 引言
继 NeRFs 之后，三维高斯拼接技术最近在捕捉三维场景并从新视角对其进行渲染方面变得非常流行。
三维高斯拼接技术以一组场景训练图像为基础，优化许多微小三维高斯的位置、方向、外观（以球谐函数表示）和 alpha 混合，以捕捉场景的几何形状和外观。由于渲染高斯比渲染神经场要快得多，因此 3D 高斯拼接比 NeRF 快得多，可以在几分钟内捕捉到一个场景。
虽然高斯模型可以非常逼真地渲染场景，但要从中提取场景的曲面仍然具有挑战性：如图 3 所示，**经过三维高斯拼接优化后，高斯一般不具有有序结构，与实际场景曲面的对应关系并不理想。**
![[Pasted image 20240404162327.png]] >>
>图 3：从高斯模型中提取网格。在没有正则化的情况下，优化后的高斯没有特殊的排列方式，这使得提取网格非常困难。如果没有我们的正则化项，Marching Cubes 无法提取可接受的网格。有了我们的正则化项，即使是非常精细的三维网格，Marching Cubes 也能恢复出噪声极高的网格。我们的可扩展提取方法即使在没有正则化项的情况下也能获得网格。但是，网格噪声仍然很大。相比之下，我们的完整方法能非常高效地重建精确网格。

除了曲面本身外，通常还需要将场景表示为网格，这在许多管线中仍是首选的表示方法：基于网格的表现形式可以提供强大的编辑、雕刻、动画和场景重光工具。**由于高斯拼接后的高斯是非结构化的，因此从中提取网格非常具有挑战性。需要注意的是，这对 NeRFs 也同样具有挑战性，只是原因不同而已。**

在本文中，**我们首先提出了一个正则化项，鼓励高斯在场景曲面良好分布，这样高斯就能更好地捕捉场景的几何形状**，如图 3 所示。**我们的方法是在假设高斯平坦且在场景曲面分布良好的前提下，从高斯中推导出体积密度。**

**在优化过程中，通过<mark style="background: #FF5582A6;">最小化该密度与根据高斯计算的实际密度之间的差异</mark>，我们鼓励三维高斯很好地表现曲面几何形状。**

有了这个正则化项，从高斯模型中提取网格就变得容易多了。**事实上，由于我们引入了一个密度函数来评估正则化项，因此一个自然的方法就是提取这个<mark style="background: #FF5582A6;">密度函数的水平集（level sets）**</mark>。然而，高斯拼接技术会进行密集化处理，以便高保真地捕捉场景细节，从而导致高斯数量急剧增加。真实场景中通常会有一个或数百万个不同比例和旋转的三维高斯，为了再现场景中的纹理和细节，大部分高斯都非常小。这导致密度函数几乎处处接近于零，而 Marching Cubes 算法即使使用精细的体素网格也无法提取这种稀疏密度函数的适当水平集，如图 3 所示。

相反，**我们引入了一种方法，可以非常高效地对密度函数水平集可见部分的点进行采样，从而在这些点上运行<mark style="background: #FF5582A6;">泊松重建算法</mark>，获得三角形网格。** 与 "Marching Cubes"算法等相比，这种方法具有可扩展性，在单个 GPU 上几分钟内就能重建曲面网格，而其他依靠神经 SDF 从辐射场提取网格的先进方法，在单个 GPU 上至少需要 24 小时，并且需要多个 GPU 来加快进程。

如图 2 和图 4 所示，我们的方法可以生成高质量的网格。**我们面临的挑战是如何有效地识别水平集上的点。为此，我们依靠从训练视点看到的高斯深度图。** 这些深度图可以通过扩展高斯拼接光栅化器来获得，我们将展示如何从这些深度图出发，对水平集上的点进行精确采样。 

**最后，在提取该网格后，我们提出了一种可选的改进策略，即仅通过高斯拼接渲染来联合优化网格和一组三维高斯。** 通过这种优化，可以使用高斯溅射渲染技术而不是传统的纹理网格渲染技术，实现高质量的网格渲染。

因此，与其他依赖底层网格进行推理的辐射场模型相比，高斯拼接模型具有更高的渲染质量性能[39, 6, 26]。如图 1 所示，这使得使用传统的网格编辑工具编辑场景的高斯拼接表示成为可能，为计算机图形学提供了无限可能。

总之，我们的贡献是
- 一个正则化项，使高斯模型能准确捕捉场景的几何形状；
- 一种高效的算法，能在几分钟内从高斯模型中提取出精确的网格；
- 这种方法可将高斯绑定到网格上，从而获得更精确的网格，与目前使用网格进行新视图合成的方法相比，渲染质量更高，并允许以多种不同方式编辑场景。

# 2 相关工作
基于图像的渲染（IBR）方法依赖于一组场景的二维图像来生成场景表示并渲染新视图。最早的新视图合成方法基于光场，并提出了新视图的体积渲染概念。他们的工作强调了高效遍历体积数据以生成逼真图像的重要性。此后，人们提出了各种场景表示法，如三角形网格、点云、体素网格、多平面图像或神经隐函数。

## 2.1 基于网格的传统 IBR 方法

运动恢复结构（SfM）和随后的多视角立体（MVS）允许对曲面进行三维重建，从而开发出几种依赖三角形网格作为场景主要三维表示的视图合成算法。这些算法考虑了纹理三角形，或将捕捉到的图像在网格曲面进行扭曲和混合，以生成新的视图[37, 4, 12]。[29, 30]考虑了基于深度学习的网格表示法，以实现更好的视图合成，弥补了传统图形学与现代机器学习技术之间的差距。虽然这些基于网格的方法利用了现有的图形硬件和软件来实现高效渲染，但在复杂区域捕捉精确的几何图形和外观方面仍有困难。

## 2.2 体积式 IBR 方法

体积法使用体素网格、多平面图像或神经网络，将场景表示为密度和颜色的连续体积函数。最近，神经辐射场（NeRF）引入了一种基于连续体积函数的新型场景表示法，该函数由多层感知器（MLP）参数化。NeRF 通过体积光线追踪技术生成具有精细细节和视图效果的逼真渲染效果。然而，最初的 NeRF 计算成本很高，而且占用大量内存。为了应对这些挑战，一些研究工作提高了 NeRF 的性能和可扩展性。这些方法利用像素网格（voxel grids）和哈希表等离散或稀疏的体积表示法来存储可学习的特征，作为三维点的位置编码、分层采样策略或低秩近似。
然而，它们仍然依赖于体积光线步进，这与为渲染多边形曲面而设计的标准图形硬件和软件不兼容。最近的研究提出了修改 NeRF 对几何体和发射辐射的表示，以便更好地重建镜面材料，或通过将材料和照明属性明确分解来重新照明场景。

## 2.3 混合 IBR 方法
有些方法建立在可微分渲染的基础上，结合了基于网格和体积方法的优势，可以进行曲面重建，并具有更好的可编辑性。这些方法采用体积-曲面混合表示法，可生成适合下游图形应用的高质量网格，同时有效地模拟视图相关外观。

特别是，一些研究通过训练神经辐射场来优化神经有向距离场（SDF），其中密度是作为 SDF 的可微分变换导出的。最后，通过应用 Marching Cubes 算法[21]，可以根据 SDF 重建三角形网格。然而，这些方法大多不以实时渲染为目标。

另外，还有一些方法将优化的 NeRF 或神经 SDF 的渲染能力 "烘焙 "成一种高效的结构，这种结构依赖于底层三角形网格，可以从传统的三角形光栅化管道中受益。特别是最近的 BakedSDF，它通过优化完整的神经 SDF 模型，将其烘焙到高分辨率的三角形网格中，结合网格渲染来插值特征，并通过深度学习将这些特征转化为图像，最后优化与视图相关的外观模型，从而重建高质量的网格。然而，尽管它能实现实时渲染并生成令人印象深刻的场景曲面网格，但该模型需要训练一个完整的神经 SDF，其架构与 Mip-NeRF360 完全相同，这就需要 48 小时的训练。

同样，最近的 NeRFMeshing [26] 方法也提出将任何 NeRF 模型烘焙成网格结构，从而实现实时渲染。然而，这种方法中执行的网格划分降低了渲染质量，导致 PSNR 远远低于我们的方法。此外，这种方法仍然需要事先训练一个完整的 NeRF 模型，并且需要在 8 个 V100 NVIDIA GPU 上进行大约一个小时的训练，以便进行网格训练和提取。

我们的方法从三维高斯拼接中获取三维网格的速度要快得多，这本身就比 NeRFs 快得多。正如我们的实验所显示的，我们通过将高斯限定在网格上进行的渲染比以前基于网格的解决方案质量更高。

## 2.4 基于点的 IBR 方法
另外，基于点的辐射场表示法擅长对薄几何体建模，并利用快速的点光栅化管道，使用 $\alpha$ 混合而非光线步进来渲染图像。特别是最近推出的 3D 高斯拼接模型，可以优化和渲染场景，其速度和质量都是前所未有的。

# 3 3D高斯泼溅
为完整起见，我们在此简要介绍一下原始的 3D 高斯拼接方法。场景表示为一组（大）高斯，其中每个高斯 $g$ 由其平均值 $\mu_g$ 表示，其协方差 $\Sigma_g$ 由缩放向量 $s_g∈ℝ3$ 和编码高斯旋转的四元数 $q_g∈ℝ4$ 参数表示。此外，每个高斯都与其不透明度 $\alpha_g∈[0,1]$ 和一组球谐坐标相关联，这组球谐坐标描述了高斯在所有方向上发出的颜色。

通过光栅化器，一组高斯图像可以从给定视角进行渲染。该光栅器可将三维高斯图拼接成与图像平面平行的二维高斯图进行渲染，从而实现极快的渲染过程。这是 3D 高斯拼接比 NeRFs 快得多的关键因素，因为它比 NeRFs 优化所需的光线行进合成快得多。

在给定一组图像的情况下，根据 SfM 生成的点云初始化高斯集。高斯参数（均值、四元数、缩放矢量以及不透明度和球谐参数）经过优化，使高斯的渲染效果与输入图像相匹配。在优化过程中，会添加更多的高斯，以更好地适应场景的几何形状。因此，高斯拼接通常会产生具有数百万个高斯的场景，这些高斯可能非常小。

# 4 方法

本节将介绍我们的 SuGaR：
- 首先，我们详细介绍了在高斯拼接优化过程中强制三维高斯与场景曲面对齐的损失项（loss term）。
-  然后，我们详细介绍了我们的方法，该方法利用这种对齐方式，在单个 GPU 上几分钟内就能从高斯中提取出高度精细的网格。
- 最后，我们介绍了我们的可选改进策略（refinement strategy），该策略利用高斯拼接渲染技术对网格和网格曲面的三维高斯进行联合优化。该策略可生成一组绑定到可编辑网格上的新高斯。

### 4.1 将高斯线与曲面对齐
如导言所述，为了便于根据高斯创建网格，我们在高斯拼接优化中引入了一个正则化项，促使高斯与场景表面对齐，并在该表面上均匀分布。

我们的方法是在假设高斯具有所需属性的前提下，从高斯中推导出一个 SDF。通过最小化该 SDF 与为高斯计算的实际 SDF 之间的差值，我们鼓励高斯具有这些特性。

对于给定的高斯拼接场景，我们首先要考虑的是相应的密度函数 $d:ℝ^3→ℝ_+$，计算方法是在任意空间位置 $p$ 上，高斯值与 $\alpha$ 混合系数的加权和：
$$
d(p)=\sum_g\alpha_g\exp\left(-\frac{1}{2}(p-\mu_g)^T\Sigma_g^{-1}(p-\mu_g)\right)
$$
其中 $\mu_g$ 、 $\Sigma_g$ 和 $\alpha_g$ 分别是高斯的中心、协方差和阿尔法混合系数。让我们考虑一下，如果高斯分布良好并与表面对齐，密度函数会变成什么样子。
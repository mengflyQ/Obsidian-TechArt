---
title: 《鱼书》
aliases: 
tags: 
create_time: 2023-04-25 23:45
uid: 202304252345
banner: "[[深度学习入门：基于Python的理论与实现_page0_image.png]]"
banner_y: 0.7475
---
> [!NOTE] 约定
> 本书以图像识别为主题，主要学习使用深度学习进行图像识别时所需的技术。自然语言处理或者语音识别等不是本书的讨论对象。
> 
> 本书将使用下列编程语言和库：
> - Python 3. x
> - NumPy
> - Matplotlib

> [!NOTE] NumPy
> NumPy 数组（np. array）可以生成 N 维数组，即可以生成一维数组、二维数组、三维数组等任意维数的数组。数学上将一维数组称为**向量**，将二维数组称为**矩阵**。另外，可以将一般化之后的向量或矩阵等统称为**张量（tensor）**。
> **本书基本上将二维数组称为“矩阵”，将三维数组及三维以上的数组称为“张量”或“多维数组”。**

[【啃书】《深度学习入门 基于Python的理论与实现》第3章 神经网络_凯旋16668的博客-CSDN博客](https://blog.csdn.net/weixin_44331401/article/details/117636609)

# 第 2 章感知机

## 2.1 感知机是什么
严格称为“人工神经元”或“朴素感知机”
**感知机的定义：** 感知机接收多个输入信号，输出一个信号。  

感知机的信号也会形成流，向前方输送信息。但是，和实际的电流不同的是，感知机的信号只有“流 / 不流 ” $(1/0)$ 两种取值。**在本书中，$0$ 对应“不传递信号”，$1$ 对应“传递信号”。**

神经元会计算传送过来的信号的总和，只有当这个总和超过了某个界限值时，才会输出 1。这也称为“神经元被激活”。这个界限称为阈值，用 $\theta$ 表示
![[Pasted image 20231107153216.png]]
（y：输出，x：输入，θ：阈值）

上述内容用数学式表示：
![[Pasted image 20231107153247.png]]
## 2.2 简单逻辑电路

①**与门**（AND gate）  
与门仅在两个输入均为 1 时输出 1，其他时候则输出 0。  

②**与非门**（NAND gate）  
与非门仅当 x1 和 x2 同时为 1 时输出 0，其他时候则输出 1。  

  
③**或门**（OR gate）  
或门是只要有一个输入信号是 1，输出就为 1。  

## 2.3 感知机的实现

把 2.1 公式中的θ换成 - b，则可表示为：  
![[Pasted image 20231107153325.png]]
（w1 和 w2 称为权重，b 称为偏置）  

$w_1$ 和 $w_2$ 是控制输入信号的重要性的参数

偏置 $b$ 是调整神经元被激活的容易程度的参数 (越大越容易输出 1)。（根据上下文，有时也会将 b、w1、w2 这些参数统称为权重。）

## 2.4 感知机的局限性
### 异或门
异或门：仅当 x1 和 x2 中的一方为 1 时，才会输出 1。  （速记：两个值不相等则为 1）
单层感知机无法实现异或门，后文所讲的叠加多层感知机即可实现

![[Pasted image 20231107153505.png]]
### 线性/非线性
发现问题：通过画图可知，因为与门、或门和与非门表现的区域可以用一条直线分割，**而异或门表现的区域只能用曲线分割**。所以用感知机可以实现与门、与非门、或门，却无法实现异或门。  
感知机的**局限性**就在于“单层感知机无法表示异或门”或者“单层感知机无法分离非线性空间 "。通过组合感知机（叠加层）就才可以实现异或门 

图例：
感知机：![[Pasted image 20230504100248.png]]
或门： ![[Pasted image 20230504100254.png]]
或门在 (x1, x2) = (0, 0) 时输出 0，在 (x1, x2) 为 (0, 1)、(1, 0)、(1, 1) 时输出 1。如果想制作或门，需要用直线将○和△分开。实际上，这条直线就将这 4 个点正确地分开了。

而异或门则不能用一条直线分开：
![[Pasted image 20230504100422.png]]
![[Pasted image 20230504100625.png]]

曲线分割而成的空间称为**非线性空间**，
由直线分割而成的空间称为**线性空间**。

## 2.5 多层感知机

感知机可以通过” 叠加层 “来表示异或门。  
![[Pasted image 20231107153842.png]]

![[Pasted image 20230504102346.png]]
图 2-13 中的感知机总共由 3 层构成，但是因为拥有权重的层实质上只有 2 层（第 0 层和第 1 层之间，第 1 层和第 2 层之间），所以称为“**2 层感知机**”。
不过，有的文献认为图 2-13 的感知机是由 3 层构成的，因而将其称为“3 层感知机”。 

# 第 3 章 神经网络
神经网络的一个重要性质是它可以**自动地从数据中学习到合适的权重参数。**

## 3.1 从感知机到神经网络

![[Pasted image 20231107154340.png]]

> [!NOTE] 
>- 我们把最左边的一列称为**输入层**，最右边的一列称为**输出层**，中间的一列称为**中间层。中间层有时也称为隐藏层**。本书中把输入层到输出层依次称为第 0 层、第 1 层、第 2 层 
>- 本书将根据实质上拥有权重的层数（输入层、隐藏层、输出层的总数减去 1 后的数量）来表示网络的层树。

回顾一下感知机：
$y=\begin{cases}0&(b+w_1x_1+w_2x_2\leqslant0)\\[6pt]1&(b+w_1x_1+w_2x_2>0)\end{cases}$

  改写成更简洁的形式，用 $h(x)$ 函数表示这种分情况的动作：
  $$
y=h(b+w_1x_1+w_2x_2)
$$
$$h(x)=\left\{\begin{array}{cc}0&(x\leqslant0)\\ 1&(x>0)\end{array}\right.
$$
  ![[Pasted image 20231107154749.png]]
上图添加了权重为 b 的输入信号 1（表示偏置）。这个感知机将 x1、x2、1 三个信号作为神经元的输入，将其和各自得权重相乘后，传送至下一个神经元。在下一个神经元中，计算这些加权信号的总和。如果这个总和超过 0，则输出 1，否则输出 0。  

### 3.1.3 激活函数登场

**激活函数的定义：像上面的 h(x)函数会将输入信号的总和转换为输出信号，这种函数一般称为激活函数（activation function）。**

如 “激活” 一词所示，**激活函数的作用在于决定如何来激活输入信号的总和。**  

进一步改写上一节的式子：首先，计算加权输入信号和偏置的总和，记为 a。然后，用 $h(a)$ 函数将 $a$ 转换为输出 $y$。
$$
\begin{matrix}a=b+w_1x_1+w_2x_2\\ \\ y=h(a)\end{matrix}
$$

![[Pasted image 20231111093459.png]]
>信号的加权总和为节点 $a$，然后节点 $a$ 被激活函数 $h ()$ 转换成节点 $y$ 

> [!NOTE] Title
> 本书中，“ 神经元”和“节点”两个术语的含义相同。这里，我们称 a 和 y 为“节点”，其实它和之前所说的“神经元”含义相同。神经元用一个○表示


> [!tip] 
> 本书在使用“感知机”一词时，没有严格统一它所指的算法。一般而言，**“朴素感知机”是指单层网络，指的是激活函数使用了阶跃函的模型。
> “多层感知机”是指神经网络，即使用 sigmoid 函数（后述）等平滑的激活函数的多层网络。** 

## 3.2 激活函数 (输出)

> [!NOTE] 输出层选择激活函数
> 输出层所用的激活函数，要根据求解问题的性质决定。一般地：
> **回归问题**可以使用恒等函数
> **二元分类问题**可以使用 sigmoid 函数
> **多元分类问题**可以使用 softmax 函数

> [!NOTE] 分类问题和回归问题
> 机器学习的问题大致可以分为分类问题和回归问题。分类问题是数据属于哪一个类别的问题。回归问题是根据某个输入预测一个（连续的） 数值的问题 

### 阶跃函数
上文中，感知机使用的激活函数被称为“**阶跃函数**”：以阈值为界，一旦输入超过阈值，就切换输出。
$$h(x)=\left\{\begin{array}{cc}0&(x\leqslant0)\\ 1&(x>0)\end{array}\right.
$$
![[Pasted image 20230504104323.png]]
阶跃函数以 0 为界，输出从 0 切换为 1（或者从 1 切换为 0）。它的值呈阶梯式变化，所以称为阶跃函数。

如果**将激活函数从阶跃函数换成其他函数，就可以进入神经网络的世界了。**
**激活函数是连接感知机和神经网络的桥梁。**  

上一章介绍的感知机和接下来要介绍的神经网络的主要区别就在于这个激活函数。其他方面，比如神经元的多层连接的构造、信号的传递方法等，基本上和感知机是一样的。 
### sigmoid 函数
“S 型函数”
$$h(x)=\dfrac{1}{1+\exp(-x)}$$
$exp(−x)$ 表示 $e^{−x}$ 的意思，e 是纳皮尔常数 2.7182...

```python title:sigmoid函数
def sigmoid(x):    
    return 1 / (1 + np.exp(-x))
```

对比阶跃函数：
不同点：
1. 平滑性不同，sigmoid 函数的平滑性对神经网络的学习具有重要意义。
![[Pasted image 20230504104947.png]]
2. 相对于阶跃函数只能返回 0 或 1，sigmoid 函数可以返回 0.731 ...、0.880 ... 等实数（这一点和刚才的平滑性有关）。也就是说，**感知机中神经元之间流动的是 0 或 1 的二元信号，而神经网络中流动的是连续的实数值信号**。

**相同点：**
1. 从宏观视角看图 3-8，可以发现它们具有相似的形状。实际上，两者的结构均是“输入小时，输出接近 0（为 0）；随着输入增大，输出向 1 靠近（变成 1） 
2. 不管输入信号有多小，或者有多大，输出信号的值都在 0 到 1 之间。
3. 两者均为非线性函数。**神经网络的激活函数必须使用非线性函数**。换句话说，激活函数不能使用线性函数。线性函数的问题在于，**不管如何加深层数，总是存在与之等效的 “无隐藏层的神经网络”**

为了具体地（稍微直观地）理解这一点，我们来思考下面这个简单的例子。这里我们考虑把线性函数 $h(x) = cx$ 作为激活函数，把 $y(x)=h(h(h(x)))$ 的运算对应 3 层神经网络 A。这个运算会进行 $y (x) = c × c × c × x$ 的乘法运算，但是同样的处理可以由 $y (x) = ax$（注意，$a=c^3$）这一次乘法运算（即没有隐藏层的神经网络）来表示。
如本例所示，**使用线性函数时，无法发挥多层网络带来的优势。因此，为了发挥叠加层所带来的优势，激活函数必须使用非线性函数。**

> [!NOTE] 线性/非线性
> 线性函数是一条笔直的直线，如 $h(x)=kx$。而非线性函数，顾名思义，指的是不像线性函数那样呈现出一条直线的函数。 

### ReLU 函数
在神经网络发展的历史上，sigmoid 函数很早就开始被使用了，而最近则主要使用 ReLU（线性整流函数，又称修正线性单元 Rectified Linear Unit）函数。
$$
h(x)=\left\{\begin{array}{cc}x&(x>0)\\ 0&(x\leqslant0)\end{array}\right.
$$
ReLU 函数在输入大于 0 时，直接输出该值；在输入小于等于 0 时，输出 0 

![[Pasted image 20231111094252.png]]

```python title:ReLU函数
def relu(x):
    return np.maximum(0, x)
```

### 恒等函数
恒等函数会将输入按原样输出，对于输入的信息，不加以任何改动地直接输出。
![[Pasted image 20231111094458.png]]
### softmax 函数
$$
y_k=\dfrac{\exp(a_k)}{\sum\limits_{i=1}^n\exp(a_i)}
$$
$exp (x)$ 是表示 $e^x$ 的指数函数。上表示假设输出层共有 $n$ 个神经元，计算第 $k$ 个神经元的输出 $y_k$。 $softmax$ 函数的分子是输入信号 $a_k$ 的指数函数，分母是所有输入信号的指数函数的和。  
![[Pasted image 20231111094555.png]]
**softmax 函数的输出通过箭头与所有的输入信号相连。这是因为，从公式中可以看出，输出层的各个神经元都受到所有输入信号的影响。所以，softmax 回归的输出层也是全连接层。**

上述 softmax 函数会发生**溢出问题**，因为进行指数级别的运算，值可能会变得非常大，超过计算机可以表示的位数。可以进行如下改进：
$$
\begin{aligned}y_k=\frac{\exp(a_k)}{\sum_{i=1}^n\exp(a_i)}&=\frac{C\exp(a_k)}{C\sum_{i=1}^n\exp(a_i)}\\ &=\frac{\exp(a_k+\log C)}{\sum_{i=1}^n\exp(a_i+\log C)}\\  &=\frac{\exp(a_k+C')}{\sum_{i=1}^n\exp(a_i+C')}\end{aligned}
$$
首先，在分子和分母上都乘上 C 这个任意的常数（因为同时对 分母和分子乘以相同的常数，所以计算结果不变）。然后，把这个 C 移动到指数函数（exp）中，记为 log C。最后，把 log C 替换为另一个符号 $C’$。
在进行 softmax 的指数函数的运算时，加上（或者减去） 某个常数并不会改变运算的结果。**这里的 $C’$ 可以使用任何值，但是为了防止溢出，一般会使用输入信号中的最大值。通过减去输入信号中的最大值，得到正确的运算结果**
```python title:softmaxh函数
def softmax(a): 
    c = np.max(a)
    exp_a = np.exp(a - c) # 溢出对策 
    sum_exp_a = np.sum(exp_a) 
    y = exp_a / sum_exp_a
    return y
```


#### softmax 函数的特征

![[Pasted image 20231111094711.png]]
  
- softmax 函数的输出是 0.0 到 1.0 之间的实数。  
- **softmax 函数的输出总和为 1 是 softmax 函数的一个重要性质，正因为有了这个性质，可以把 softmax 函数的输出解释为 “概率”。**  
- 数组 a 中元素的大小关系和输出 y 中元素的大小关系一致，**即使用了 softmax 函数，各个元素之间的大小关系也不会改变。**

一般而言，**神经网络只把输出值最大的神经元所对应的类别作为识别结果**。
**在实际的问题中，由于指数函数的运算需要一定的计算机运算量，因此输出层的 softmax 函数一般会被省略。**

> [!NOTE] 学习和推理
> 求解机器学习问题的步骤可以分为“学习（也称为训练）” 和“推理”两个阶段。
> 
> 首先，在学习阶段进行模型的学习，然后，在推理阶段，用学到的模型对未知的数据进行推理（分类）。如前所述，**推理阶段一般会省 略输出层的 softmax 函数。** 

## 3.3 多维数组的运算

```c
import numpy as np
np.ndim(A)：获得数组A的维数
A.shape：获得数组的形状
np.dot(A,B)：返回A与B数组的乘积
```

下面我们使用 NumPy 矩阵来实现神经网络。这里我们以图 3-14 中的简单神经网络为对象。这个神经网络省略了偏置和激活函数，只有权重。
![[1681573992351]]
```python>>> X = np.array([1, 2]) 
>>> X.shape
(2,)
>>> W = np.array([[1, 3, 5], [2, 4, 6]]) 
>>> print(W)
[[1 3 5] 
 [2 4 6]] 
>>> W.shape
(2, 3)
>>> Y = np.dot(X, W) 
>>> print(Y)
[ 5  11  17]
```
## 3.4 3 层神经网络的实现

这里书中的图解讲的很详细, P56

## 3.5 输出层的神经元数量

输出层的神经元数量需要根据待解决的问题来决定。**对于分类问题，输出层的神经元数量一般设定为类别的数量。** 比如，对于手写数字识别，即某个输入图像，预测是图中的数字 0 到 9 中的哪一个的问题（10 类别分类问题），可以如下图所示，将输出层的神经元设定为 10 个。其中神经元 y2 颜色最深，输出的值最大。这表明这个神经网络预测的是 y2 对应的类别，也就是 “2”。  
![[Pasted image 20231111095054.png]]

# 第 4 章 神经网络的学习
**“学习”是指从训练数据中自动获取最优权重参数的过程。** 
 
本章中，为了使神经网络能进行学习，将导入损失函数这一指标。而**学习的目的就是以该损失函数为基准，找出能使它的值达到最小的权重参数。** 
为了找出尽可能小的损失函数的值，本章我们将介绍利用了函数斜率的梯度法。
## 4.1 从数据中学习
**神经网络的特征就是可以从数据中学习。所谓“从数据中学习”，是指可以由数据自动决定权重参数的值。**
感知机的例子中，我们对照着真值表，人工设定了参数的值，但是那时的参数只有 3 个。而在实际的神经网络中，参数的数量成千上万，在层数更深的深度学习中，参数的数量甚至可以上亿，想要人工决定这些参数的值是不可能的。

> [!NOTE] Title
> 对于线性可分问题，第 2 章的感知机是可以利用数据自动学习的。 根据“感知机收敛定理”，通过有限次数的学习，线性可分问题是可 解的。但是，非线性可分问题则无法通过（自动）学习来解决。
### 数据驱动
数据是机器学习的核心。这种数据驱动的方法，也可以说脱离了 过往以人为中心的方法。

以识别数字 5 的算法为例：
![[Pasted image 20230504114413.png]]
机器学习方案：先从图像中提取特征量，再用机器学习技术学习这些特征量的模式。图像的特征量通常表示为向量的形式，特征量仍是由人设计的。
神经网络（深度学习）方案：不存在人为的介入。神经网络直接学习图像本身，在神经网络中，连图像中包含的重要特征量也都是由机器来学习的。
![[Pasted image 20230504114915.png]]


> [!NOTE] 
> 深度学习有时也称为端到端机器学习（end-to-end machine  learning）。这里所说的端到端是指从一端到另一端的意思，也就是 从原始数据（输入）中获得目标结果（输出）的意思。 

神经网络的优点是对所有的问题都可以用同样的流程来解决。无论是识别什么，神经网络都是通过不断地学习所提供的数据，尝试发现待求解的问题的模式。也就是说，**与待处理的问题无关，神经网络可以将数据直接作为原始数据，进行“端对端” 的学习。**
### 训练数据和测试数据
机器学习中，一般将数据分为**训练数据**和**测试数据**两部分来进行学习和实验等。
- 首先，使用训练数据进行学习，寻找最优的参数。
- 然后，使用测试数据评价训练得到的模型的实际能力。

为什么需要将数据分为训练数据和测试数据呢？因为我们追求的是模型的泛化能力。为了正确评价模型的泛化能力，就必须划分训练数据和测试数据。另外，**训练数据也可以称为监督数据**。
**泛化能力是指处理未被观察过的数据（不包含在训练数据中的数据）的能力。获得泛化能力是机器学习的最终目标。**

仅仅用一个数据集去学习和评价参数，是无法进行正确评价的。 这样会导致可以顺利地处理某个数据集，但无法处理其他数据集的情况。顺便说一下，**只对某个数据集过度拟合的状态称为过拟合（over fitting）。避免过拟合也是机器学习的一个重要课题**
## 4.2 损失函数（学习）
**神经网络的学习通过损失函数作为指标表示现在的状态。然后，以这个指标为基准，寻找最优权重参数。**

损失函数可以使用任意函数，但一般用**均方损失**和**交叉熵损失**等。

> [!NOTE]
> 损失函数是表示神经网络性能的 “恶劣程度” 的指标，即当前的神经网络对监督数据在多大程度上不拟合，在多大程度上不一致。（即**反映了预测值和真实值之间有多大区别**）
> 学习的目的就是以该损失函数为基准，找出能使它的值达到最小的权重参数。

### 均方损失

$$E=\dfrac{1}{2}\sum_k(y_k-t_k)^2=\dfrac{1}{2}\sum_k(t_{k}- y_k)^2$$
  
$y_k$ 是表示神经网络的输出（即预测值），$t_k$ 表示监督数据（真实值），$k$ 表示数据的维数。除以 2 是为了求导数时常数项为 1，方便计算。


比如，在 3.6 节手写数字识别的例子中，$y_k$、$t_k$ 是由如下 10 个元素构成的数据。  
```c++
>>> y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0] 
>>> t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]
```
数组元素的索引从第一个开始依次对应数字“0”“ 1”“ 2”…… 

这里，神经网络的输出 $y$ 是 softmax 函数的输出。由于 softmax 函数的输出可以理解为概率，因此上例表示“0”的概率是 0.1，“ 1”的概率是 0.05，“ 2”的概率是 0.6 等。
**$t$ 是监督数据，将正确解标签设为 1，其他均设为 0**。这里，标签“2”为 1，表示正确解是“2”。**将正确解标签表示为 1，其他标签表示为 0 的表示方法称为 one-hot 表示。**

```python title:均方损失
def mean_squared_error(y, t):
    return 0.5 * np.sum((y-t)**2
```

计算结果越小，说明和监督数据之间的误差越小。

```python
>>> # 设 “2”为正确解
>>> t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] 
>>>
>>> # 例 1：“2”的概率最高的情况（0.6）
>>> y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0] 
>>> mean_squared_error(np.array(y), np.array(t))
0.097500000000000031 
>>>
>>> # 例 2：“7”的概率最高的情况（0.6）
>>> y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0] 
>>> mean_squared_error(np.array(y), np.array(t))
0.59750000000000003
```
第一个例子中，正确解是“2”，神经网络的输出的最大值是“ 2”；第二个例子中，正确解是“2”，神经网络的输出的最大值是“7”。如 
实验结果所示，我们发现第一个例子的损失函数的值更小，和监督数据之间的 误差较小。也就是说，均方损失显示第一个例子的输出结果与监督数据更加吻合。
### 交叉熵损失
$$
E=-\sum_k t_k\log y_k
$$

这里，$log$ 表示以 $e$ 为底数的自然对数（$loge$）。 $y_k$ 是神经网络的输出，$t_k$ 是正确解标签。并且， $t_k$  中只有正确解标签的索引为 1，其他均为 0（one-hot 表示）。因此，**上式实际上只计算对应正确解标签的输出的自然对数。**  
（PS：在机器学习中，log 默认就是 In，以 e 为底）

```python title:交叉熵损失
def cross_entropy_error(y, t):
	delta = 1e-7 # 因为，当出现 np.log(0) 时，np.log(0) 会变为负无限大 的 -inf，这样一来就会导致后续计算无法进行。作为保护性对策，添加一个 微小值可以防止负无限大的发生。
	return -np.sum(t * np.log(y + delta))
```

```python
>>> t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]
>>> y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0] 
>>> cross_entropy_error(np.array(y), np.array(t))
0.51082545709933802 
>>>
>>> y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0] 
>>> cross_entropy_error(np.array(y), np.array(t))
2.3025840929945458
```
第一个例子中，正确解标签对应的输出为 0.6，此时的交叉熵损失大约为 0.51。
第二个例子中，正确解标签对应的输出为 0.1 的低值，此时的交叉熵损失大约为 2.3。由此可以看出，这些结果与我们前面讨论的内容是一致的。

#### 交叉熵
>信息论的核心思想是量化数据中的信息内容。在信息论中，该数值被称为分布 $P$ 的熵（entropy）。

交叉熵损失（cross-entropy loss），是分类问题最常用的损失之一。

![[Pasted image 20231112210802.png]]

### mini-batch 学习（小批量数据）
前面介绍的损失函数的例子中考虑的都是针对单个数据的损失函数。如果要求所有训练数据的损失函数的总和，以交叉熵损失为例，可以写成下面的式子。 
$$E=-\dfrac{1}{N}\sum_n\sum_k t_{nk}\log y_{nk}$$
这里, 假设数据有 N 个，$t_nk$ 表示第 n 个数据的第 k 个元素的值（$y_nk$ 是神经网络的输出，$t_nk$  是监督数据）。式子虽然看起来有一些复杂，其实只是把求单个数据的损失函数的式子扩大到了 N 份数据，不过最后还要除以 N 进行正规化。通过除以 N，可以求单个数据的 “**平均损失函数**”。通过这样的平均化，可以获得和训练数据的数量无关的统一指标。  
比如，即便训练数据 有 1000 个或 10000 个，也可以求得单个数据的平均损失函数。

大型训练数据数据量极大，以全部数据为对象计算损失函数是不现实的。因此，我们从全部数据中选出一部分，作为全部数据的“近似。**神经网络的学习也是从训练数据中选出一批数据（称为 mini-batch, 小批量），然后对每个 mini-batch 进行学习** 
比如，从 60000 个训练数据中随机选择 100 笔，再用这 100 笔数据进行学习。这种学习方式称为 mini-batch 学习。
相应的，我们就要使用mini-batch 版的损失函数。

### 为何要设定损失函数

**“导数”在神经网络学习中的作用**：在神经网络的学习中，寻找最优参数（权重和偏置）时，要寻找使损失函数的值尽可能小的参数。**为了找到使损失函数的值尽可能小的地方，需要计算参数的导数（确切地讲是梯度），然后以这个导数为指引，逐步更新参数的值。** 

假设有一个神经网络，现在我们来关注这个神经网络中的某一个权重参数。此时，**对该权重参数的损失函数求导，表示的是“如果稍微改变这个权重参数的值，损失函数的值会如何变化”。** 如果导数的值为负，通过使该权重参数向正方向改变，可以减小损失函数的值；反过来，如果导数的值为正，则通过使该权重参数向负方向改变，可以减小损失函数的值。不过，当导数的值为 0 时，无论权重参数向哪个方向变化，损失函数的值都不会改变，此时该权重参数的更新会停在此处。


在进行神经网络的学习时，不能将识别精度作为指标。因为如果以识别精度为指标，则参数的导数在绝大多数地方都会变为 0。识别精度对微小的参数变化基本上没有什么反应，即便有反应，它的值 也是不连续地、突然地变化。


## 4.3 数值微分

![[Pasted image 20230504121853.png]]

**利用微小的差分求导数的过程称为数值微分（numerical  differentiation）**。
而基于数学式的推导求导数的过程，则用“解析性”（analytic）一词，称为“解析性求解”或者“解析性求导。解析性求导得到的导数是不含误差的“真的导数 

```python title:数值微分求导
def numerical_diff(f,x):
    h = 1e-4 # 0.001
    return (f(x+h) - f(x-h)) / (2*h)
```

## 4.4 梯度

> [!NOTE] 求梯度的方法
> 1. 基于数值微分的方法
> 2. 解析性地求解数学式的方法。通过使用误差反向传播法

定义：像 $\left(\frac{\partial f}{\partial x_0},\frac{\partial f}{\partial x_1}\right)$ 这样的由**全部变量的偏导数汇总而成的向量**称为梯度。

```python title:求梯度，相当于对数组x的各个元素求数值微分
def numerical_gradient(f, x):    
    h = 1e-4 # 0.0001 
    grad = np.zeros_like(x) # 会生成一个形状和x相同、所有元素都为0的数组
    
    for idx in range(x.size): # 如x[3,4]，idx=0，1 
        tmp_val = x[idx]      # tmp_val=x[0]=3
        # f(x+h)的计算 
        x[idx] = tmp_val + h  # x[0]=3+h，x变为[3+h,4] 
        fxh1 = f(x)           # 算[3+h,4]对应的函数值f
        
        # f(x-h)的计算 
        x[idx] = tmp_val - h  # x[0]=3-h，x为[3-h,4] 
        fxh2 = f(x)           # 算[3-h,4]对应的函数值f
        
        grad[idx] = (fxh1 - fxh2) / (2*h) # 算出梯度 
        x[idx] = tmp_val # 还原x为[3,4]
    return grad
```

函数 `numerical_gradient (f, x)` 中，参数 f 为函数，x 为 NumPy 数组，该函数对 NumPy 数组 x 的各个元素求数值微分。现在，我们用这个函数实际计算一下梯度。这里我们求点 (3, 4)、(0, 2)、(3, 0) 处的梯度。
```python
>>> numerical_gradient(function_2, np.array([3.0, 4.0])) 
array([ 6.,  8.])
>>> numerical_gradient(function_2, np.array([0.0, 2.0])) 
array([ 0.,  4.])
>>> numerical_gradient(function_2, np.array([3.0, 0.0])) 
array([ 6.,  0.])
```

![[Pasted image 20230504135520.png]]


**这里我们画的是元素值为负梯度的向量，负梯度方向是梯度法中变量的更新方向。**
我们发现梯度指向函数 $f (x0, x1)$ 的“最低处”（最小值），就像指南针一样，所有的箭头都指向同一点。其次，我们发现离“最低处”越远，箭头越大。

虽然图 4-9 中的梯度指向了最低处，但并非任何时候都这样。**实际上，梯度会指向各点处的函数值降低的方向。更严格地讲，梯度指示的方向是各点处的函数值减小最多的方向。** 

> [!warning] Title
> - 无法保证梯度所指的方向就是函数的最小值或者真正应该前进的方向。实际上，在复杂的函数中，梯度指示的方向基本上都不是函数值最小处 
> - 函数的极小值、最小值以及被称为**鞍点**（saddle point）的地方，梯度为 0 
> - **鞍点**是从某个方向上看是极大值，从另一个方向上看则是极小值的点 
> - 虽然梯度法是要寻找梯度为 0 的地方，但是那个地方不一定就是最小值（也有可能是极小值或者鞍点）。此外，当函数很复杂且呈扁平状时，学习可能会进入一个（几乎）平坦的地区，陷入被称为“学习高原”的无法前进的停滞期。

### 梯度下降法（学习，寻找损失函数最小值）
- 梯度下降通过不断沿着反梯度方向更新参数求解
- 小批量（mini-batch）随机梯度下降是深度学习默认的求解算法
- 两个重要的超参数是批量大小和学习率


机器学习的主要任务是在学习时寻找最优参数。同样地，**神经网络也必须在学习时找到最优参数（权重和偏置）。这里所说的最优参数是指损失函数取最小值时的参数。** 但是，一般而言，损失函数很复杂，参数空间庞大，我们不知道它在何处能取得最小值。而**通过巧妙地使用梯度来寻找函数最小值 （或者尽可能小的值）的方法就是梯度法。**  
在梯度法中，函数的取值从当前位置沿着梯度方向前进一定距离，然后在新的地方重新求梯度，再沿着新梯度方向前进，如此反复，不断地沿梯度方向前进。像这样，**通过不断地沿梯度方向前进， 逐渐减小函数值的过程就是梯度法（gradient method）**。梯度法是解决机器学习中最优化问题的常用方法，特别是在神经网络的学习中经常被使用。

严格地讲， 寻找最小值的梯度法称为**梯度下降法**（gradient descent method），寻找最大值的梯度法称为**梯度上升法**（gradient ascent method）。**一般来说，神经网络（深度学习）中，梯度法主要是指梯度下降法。**  

数学式来表示梯度法： $$\begin{matrix}x_0=x_0-\eta\dfrac{\partial f}{\partial x_0}\\ x_1=x_1-\eta\dfrac{\partial f}{\partial x_1}\end{matrix}$$
上式中的 $η$ 表示更新量，在神经网络的学习中，称为**学习率（learning rate）**。**学习率决定在一次学习中，应该学习多少，以及在多大程度上更新参数。**
上式是表示更新一次的式子，这个步骤会反复执行。也就是说，每一步都按式更新变量的值，通过反复执行此步骤，逐渐减小函数值。虽然这里只展示了有两个变量时的更新过程，但是即便增加变量的数量，也可以通过类似的式子（各个变量的偏导数）进行更新。

学习率需要事先确定为某个值，比如 0.01 或 0.001。一般而言，这个值过大或过小，都无法抵达一个“好的位置”。**在神经网络的学习中，一般会一边改变学习率的值，一边确认学习是否正确进行了。**

```python title:梯度下降法
def gradient_descent(f, init_x, lr=0.01, step_num=100):    
    x = init_x
    
    for i in range(step_num):        
        grad = numerical_gradient(f, x)        
        x -= lr * grad
    return x
```

参数:
`f` 是要进行最优化的函数
`init_x` 是初始值
`lr ` 是学习率 learning rate
` step_num ` 是梯度法的重复次数。
`numerical_gradient(f,x) ` 会求函数的梯度，用该梯度乘以学习率得到的值进行更新操作，由 step_num 指定重复的次数。  

> [!NOTE] Title
> 像学习率这样的参数称为**超参数**。这是一种和神经网络的参数（权重和偏置）性质不同的参数。
> 
> 相对于神经网络的权重参数是通过训练数据和学习算法自动获得的，**学习率这样的超参数则是人工设定的。一般来说，超参数需要尝试多个值，以便找到一种可以使学习顺利进行的设定。** 

使用这个函数可以求函数的极小值，顺利的话，还可以求函数的最小值。
用梯度法求 $f(x_0+x_1)=x_0^2+x_1^2$ 的最小值：
```python
>>> def function_2(x):
        return x[0]**2 + x[1]**2
>>> init_x = np.array([-3.0, 4.0])
>>> gradient_descent(function_2, init_x=init_x, lr=0.1, step_num=100) 

# 结果
array([ -6.11110793e-10,   8.14814391e-10])
```
这里，设初始值为 (-3.0, 4.0)，开始使用梯度法寻找最小值。最终的结果是 (-6.1e-10, 8.1e-10)，非常接近 (0，0)。实际上，真的最小值就是 (0，0)，所以说通过梯度法我们基本得到了正确结果
![[Pasted image 20231111101628.png]]

### 神经网络的梯度（损失函数关于权重参数的梯度）

比如，有一个只有一个形状为 2×3 的权重 $W$ 的神经网络，损失函数用 $L$ 表示，梯度用$\frac{∂L}{∂W}$ 表示，用数学式表示的话：  
$$
\mathbf{W}=\left(\begin{array}{ccc}w_{11}&w_{12}&w_{13}\\ w_{21}&w_{22}&w_{23}\end{array}\right)
$$
$$
\dfrac{\partial L}{\partial\mathbf{W}}=\left(\begin{array}{ccc}\frac{\partial L}{\partial w_{11}}&\frac{\partial L}{\partial w_{12}}&\frac{\partial L}{\partial w_{13}}\\ \frac{\partial L}{\partial w_{21}}&\frac{\partial L}{\partial w_{22}}&\frac{\partial L}{\partial w_{23}}\end{array}\right)
$$

$\frac{∂L}{∂W}$ 的元素由各个元素关于 $W$ 的偏导数构成。
比如，第 1 行第 1 列的元素 $\frac{∂L}{∂w_{11}}$ 表示当 $w_{11}$ 稍微变化时，损失函数 $L$ 会发生多大变化。这里的重点是， $W$ 和 $\frac{∂L}{∂W}$ 的形状相同。

```python
# 根据书上的思路，可以理解为：
# 1.定义x（输入）：1*2，t（标签）：1*3，W（权重）：2*3 ，y（输出）：1*3
# 2.x，W点积求得y
# 3.通过softmax函数处理y
# 4.求损失函数，交叉熵损失
# 5.定义匿名函数，将W变为损失函数的参数
# 6.求损失函数关于W的梯度
# PS:求出来的梯度大小就可以知道权重W如何调整

# 则按照上述步骤编写程序如下：
import numpy as np

"""激活函数"""
def softmax(x):
    if x.ndim == 2:
        x = x.T
        x = x - np.max(x, axis=0)
        y = np.exp(x) / np.sum(np.exp(x), axis=0)
        return y.T

    x = x - np.max(x) # 溢出对策
    return np.exp(x) / np.sum(np.exp(x))

"""损失函数，交叉熵损失"""
def cross_entropy_error(y, t):
    if y.ndim == 1:
        t = t.reshape(1, t.size)
        y = y.reshape(1, y.size)

    # 监督数据是one-hot-vector的情况下，转换为正确解标签的索引
    if t.size == y.size:
        t = t.argmax(axis=1)

    batch_size = y.shape[0]
    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size

"""求一维的梯度"""
def _numerical_gradient_1d(f, x):
    h = 1e-4  # 0.0001
    grad = np.zeros_like(x)

    for idx in range(x.size):
        tmp_val = x[idx]
        x[idx] = float(tmp_val) + h
        fxh1 = f(x)  # f(x+h)

        x[idx] = tmp_val - h
        fxh2 = f(x)  # f(x-h)
        grad[idx] = (fxh1 - fxh2) / (2 * h)

        x[idx] = tmp_val  # 还原值

    return grad

"""求二维的梯度"""
def numerical_gradient_2d(f, X):
    if X.ndim == 1:
        return _numerical_gradient_1d(f, X)
    else:
        grad = np.zeros_like(X)

        for idx, x in enumerate(X):
            grad[idx] = _numerical_gradient_1d(f, x)

        return grad

# 1.定义x，t，W
x = np.array([0.6,0.9]) # 输入数据
t = np.array([0,0,1]) # 正确结果
W = np.random.randn(2,3) # 2*3的权重

# 2.x，W点积求得y
y = np.dot(x,W)
print("y：{}".format(y))

# 3.通过softmax函数处理y
y_sm = softmax(y)
print("y_sm：{}".format(y_sm))

# 4.求损失函数，交叉熵损失
loss = cross_entropy_error(y_sm,t)
print("loss：{}".format(loss))

# 5.定义匿名函数，将W变为损失函数的参数
f = lambda  W:cross_entropy_error(y_sm,t)
# 用匿名函数将W变为参数
print(f(W))
print(f(1))
print(W)

# 6.求损失函数关于W的梯度
dW = numerical_gradient_2d(f,W)
print(dW)

# 输出：
# y：[-0.54321364 -0.37949175 -1.06371615]
# y_sm：[0.36073623 0.42490641 0.21435736]
# loss：1.5401102895993706
# 1.5401102895993706
# 1.5401102895993706
# [[ 1.60980903 -0.27800492 -1.67564275]
#  [-1.67677673 -0.23632088 -0.06481167]]
# [[0. 0. 0.]
#  [0. 0. 0]]

# 可以发现，该程序输出的梯度为0，说明这个方法是错误的。
# 而书上的程序是把simpleNet写成类
# 猜测在第五步，这种形式，W并没有成为函数f真正的变量，W值改变(权重需要不断更新)，f值并不会改变。由于f的值不变，
# f(W+h) - f(W-h) = 0，所以梯度都为0。
```

下面来看看书上给的源码（源代码在 ch04/gradient_simplenet.py 中），这里为了方便查看程序，我把头文件中引入的函数也写出来：

```
# coding: utf-8
import numpy as np

def softmax(x):
    if x.ndim == 2:
        x = x.T
        x = x - np.max(x, axis=0)
        y = np.exp(x) / np.sum(np.exp(x), axis=0)
        return y.T

    x = x - np.max(x) # 溢出对策
    return np.exp(x) / np.sum(np.exp(x))

def cross_entropy_error(y, t):
    if y.ndim == 1:
        t = t.reshape(1, t.size)
        y = y.reshape(1, y.size)

    # 监督数据是one-hot-vector的情况下，转换为正确解标签的索引
    if t.size == y.size:
        t = t.argmax(axis=1)

    batch_size = y.shape[0]
    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size

def numerical_gradient(f, x):  # n维数组求梯度
    h = 1e-4  # 0.0001
    grad = np.zeros_like(x)  # 梯度的形状与x的形状相同

    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])
    # multi_index将元素索引(0,0) (0,1)等取出来
    # readwrite，使用可读可写的格式，我们需要改变x的值来计算f，所以需要用此方式
    while not it.finished:
        idx = it.multi_index
        tmp_val = x[idx]  # 取出某个元素
        x[idx] = float(tmp_val) + h
        fxh1 = f(x)  # f(x+h)

        x[idx] = tmp_val - h
        fxh2 = f(x)  # f(x-h)
        grad[idx] = (fxh1 - fxh2) / (2 * h)

        x[idx] = tmp_val  # 还原值
        it.iternext()

    return grad

class simpleNet:
    def __init__(self):
        self.W = np.random.randn(2,3) #用高斯分布进行初始化，返回一个从[0,1)均匀分布的数组

    def predict(self, x):
        return np.dot(x, self.W)

    def loss(self, x, t): # 求损失函数的值
        z = self.predict(x)
        y = softmax(z)
        loss = cross_entropy_error(y, t)

        return loss

x = np.array([0.6, 0.9])
t = np.array([0, 0, 1])

net = simpleNet() # W = np.random.randn(2,3)
print("net.W：{}".format(net.W))

p = net.predict(x)
print("p：{}".format(p))

print("net.loss(x,t)：{}".format(net.loss(x,t)))

f = lambda w: net.loss(x, t) # 这里的f是一个函数，不是一个值
print(type(f))
dW = numerical_gradient(f, net.W)

print(dW)

# 输出：
# net.W：[[-1.22317556 -0.02853916 -0.24033821]
#  [-1.62537437 -1.27039753  0.84045948]]
# p：[-2.19674227 -1.16048127  0.6122106 ]
# net.loss(x,t)：0.2071304284027996
# <class 'function'>
# [[ 0.02939563  0.08285624 -0.11225188]
#  [ 0.04409345  0.12428437 -0.16837781]]
```

**问题**：程序每次运行时，都会产生不同的梯度值，因为 W 设置的是随机生成的数组，然而 x 和 t 是固定的，在源码中 f =lambda w: net.loss(x, t) 并未对 W 进行改变。那么这种结构的 W 到底能不能被改变，从结果来看是被改变了，它的本质是在用函数调用改变全局变量 W。  
**思路**：已知 x，正确标签 t，权重 W 有初始值，预测值 y = W*x + b，损失值 loss = |y - t|，求 loss 对 W 的偏导，核心问题在于，loss 的参数是 W，但我们定义的函数里面，W 并不是 loss 的直接参数，我们输入的就是 x 和 t，结果就是 loss 对 W 的梯度。  
**为什么要用 lambda**：我们想要求梯度，求梯度的这个函数有两个参数，numerical_gradient(损失函数，W 初始值)，注意第一个参数是损失函数，是一个函数，如果不定义一个新的函数，直接用 loss，loss(x,t) 这时你又必须把参数输进去，这样函数只会返回一个值，并不会保留函数关系，所以必须用 lambda 定义一个过渡的函数，只保留函数关系，但不会去运行 loss。

补充知识：  
函数参数传递机制：函数参数传递机制问题的本质上是调用函数（过程）和被调用函数（过程）在调用发生时进行通信的方法问题。基本的参数传递机制有两种：值传递和引用传递  
值传递（passl-by-value）过程中，被调函数的形式参数作为被调函数的局部变量处理，即在堆栈中开辟了内存空间以存放由主调函数放进来的实参的值，从而成为了实参的一个副本。值传递的特点是被调函数对形式参数的任何操作都是作为局部变量进行，不会影响主调函数的实参变量的值。  
引用传递 (pass-by-reference) 过程中，被调函数的形式参数虽然也作为局部变量在堆栈中开辟了内存空间，但是这时存放的是由主调函数放进来的实参变量的地址。被调函数对形参的任何操作都被处理成间接寻址，即通过堆栈中存放的地址访问主调函数中的实参变量。正因为如此，被调函数对形参做的任何操作都影响了主调函数中的实参变量。  
具体参考：[http://c.biancheng.net/view/2258.html](http://c.biancheng.net/view/2258.html)

Python 中：  
如果是**可变对象**，如字典或者列表，就能修改对象的原始值，相当于引用传递；  
如果是**不可变对象**，如数字、字符或者元组，就不能直接修改原始对象，相当于值传递。

```
id(a) # 表示查看a的地址
```

总结：  
在一开始按照步骤写的程序中，定义的随机数是一个整数，所以在传进函数里的时候是值传递，但是在书里面的例子，生成的随机数是个 array，所以在数组求梯度那两个函数里面属于引用传递，在函数里面修改，同样相当于全局修改。（来自大佬的解答）

## 4.5 学习算法的实现
**前提**
**神经网络存在合适的权重和偏置，调整权重和偏置以便拟合训练数据的过程称为“学习”。**

### 学习步骤
神经网络的学习分成下面 4 个步骤。
**步骤 1（mini-batch）**
从训练数据中随机选出一部分数据，这部分数据称为 mini-batch。我们 的目标是减小 mini-batch 的损失函数的值。
**步骤 2（计算梯度）**
为了减小 mini-batch 的损失函数的值，需要求出各个权重参数的梯度。 梯度表示损失函数的值减小最多的方向。
**步骤 3（更新参数）**
将权重参数沿梯度方向进行微小更新。
**步骤 4（重复）**
重复步骤 1、步骤 2、步骤 3。

这里使用的数据是随机选择的 mini batch 数据，所以又称为**随机梯度下降法**。“随机”指的是“随机选择的” 的意思，因此，随机梯度下降法是“对随机选择的数据进行的梯度下降法”。 
**深度学习的很多框架中，随机梯度下降法一般由一个名为 SGD 的函数来实现**。 SGD 来源于随机梯度下降法的英文名称的首字母

### 2层神经网络的类
输入层 -> 中间层（隐藏层）-> 输出层

```python title:TwoLayerNetl类
import sys, os 
sys.path.append(os.pardir) # 添加上一级目录到sys.path中
from common.functions import * # 导入common文件夹中的模块
from common.gradient import numerical_gradient # 导入common文件夹中的模块

class TwoLayerNet:
    # (输入层的神经元数、隐藏层的神经元数、输出层的神经元数)
    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):
        # 初始化权重
        self.params = {}  #params保存神经网络的参数的字典型变量（实例变量）
        # 随机生成输入层到隐藏层的权重矩阵，大小为(input_size, hidden_size)，并乘以标准差
        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size) 
        # 初始化偏置为0，大小为(hidden_size,)
        self.params['b1'] = np.zeros(hidden_size)
        # 随机生成隐藏层到输出层的权重矩阵，大小为(hidden_size, output_size)，并乘以标准差
        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) 
        # 初始化偏置为0，大小为(output_size,)
        self.params['b2'] = np.zeros(output_size)

    # 进行识别（推理） 前向传播，计算输出值, x是图像数据
    def predict(self, x):
        W1, W2 = self.params['W1'], self.params['W2'] 
        b1, b2 = self.params['b1'], self.params['b2']
        # 计算隐藏层的加权和，使用sigmoid函数作为激活函数
        a1 = np.dot(x, W1) + b1 
        z1 = sigmoid(a1) 
        # 计算输出层的加权和，使用softmax函数作为激活函数
        a2 = np.dot(z1, W2) + b2 
        y = softmax(a2)
        return y

    # 计算损失函数的值
    # x:输入数据 , t:监督数据（正确解标签）
    def loss(self, x, t): 
        y = self.predict(x)
        return cross_entropy_error(y, t) 

    # 计算识别精度
    # 调用self.predict(x)方法来预测输入数据的类别，然后使用np.argmax函数沿着指定轴返回最大值的索引，从而得到预测标签y和目标标签t的索引。接下来，使用np.sum函数计算预测标签和目标标签相同的数量，最后将其除以输入数据的数量，得到识别精度。
    def accuracy(self, x, t):
        y = self.predict(x) 
        y = np.argmax(y, axis=1) 
        t = np.argmax(t, axis=1)
        accuracy = np.sum(y == t) / float(x.shape[0]) 
        return accuracy

    # 基于数值微分计算计算各个参数的梯度，下一章使用误差反向传播法可以更高速的处理
    def numerical_gradient(self, x, t): 
        loss_W = lambda W: self.loss(x, t)
        grads = {}
        # 计算输入层到隐藏层的权重矩阵的梯度
        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])
        # 计算输入层到隐藏层的偏置的梯度
        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])
        # 计算隐藏层到输出层的权重矩阵的梯度
        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])
        # 计算隐藏层到输出层的偏置的梯度
        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])
        return grads
```

### mini-batch 的实现
以TwoLayerNet 类为对象，使用 MNIST 数据集进行学习（源代码在 ch04/train_ 
neuralnet. py 中 ）。
```python
import numpy as np
from dataset.mnist import load_mnist 
from two_layer_net import TwoLayerNet
(x_train, t_train), (x_test, t_test) = \ load_mnist(normalize=True, one_hot_ 
label = True)
train_loss_list = [] 
# 超参数
iters_num = 10000
train_size = x_train.shape[0] 
batch_size = 100
learning_rate = 0.1

network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10) 
for i in range(iters_num):
    # 获取 mini-batch
    batch_mask = np.random.choice(train_size, batch_size) 
    x_batch = x_train[batch_mask]
    t_batch = t_train[batch_mask] 
    # 计算梯度
    grad = network.numerical_gradient(x_batch, t_batch) 
    # grad = network.gradient(x_batch, t_batch) # 高速版 !
    # 更新参数
    for key in ('W1', 'b1', 'W2', 'b2'):
        network.params[key] -= learning_rate * grad[key] 
    # 记录学习过程
    loss = network.loss(x_batch, t_batch) 
    train_loss_list.append(loss)
```
这里，mini-batch 的大小为 100，需要每次从 60000 个训练数据中随机取出 100 个数据（图像数据和正确解标签数据）。然后，对这个包含 100 笔数据的 mini-batch 求梯度，使用随机梯度下降法（SGD）更新参数。这里，梯度法的更新次数（循环的次数）为 10000。每更新一次，都对训练数据计算损失函数的值，并把该值添加到数组中。用图像来表示这个损失函数的值的推移
![[Pasted image 20230505122226.png]]

**随着学习的进行，损失函数的值在不断减小。这是学习正常进行的信号，表示神经网络的权重参数在逐渐拟合数据。也就是说，神经网络的确在学习！通过反复地向它浇灌（输入）数据，神经网络正在逐渐向最优参数靠近。** 
### 基于测试数据的评价
**神经网络的学习中，必须确认是否能够正确识别训练数据以外的其他数据，即确认是否会发生过拟合。**

**过拟合是指，虽然训练数据中的数字图像能被正确辨别，但是不在训练数据中的数字图像却无法被识别的现象。**

神经网络学习的最初目标是掌握泛化能力，因此，**要评价神经网络的泛化能力，就必须使用不包含在训练数据中的数据**。下面的代码在进行学习的过程中，会定期地对训练数据和测试数据记录识别精度。这里，每经过一个 epoch，我们都会记录下训练数据和测试数据的识别精度。

> [!NOTE]
> **epoch** 是一个单位。一个 epoch 表示学习中所有训练数据均被使用过一次时的更新次数。比如，对于 10000 笔训练数据，用大小为 100笔数据的 mini-batch 进行学习时，重复随机梯度下降法 100 次，所有的训练数据就都被“看过”了 A。此时，100 次就是一个 epoch。
> > [!warning] 
> > 实际上，一般做法是事先将所有训练数据随机打乱，然后按指定的批次大小，按序生成 mini-batch。这样每个 mini-batch 均有一个索引号，比如此例可以是 0, 1, 2, ..., 99，然后用索引号可以遍历所有的 mini-batch。遍历一次所有数据，就称为一个 epoch。请注意，本节中的 mini-batch 每次都是随机选择的，所以不一定每个数据都会被看到。

为了正确进行评价，我们来稍稍修改一下前面的代码。
```python
import numpy as np
from dataset.mnist import load_mnist 
from two_layer_net import TwoLayerNet
(x_train, t_train), (x_test, t_test) = \ load_mnist(normalize=True, one_hot_ 
laobel = True)
train_loss_list = [] 
train_acc_list = [] 
test_acc_list = [] 
# 平均每个 epoch的重复次数
iter_per_epoch = max(train_size / batch_size, 1) 
# 超参数
iters_num = 10000 
batch_size = 100 
learning_rate = 0.1
network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10) 
for i in range(iters_num):
    # 获取 mini-batch
    batch_mask = np.random.choice(train_size, batch_size) 
    x_batch = x_train[batch_mask]
    t_batch = t_train[batch_mask] 
    
    # 计算梯度
    grad = network.numerical_gradient(x_batch, t_batch) 
    # grad = network.gradient(x_batch, t_batch) # 高速版 !
    
    # 更新参数
    for key in ('W1', 'b1', 'W2', 'b2'):
        network.params[key] -= learning_rate * grad[key] 
        
    loss = network.loss(x_batch, t_batch)
    train_loss_list.append(loss) 
    
    # 计算每个 epoch的识别精度
    if i % iter_per_epoch == 0:
        train_acc = network.accuracy(x_train, t_train) 
        test_acc = network.accuracy(x_test, t_test) 
        train_acc_list.append(train_acc)
        test_acc_list.append(test_acc)
        print("train acc, test acc | " + str(train_acc) + ", " + str(test_acc))
```

![[Pasted image 20230505155325.png]]
每经过一个 epoch 就记录一次训练数据的识别精度。

实线表示训练数据的识别精度，虚线表示测试数据的识别精度。如图所示，随着 epoch 的前进（学习的进行），我们发现使用训练数据和测试数据评价的识别精度都提高了，并且，这两个识别精度基本上没有差异（两条线基本重叠在一起）。因此，可以说这次的学习中没有发生过拟合的现象。
# 第 5 章误差反向传播法（学习，没太看懂）
数值微分虽然简单，也容易实现，但缺点是计算上比较费时间。
高效计算权重参数的梯度的方法——误差反向传播法 

## 5.1 计算图 &  链式法则 & 反向传播
**计算图的优点是，可以通过正向传播和反向传播高效地计算各个变量的导数值 

使用计算图最大的原因是，可以通过反向传播高效计算导数。

假设存在 $y = f (x)$ 的计算，这个计算的反向传播如图所示。
![[Pasted image 20230505160058.png]]
反向传播的计算顺序是，将信号 E 乘以节点的局部导数 $\frac{\partial y}{\partial x}$ ，然后将结果传递给下一个节点。这里所说的**局部导数是指正向传播中 $y = f (x)$ 的导数**

### 加法节点的反向传播
$z=x+y$ 的导数可由下式（解析性的）计算出来：
$$\begin{array}{l}\frac{\partial z}{\partial x}=1\\ \\ \frac{\partial z}{\partial y}=1\end{array}$$
反向传播将从**上游传过来的导数（本例中是 $\frac{\partial L}{\partial z}$）** 乘以 1，然后传向下游。也就是说，因为加法节点的反向传播只乘以 1，所以输入的值会原封不动地流向下一个节点。
![[Pasted image 20230505160450.png]]
  
加法的反向传播的具体例子。假设有“10 + 5=15”这一计算，反向传播时，从上游会传来值 1.3。用计算图表示的话，如图 5-11 所示。
![[Pasted image 20230505160534.png]]

由于导数为 1，所以加法的反向传播只是将上游的值传给下游，并不需要正向传播的输入信号。

```python title:加法层的实现
class AddLayer:
    def __init__(self):
        pass
        
    def forward(self, x, y): # 正向传播
        out = x + y
        return out
        
    def backward(self, dout): # 反向传播
        dx = dout * 1
        dy = dout * 1
        return dx, dy
# 加法层不需要特意进行初始化，所以__init__()中什么也不运行（pass 语句表示“什么也不运行”）。
# 加法层的forward()接收x和y两个参数，将它们相加后输出。backward()将上游传来的导数（dout）原封不动地传递给下游。
```

### 乘法节点的反向传播
以 $z=xy$ 的导数为例：

$\begin{array}{l}\frac{\partial z}{\partial x}=y\\ \\ \frac{\partial z}{\partial y}=x\end{array}$

  
**乘法的反向传播会将上游的值乘以正向传播时的输入信号的“翻转值”后传递给下游。** 翻转值表示一种翻转关系，如图 5-12 所示，正向传播时信号是 x 的话，反向传播时则是 y；正向传播时信号是 y 的话，反向传播时则是 x。

比如，假设有“10 × 5 = 50”这一计算，反向传播时，从上游会传来值 1.3。用计算图表示的话，如图 所示。
![[Pasted image 20230505161037.png]]
  
加法的反向传播只是将上游的值传给下游，并不需要正向传播的输入信号。但是，**乘法的反向传播需要正向传播时的输入信号值。因此，实现乘法节点的反向传播时，要保存正向传播的输入信号。** 


```python title:乘法层的实现
class MulLayer:
    def __init__(self):
        self.x = None
        self.y = None
        
    def forward(self, x, y):
        self.x = x
        self.y = y                
        out = x * y
        
        return out
        
    def backward(self, dout):
        dx = dout * self.y
        dy = dout * self.x
        
        return dx, dy
# __init__()中会初始化实例变量x和y，它们用于保存正向传播时的输入值。
# forward()接收x和y两个参数，将它们相乘后输出。backward()将从上游传 来的导数（dout）乘以正向传播的翻转值，然后传给下游。
```

### 反向传播的例子
再来思考一下本章最开始举的购买苹果的例子（2 个苹果和消费税）。这里要解的问题是苹果的价格、苹果的个数、消费税这 3 个变量各自如何影响最终支付的金额。
**这个问题相当于求“支付金额关于苹果的价格的导数”“支付金额关于苹果的个数的导数”“支付金额关于消费税的导数”**。用计算图的反向传播来解的话，求解过程如图 5-14 所示。
![[Pasted image 20230505161812.png]]
如前所述，乘法节点的反向传播会将输入信号翻转后传给下游。从图 5-14的结果可知，苹果的价格的导数是 2.2，苹果的个数的导数是 110，消费税的导数是 200。这可以解释为，**如果消费税和苹果的价格增加相同的值，则消费税将对最终价格产生 200 倍大小的影响，苹果的价格将产生 2.2 倍大小的影响**。不过，因为这个例子中消费税和苹果的价格的量纲不同，所以才形成了这样的结果.

```python
apple = 100 
apple_num = 2 
tax = 1.1

# layer
mul_apple_layer = MulLayer() 
mul_tax_layer = MulLayer()

# forward
apple_price = mul_apple_layer.forward(apple, apple_num) 
price = mul_tax_layer.forward(apple_price, tax)
print(price) # 220

# 关于各个变量的导数可由 backward() 求出。
# backward 
dprice = 1
dapple_price, dtax = mul_tax_layer.backward(dprice)
dapple, dapple_num = mul_apple_layer.backward(dapple_price) 
print(dapple, dapple_num, dtax) # 2.2 110 200
```
这里，调用 backward () 的顺序与调用 forward () 的顺序相反。此外，要注意 backward () 的参数中需要输入“关于正向传播时的输出变量的导数”。比如，mul_apple_layer 乘法层在正向传播时会输出 apple_price，在反向传播时，则会将 apple_price 的导数 dapple_price 设为参数。另外，这个程序的运行结果和图 5-16 是一致的。

---

使用加法层和乘法层，实现图 5-17 所示的购买 2 个苹果和 3 个橘子的例子:
![[Pasted image 20230505163241.png]]
```python
apple = 100 
apple_num = 2 
orange = 150 
orange_num = 3 
tax = 1.1

# layer
mul_apple_layer = MulLayer()
mul_orange_layer = MulLayer()
add_apple_orange_layer = AddLayer() 
mul_tax_layer = MulLayer()

# forward
apple_price = mul_apple_layer.forward(apple, apple_num) #(1) 
orange_price = mul_orange_layer.forward(orange, orange_num) #(2)
all_price = add_apple_orange_layer.forward(apple_price, orange_price) #(3) 
price = mul_tax_layer.forward(all_price, tax) #(4)

# backward 
dprice = 1
dall_price, dtax = mul_tax_layer.backward(dprice) #(4)
dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price) #(3) 
dorange, dorange_num = mul_orange_layer.backward(dorange_price) #(2) 
dapple, dapple_num = mul_apple_layer.backward(dapple_price) #(1)

print(price) # 715
print(dapple_num, dapple, dorange, dorange_num, dtax) # 110 2.2 3.3 165 650
```

**首先，生成必要的层，以合适的顺序调用正向传播的 forward () 方法。然后，用与正向传播相反的顺序调用反向传播的 backward () 方法，就可以求出想要的导数。**

**综上，计算图中层的实现（这里是加法层和乘法层）非常简单，使用这些层可以进行复杂的导数计算**。下面，我们来实现神经网络中使用的层。

## 5.5 激活函数层的实现
我们将计算图的思路应用到神经网络中。这里，我们把构成神经网络的层实现为一个类。
### ReLU 层
$$
y=\begin{cases}x&(x>0)\\ 0&(x\leqslant0)\end{cases}
$$
$$
\frac{\partial y}{\partial x}=\begin{cases}1&(x>0)\\ 0&(x\leqslant0)\end{cases}
$$

（由上式可知：如果正向传播时的输入 x 大于 0，则反向传播会将上游的值原封不动地传给下游。反过来，如果正向传播时的 x 小于等于 0，则反向传播中传给下游的信号将停在此处。）
![[Pasted image 20230505163727.png]]
```python title:ReLUc层
"""激活函数是ReLU时的正向与反向传播"""
class Relu:
    def __init__(self):
        self.mask = None # mask:由True/False构成的NumPy数组
        
    def forward(self, x):
        self.mask = (x <= 0) # 正向传播时，x≤0时，设为True
        out = x.copy()
        out[self.mask] = 0 # 将True的地方设为0
        
        return out
        
    def backward(self, dout):
        dout[self.mask] = 0
        dx = dout
        
        return dx
```

PS:ReLU 层的作用就像电路中的开关一样。正向传播时，有电流通过的话，就将开关设为 ON；没有电流通过的话，就将开关设为 OFF。 反向传播时，开关为 ON 的话，电流会直接通过；开关为 OFF 的话， 则不会有电流通过。

### Sigmoid 层
$$y=\frac{1}{1+\exp(-x)}$$
![[Pasted image 20230505163922.png]]
除了 “×” 和“ +”节点外，还出现了新的 “exp” 和“ /”节点。 “exp”节点会进行 $y = exp(x)$的计算，“/”节点会进行 $y=\frac{1}{x}$ 的计算。  

关于 Sigmoid 的反向传播计算步骤见书 P142
![[Pasted image 20230505164128.png]]

![[Pasted image 20230505164215.png]]
简洁版的计算图可以省略反向传播中的计算过程，因此计算效率更高。此外，**通过对节点进行集约化，可以不用在意 Sigmoid 层中琐碎的细节，而只需要专注它的输入和输出，这一点也很重要。**

进一步整理:
$$
\begin{aligned}\frac{\partial L}{\partial y}y^2\exp(-x)&=\frac{\partial L}{\partial y}\frac{1}{(1+\exp(-x))^2}\exp(-x)\\ &=\frac{\partial L}{\partial y}\frac{1}{1+\exp(-x)}\frac{\exp(-x)}{1+\exp(-x)}\\ &=\frac{\partial L}{\partial y}y(1-y)\end{aligned}
$$
![[Pasted image 20230505164349.png]]

```python title:Sigmoid层
"""激活函数是Sigmoid时的正向与反向传播"""
class Sigmoid:
    def __init__(self):
        self.out = None
        
    def forward(self, x):
        out = sigmoid(x)
        self.out = out
        
        return out
        
    def backward(self, dout):
        dx = dout * (1.0 - self.out) * self.out
        
        return dx
```

## 5.6 Affine/Softmax 层的实现

### Affine 层（全连接）

全连接：相邻层的所有神经元之间都有连接（每个输入都与每个输出相连）

> [!NOTE]
> 神经网络的正向传播中进行的矩阵的乘积运算在几何学领域被称为 “仿射变换” 。因此，这里**将进行仿射变换的处理实现为 “Affine 层”**。  

图形学：仿射变换 = 线性变换 + 平移

![[Pasted image 20230505164826.png]]
  
![[Pasted image 20230505164917.png]]
###  批版本的 Affine 层
![[Pasted image 20230505165149.png]]
加上偏置时，需要特别注意。正向传播时，偏置被加到 X· W 的各个数据上。比如，N = 2（数据为 2 个）时，偏置会被分别加到这 2 个数据（各自的计算结果）上，具体的例子如下所示。
```python
>>> X_dot_W = np.array([[0, 0, 0], [10, 10, 10]]) 
>>> B = np.array([1, 2, 3])
>>>
>>> X_dot_W
array([[ 0,  0,  0], 
       [ 10, 10, 10]]) 
>>> X_dot_W + B 
array([[ 1,  2,  3], 
       [11, 12, 13]])
```

**正向传播时，偏置会被加到每一个数据（第 1 个、第 2 个……）上。因此，反向传播时，各个数据的反向传播的值需要汇总为偏置的元素**。用代码表示的话，如下所示。
```python
>>> dY = np.array([[1, 2, 3,], [4, 5, 6]]) 
>>> dY
array([[1, 2, 3], 
       [4, 5, 6]]) 
>>>
>>> dB = np.sum(dY, axis=0) 
>>> dB
array([5, 7, 9])
```
这个例子中，假定数据有 2 个（ N = 2）。偏置的反向传播会对这 2 个数据的导数按元素进行求和。因此，这里使用了 np.sum () 对第 0 轴（以数据为单位的轴，axis=0）方向上的元素进行求和。

```python title:Affine层
class Affine:
    def __init__(self, W, b):
        self.W = W
        self.b = b
        self.x = None
        self.dW = None
        self.db = None
        
    def forward(self, x): 
        self.x = x
        out = np.dot(x, self.W) + self.b 
        
        return out
        
    def backward(self, dout):
        dx = np.dot(dout, self.W.T) 
        self.dW = np.dot(self.x.T, dout) 
        self.db = np.sum(dout, axis=0)
        
        return dx
```

###  Soft-with-Loss 层
前面我们提到过，softmax 函数会将输入值正规化之后再输出。比如手写数字识别时，Softmax 层的输出如图 5-28 所示。
![[Pasted image 20230505171140.png]]
Softmax 层将输入值正规化（将输出值的和调整为 1）之后再输出。另外，因为手写数字识别要进行 10 类分类，所以向 Softmax 层的输入也有 10 个。

> [!NOTE] 
> 神经网络中进行的处理有**学习和推理（inference）**两个阶段。**神经网络的推理通常不使用 Softmax 层**。比如，用图 5 - 2 8 的网络进行推理时，会将最后一个 Affine 层的输出作为识别结果。**神经网络中未被正规化的输出结果（图 5-28 中 Softmax 层前面的 Affine 层的输出）有时被称为“得分”。**
>  也就是说，**当神经网络的推理只需要给出一个答案的情况下，因为此时只对得分最大值感兴趣，所以不需要 Softmax 层。** 不过，**神经网络的学习阶段则需要 Softmax 层。**
>>[!summary] 
>>- 学习阶段则需要 Softmax 层
>>- 推理通常不使用 Softmax 层
> 

下面来实现 Softmax 层。考虑到这里也包含作为损失函数的交叉熵损失（ cross entropy error），所以称为“Softmax-with-Loss 层 ”。 
![[Pasted image 20230505171943.png]]
softmax 函数记为 Softmax 层，交叉熵损失记为 Cross Entropy Error 层。这里假设要进行 3 类分类，从前面的层接收 3 个输入（得分）。如图 5-30 所示，Softmax 层将输入（a1, a2, a3）正规化，输出（y1, y2, y3）。 Cross Entropy Error 层接收 Softmax 的输出（y1, y2, y3）和监督标签（t1, t2, t3），从这些数据中输出损失 L。
![[Pasted image 20230505172119.png]]

Softmax 层的反向传播得到了（y1 − t1, y2 − t2, y3 − t3）这样“漂亮”的结果。由于（y1, y2, y3）是 Softmax 层的输出，（ t1, t2, t3）是监督数据，所以（y1 − t1, y2 − t2, y3 − t3）是 **Softmax 层的输出和监督标签的差分**。**神经网络的反向传播会把这个差分表示的误差传递给前面的层，这是神经网络学习中的重要性质。**

**神经网络学习的目的就是通过调整权重参数，使神经网络的输出（Softmax 的输出）接近监督标签。因此，必须将神经网络的输出与监督标签的误差高效地传递给前面的层**。刚刚的（y1 − t1, y2 − t2, y3 − t3）正是 Softmax 层的输出与监督标签的差，直截了当地表示了当前神经网络的输出与监督标签的误差。

这里考虑一个具体的例子，比如思考监督标签是（0, 1, 0）， Softmax 层的输出是 (0.3, 0.2, 0.5) 的情形。因为正确解标签处的概率是 0.2（20%），这个时候的神经网络未能进行正确的识别。此时，Softmax 层的反向传播传递的是 (0.3, −0.8, 0.5) 这样一个大的误差。因为这个大的误差会向前面的层传播，所以 **Softmax 层前面的层会从这个大的误差中学习到“大”的内容。**
举一个例子，比如思考监督标签是 (0, 1, 0)，Softmax 层的输出是 (0.01, 0.99, 0) 的情形（这个神经网络识别得相当准确）。此时 Softmax 层的反向传播传递的是 (0.01, −0.01, 0) 这样一个小的误差。这个小的误差也会向前面的层传播，因为误差很小，所以 Softmax 层前面的层学到的内容也很“小”。

> [!NOTE]
> 使用交叉熵损失作为 softmax 函数的损失函数后，反向传播得到（y1 − t1, y2 − t2, y3 − t3）这样 “漂亮”的结果。**实际上，这样“漂亮”的结果并不是偶然的，而是为了得到这样的结果，特意设计了交叉熵损失函数**。
> 
> 回归问题中输出层使用“恒等函数”，损失函数使用“平方和误差”，也是出于同样的理由（3.5 节）。也就是说，使用“平方和误差”作为“恒等函数”的损失函数，反向传播才能得到（y1 − t1, y2 − t2, y3 − t3）这样“漂亮”的结果。

```python title:Soft-with-Loss层
# x：输入 y：softmax的输出 t：监督标签
class SoftmaxWithLoss:
    def __init__(self):
        self.loss = None
        self.y = None # softmax的输出
        self.t = None # 监督数据
        
    def forward(self, x, t):
        self.t = t
        self.y = softmax(x)
        self.loss = cross_entropy_error(self.y, self.t)    
        
        return self.loss
        
    def backward(self, dout=1):
        batch_size = self.t.shape[0] # t是二维，t.shape[0]表示行的个数
        if self.t.size == self.y.size: # 监督数据是one-hot-vector的情况,注意反向传播时，将要传播的值除以批的大小（batch_size）后，传递给前面的层的是单个数据的误差。
            dx = (self.y - self.t) / batch_size
        else:
            dx = self.y.copy()
            dx[np.arange(batch_size), self.t] -= 1
            dx = dx / batch_size  
                
        return dx
```

## 5.7 误差反向传播法的实现
### 对应误差反向传播法的神经网络的实现
神经网络的学习分成下面 4 个步骤。
**步骤 1（mini-batch）**
从训练数据中随机选出一部分数据，这部分数据称为 mini-batch。我们的目标是减小 mini-batch 的损失函数的值。
**步骤 2（计算梯度）**
为了减小 mini-batch 的损失函数的值，需要求出各个权重参数的梯度。梯度表示损失函数的值减小最多的方向。
**步骤 3（更新参数）**
将权重参数沿梯度方向进行微小更新。
**步骤 4（重复）**
重复步骤 1、步骤 2、步骤 3。

误差反向传播法会在步骤 2 中出现。上一章中，我们利用数值微分求得了这个梯度。数值微分虽然实现简单，但是计算要耗费较多的时间。和需要花费较多时间的数值微分不同，误差反向传播法可以快速高效地计算梯度。
```python title: TwoLayerNet类
import sys, os
sys.path.append(os.pardir) 
import numpy as np
from common.layers import *
from common.gradient import numerical_gradient
from collections import OrderedDict

class TwoLayerNet:
    def __init__(self, input_size, hidden_size, output_size, 
                 weight_init_std=0.01):     
        # 初始化权重 
        self.params = {}
        self.params['W1'] = weight_init_std * \
                            np.random.randn(input_size, hidden_size) 
        self.params['b1'] = np.zeros(hidden_size)
        self.params['W2'] = weight_init_std * \
                            np.random.randn(hidden_size, output_size) 
        self.params['b2'] = np.zeros(output_size)
        
        # 生成层
        self.layers = OrderedDict() 
        self.layers['Affine1'] = \
            Affine(self.params['W1'], self.params['b1']) 
        self.layers['Relu1'] = Relu()
        self.layers['Affine2'] = \
            Affine(self.params['W2'], self.params['b2']) 
        self.lastLayer = SoftmaxWithLoss()
        
    def predict(self, x):
        for layer in self.layers.values(): 
            x = layer.forward(x)
            
        return x
        
    # x:输入数据 , t:监督数据 
    def loss(self, x, t): 
        y = self.predict(x)
        return self.lastLayer.forward(y, t) 
        
    def accuracy(self, x, t):
        y = self.predict(x) 
        y = np.argmax(y, axis=1)
        if t.ndim != 1 : t = np.argmax(t, axis=1)
        accuracy = np.sum(y == t) / float(x.shape[0]) 
        
        return accuracy
        
    # 通过数值微分计算关于权重参数的梯度（同上一章）
    # x:输入数据 , t:监督数据
    def numerical_gradient(self, x, t): 
        loss_W = lambda W: self.loss(x, t)
        grads = {}
        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])
        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])
        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])
        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])
        
        return grads
        
    # 通过误差反向传播法计算关于权重参数的梯度
    def gradient(self, x, t): 
        # forward
        self.loss(x, t) 
        # backward
        dout = 1
        dout = self.lastLayer.backward(dout) 
        layers = list(self.layers.values())
        layers.reverse()
        for layer in layers: 
            dout = layer.backward(dout)
        # 设定
        grads = {}
        grads['W1'] = self.layers['Affine1'].dW
        grads['b1'] = self.layers['Affine1'].db
        grads['W2'] = self.layers['Affine2'].dW
        grads['b2'] = self.layers['Affine2'].db
        
        return grads
```
这个类的实现稍微有一点长，但是内容和 4.5 节的学习算法的实现有很多共通的部分，**不同点主要在于这里使用了层**。通过使用层，获得识别结果的处理（predict ()）和计算梯度的处理（gradient ()）只需通过层之间的传递就能完成。

将神经网络的层保存为 OrderedDict 这一点非常重要。OrderedDict 是有序字典，“有序”是指它可以记住向字典里添加元素的顺序。因此，神经网络的正向传播只需按照添加元素的顺序调用各层的 forward () 方法就可以完成处理，而反向传播只需要按照相反的顺序调用各层即可。因为 Affine 层和 ReLU 层的内部会正确处理正向传播和反向传播，所以这里要做的事情仅仅是以正确的顺序连接各层，再按顺序（或者逆序）调用各层。
像这样通过将神经网络的组成元素以层的方式实现，可以轻松地构建经网络。这个用层进行模块化的实现具有很大优点。因为想另外构建一个神经网络（比如 5 层、10 层、20 层……的大的神经网络）时，只需像组装乐高积木那样添加必要的层就可以了。之后，通过各个层内部实现的正向传播和反向传播，就可以正确计算进行识别处理或学习所需的梯度。
### 误差反向传播法的梯度确认
我们介绍了两种求梯度的方法。
一种是基于数值微分的方法，另一种是解析性地求解数学式的方法。后一种方法通过使用误差反向传播法，即使存在大量的参数，也可以高效地计算梯度。因此，后文将不再使用耗费时间的数值微分，而是使用误差反向传播法求梯度。
数值微分的优点是实现简单，因此，一般情况下不太容易出错。而误差反向传播法的实现很复杂，容易出错。所以，经常会比较数值微分的结果和误差反向传播法的结果，以确认误差反向传播法的实现是否正确。**确认数值微分求出的梯度结果和误差反向传播法求出的结果是否一致（严格地讲，是非常相近）的操作称为梯度确认（gradient check）**

### 使用误差反向传播法的学习
```python
import sys, os
sys.path.append(os.pardir) 
import numpy as np
from dataset.mnist import load_mnist 
from two_layer_net import TwoLayerNet

# 读入数据
(x_train, t_train), (x_test, t_test) = \
    load_mnist(normalize=True, one_hot_label=True)
network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10) 
iters_num = 10000
train_size = x_train.shape[0] 
batch_size = 100
learning_rate = 0.1 
train_loss_list = [] 
train_acc_list = [] 
test_acc_list = []
iter_per_epoch = max(train_size / batch_size, 1) 

for i in range(iters_num):
    batch_mask = np.random.choice(train_size, batch_size) 
    x_batch = x_train[batch_mask]
    t_batch = t_train[batch_mask] 
    
    # 通过误差反向传播法求梯度
grad = network.gradient(x_batch, t_batch) 

    # 更新
    for key in ('W1', 'b1', 'W2', 'b2'):
        network.params[key] -= learning_rate * grad[key] 
    loss = network.loss(x_batch, t_batch)
    train_loss_list.append(loss) 
    if i % iter_per_epoch == 0:
        train_acc = network.accuracy(x_train, t_train) 
        test_acc = network.accuracy(x_test, t_test) 
        train_acc_list.append(train_acc)
        test_acc_list.append(test_acc) 
        print(train_acc, test_acc)
```

# 【未学习】第 6 章与学习相关的技巧

## 6.1 参数的更新

神经网络的学习的目的是找到使损失函数的值尽可能小的参数。这是寻找最优参数的问题，解决这个问题的过程称为最优化（optimization）。

## 深度学习中的常用数学算法

推荐一个网站：[https://www.tensorinfinity.com/viewlab.html](https://www.tensorinfinity.com/viewlab.html)  
里面可以直观得观察你输入函数的图像，方便理解。  
优化器算法比较：  
[https://www.cnblogs.com/guoyaohua/p/8542554.html](https://www.cnblogs.com/guoyaohua/p/8542554.html)

### 6.1.2 SGD

SGD：随机梯度下降法（stochastic gradient descent）  

  
（这里把需要更新的权重参数记为 W，把损失函数关于 W 的梯度记为∂L/∂W。η表示学习率，实际上会取 0.01 或 0.001 这些事先决定好的值。式子中的←表示用右边的值更新左边的值。SGD 是朝着梯度方向只前 进一定距离的简单方法。）

```
class SGD:
    """随机梯度下降法（Stochastic Gradient Descent）"""
    
    def __init__(self, lr=0.01):
        self.lr = lr    
        
    def update(self, params, grads):
        for key in params.keys():
            params[key] -= self.lr * grads[key]  #grads[key]：字典型变量
```

**SGD 的缺点**：  
1）由于梯度下降法向目标函数梯度为零的点收敛，因此迭代可能停止在鞍点处。例如，目标函数 y2-x2 存在鞍点（0, 0），当 x 轴的初始位置为 0 时，梯度下降法会停止在鞍点。  

![[1681573993851]]

  
2）梯度下降法只会收敛到极小值点，而不一定是最小值点。当目标函数存在多个极小值点时，初始位置的选择十分重要。例如，目标函数 y4 + 3_x4 +8_x3- 48*x2 存在两个极小值，在默认参数下，梯度下降法会收敛到极小值点而非最小值点。  

![[1681573993887]]

  
3）梯度下降法的学习率是人为设置的一个参数，当学习率较小时，达到收敛的迭代次数较大。当学习率较大时，会存在极小值点处震荡甚至无法收敛的情况。例如，目标函数为 y2+x2，当学习率大于 0.5 时开始出现震荡现象，当学习率大于等于 1 时则无法收敛。  

![[1681573993938]]

  

![[1681573993986]]

  

![[1681573994028]]

  
4）在书上那个例子中，SGD 的缺点是，如果函数的形状非均向（anisotropic），比如呈延伸状，搜索的路径就会非常低效。因此 SGD 低效的根本原因是，梯度的方向并没有指向最小值的方向。

### 6.1.4 Momentum

![[1681573994065]]

  
（W 表示要更新的权重参数，∂L/∂W 表示损失函数关于 W 的梯度，η表示学习率。这里新出现了一个变量 v，对应物理上的速度。 上式表示了物体在梯度方向上受力，在这个力的作用下，物体的速度增加这一物理法则。）  

![[1681573994126]]

```
class Momentum:
    """Momentum SGD"""
    def __init__(self, lr=0.01, momentum=0.9):
        self.lr = lr
        self.momentum = momentum
        self.v = None      
        
    def update(self, params, grads):
        if self.v is None:
            self.v = {}
            for key, val in params.items():                                
                self.v[key] = np.zeros_like(val)               
                
        for key in params.keys():
            self.v[key] = self.momentum*self.v[key] - self.lr*grads[key] 
            params[key] += self.v[key]
```

理解：当我们将一个小球从山上滚下来时，没有阻力的话，它的动量会越来越大，但是如果遇到了阻力，速度就会变小。加入了αv 这一项，可以使得梯度方向不变的维度上速度变快，梯度方向有所改变的维度上的更新速度变慢，这样就可以加快收敛并减小震荡。  
超参数设定值: 一般 α 取值 0.9 左右。  
**Momentum 缺点**：  
这种情况相当于小球从山上滚下来时是在盲目地沿着坡滚，如果它能具备一些先知，例如快要上坡时，就知道需要减速了的话，适应性会更好。

### 牛顿法

[https://www.tensorinfinity.com/lab_22.html](https://www.tensorinfinity.com/lab_22.html)

### BFGS

[https://www.tensorinfinity.com/lab_57.html](https://www.tensorinfinity.com/lab_57.html)

### 6.1.5 AdaGrad

在神经网络的学习中，学习率（数学式中记为η）的值很重要。学习率过小， 会导致学习花费过多时间；反过来，学习率过大，则会导致学习发散而不能 正确进行。 在关于学习率的有效技巧中，有一种被称为**学习率衰减**（learning rate decay）的方法，即随着学习的进行，使学习率逐渐减小。实际上，一开始 “多” 学，然后逐渐“少” 学的方法，在神经网络的学习中经常被使用。 逐渐减小学习率的想法，相当于将 “全体” 参数的学习率值一起降低。 而 AdaGrad 进一步发展了这个想法，针对 “一个一个“的参数，赋予其“定制” 的值。 AdaGrad 会为参数的每个元素适当地调整学习率，与此同时进行学习 （AdaGrad 的 Ada 来自英文单词 Adaptive，即 “适当的” 的意思）。  

![[1681573994161]]

  
（W 表示要更新的权重参数，∂L/∂W 表示损失函数关于 W 的梯度，η表示学习率。这里新出现了变量 h，它保存了以前的所有梯度值的平方和。然后，在更新参数时，通过乘以 1 / 根号下 h ，就可以调整学习的尺度。这意味着， 参数的元素中变动较大（被大幅更新）的元素的学习率将变小。也就是说， 可以按参数的元素进行学习率衰减，使变动大的参数的学习率逐渐减小。）

```
class AdaGrad:
    """AdaGrad"""
    
    def __init__(self, lr=0.01):
        self.lr = lr
        self.h = None
              
    def update(self, params, grads):
        if self.h is None:
            self.h = {}
            for key, val in params.items():
                self.h[key] = np.zeros_like(val)
                           
        for key in params.keys():
            self.h[key] += grads[key] * grads[key]
            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)
```

**AdaGrad 总结**：  
1）AdaGrad 算法可以对低频的参数做较大的更新，对高频的做较小的更新，也因此，对于稀疏的数据它的表现很好，很好地提高了 SGD 的鲁棒性。  
2）Adagrad 的优点是减少了学习率的手动调节；超参数设定值：一般η选取 0.01；缺点是它的缺点是分母会不断积累，这样学习率就会收缩并最终会变得非常小。  
3）AdaGrad 考虑了从开始到当前迭代时的所有梯度值，随着迭代次数的增加学习率逐渐下降，与标准梯度下降法相比，需要更多的迭代次数才能达到相同的效果，训练速度较慢。  

![[1681573994197]]

4）与标准梯度下降法相比，Adagrad 算法收敛性较好，不易出现震荡现象。  

![[1681573994219]]

  
5）AdaGrad 算法存在停止在鞍点处的情况。例如，目标函数 y2-x2 存在鞍点（0, 0），当 x 轴的初始位置为 0 时，迭代会停止在鞍点。  

![[1681573994281]]

  
6）AdaGrad 算法只会收敛到极小值点，而不一定是最小值点。当目标函数存在多个极小值点时，初始位置的选择十分重要。例如，目标函数 y4+3_x4+8_x3-48*x2 存在两个极小值，在默认参数下，AdaGrad 算法会收敛到极小值点而非最小值点。  

![[1681573994301]]

### AdaDelta

[https://www.tensorinfinity.com/lab_23.html](https://www.tensorinfinity.com/lab_23.html)

### RMSprop

RMSprop 和 Adadelta 都是为了解决 Adagrad 学习率急剧下降问题的。  
AdaGrad 会记录过去所有梯度的平方和。因此，学习越深入，更新的幅度就越小。实际上，如果无止境地学习，更新量就会变为 0， 完全不再更新。为了改善这个问题，可以使用 RMSProp 方法。 RMSProp 方法并不是将过去所有的梯度一视同仁地相加，而是逐渐地遗忘过去的梯度，在做加法运算时将新梯度的信息更多地反映出来。 这种操作从专业上讲，称为 “指数移动平均”，呈指数函数式地减小过去的梯度的尺度。  
[https://www.tensorinfinity.com/lab_63.html](https://www.tensorinfinity.com/lab_63.html)

```
class RMSprop:
    """RMSprop"""
    
    def __init__(self, lr=0.01, decay_rate = 0.99):
        self.lr = lr
        self.decay_rate = decay_rate
        self.h = None       
        
    def update(self, params, grads):
        if self.h is None:
            self.h = {}
            for key, val in params.items():
                self.h[key] = np.zeros_like(val)
                           
        for key in params.keys():
            self.h[key] *= self.decay_rate
            self.h[key] += (1 - self.decay_rate) * grads[key] * grads[key]
            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)
```

### Nesterov

[https://www.tensorinfinity.com/lab_61.html](https://www.tensorinfinity.com/lab_61.html)  
Nesterov Accelerated Gradient（NAG）  
梯度更新规则:  
用 θ−γv_t−1 来近似当做参数下一步会变成的值，则在计算梯度时，不是在当前位置，而是未来的位置上。  

![[1681573994564]]

  
超参数设定值: 一般 γ 仍取值 0.9 左右。  

![[1681573994612]]

  
蓝色是 Momentum 的过程，会先计算当前的梯度，然后在更新后的累积梯度后会有一个大的跳跃。而 Nesterov 会先在前一步的累积梯度上 (brown vector) 有一个大的跳跃，然后衡量一下梯度做一下修正(red vector)，这种预期的更新可以避免我们走的太快。  
Nesterov 可以使 RNN 在很多任务上有更好的表现。  
目前为止，我们可以做到，在更新梯度时顺应 loss function 的梯度来调整速度，并且对 SGD 进行加速。我们还希望可以根据参数的重要性而对不同的参数进行不同程度的更新。

```
class Nesterov:
    """Nesterov's Accelerated Gradient (http://arxiv.org/abs/1212.0901)"""
    
    def __init__(self, lr=0.01, momentum=0.9):
        self.lr = lr
        self.momentum = momentum
        self.v = None
                
    def update(self, params, grads):
        if self.v is None:
            self.v = {}
            for key, val in params.items():
                self.v[key] = np.zeros_like(val)
                            
        for key in params.keys():
            self.v[key] *= self.momentum
            self.v[key] -= self.lr * grads[key]
            params[key] += self.momentum * self.momentum * self.v[key]
            params[key] -= (1 + self.momentum) * self.lr * grads[key]
```

### 6.1.6 Adam

Adam 算法全称为 adaptive moment estimation 自适应矩估计。  
[Adam 直观介绍](https://www.tensorinfinity.com/lab_59.html)  

![[1681573994661]]

```
class Adam:
    """Adam (http://arxiv.org/abs/1412.6980v8)"""
    
    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):
        self.lr = lr
        self.beta1 = beta1
        self.beta2 = beta2
        self.iter = 0
        self.m = None
        self.v = None
                
    def update(self, params, grads):
        if self.m is None:
            self.m, self.v = {}, {}
            for key, val in params.items():
                self.m[key] = np.zeros_like(val)
                self.v[key] = np.zeros_like(val)        
        self.iter += 1
        lr_t  = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)                 
        for key in params.keys():
            #self.m[key] = self.beta1*self.m[key] + (1-self.beta1)*grads[key]
            #self.v[key] = self.beta2*self.v[key] + (1-self.beta2)*(grads[key]**2)
            self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])
            self.v[key] += (1 - self.beta2) * (grads[key]**2 - self.v[key])           
            
            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)           
            
            #unbias_m += (1 - self.beta1) * (grads[key] - self.m[key]) # correct bias
            #unbisa_b += (1 - self.beta2) * (grads[key]*grads[key] - self.v[key]) # correct bias
            #params[key] += self.lr * unbias_m / (np.sqrt(unbisa_b) + 1e-7)
```

### 6.1.7 使用哪种更新方法

如果数据是稀疏的，就用自适用方法，即 Adagrad, Adadelta, RMSprop, Adam。  
RMSprop, Adadelta, Adam 在很多情况下的效果是相似的。  
Adam 就是在 RMSprop 的基础上加了 bias-correction 和 momentum，  
随着梯度变的稀疏，Adam 比 RMSprop 效果会好。  
整体来讲，Adam 是最好的选择。  
很多论文里都会用 SGD，没有 momentum 等。SGD 虽然能达到极小值，但是比其它算法用的时间长，而且可能会被困在鞍点。  
如果需要更快的收敛，或者是训练更深更复杂的神经网络，需要用一种自适应的算法。

## 6.2 权重的初始值

### 6.2.1 可以将权重初始值设为 0 吗

如果想减小权重的值，一开始就将初始值设为较小的值才是正途。实际上， 在这之前的权重初始值都是像 0.01 * np.random.randn(10, 100) 这样，使用 由高斯分布生成的值乘以 0.01 后得到的值（**标准差为 0.01 的高斯分布**）。

### 6.2.2 Xavier 初始值

比如，Caffe 框架中，通过在设定权重初始值时赋予 xavier 参数， 就可以使用 Xavier 初始值。  
如果前一层的节点数为 n，则初始 值使用标准差为

![[1681573994711]]

的分布。

### tanh 函数

tanh 是双曲函数中的一个，tanh()为双曲正切。在数学中，双曲正切 “tanh” 是由基本双曲函数双曲正弦和双曲余弦推导而来。  

![[1681573994734]]

  

![[1681573994753]]

### 6.2.3 ReLU 的权重初始值——He 初始值

![[1681573994833]]

## Batch Normalization

Batch Norm 的思路是调整各层的激活值分布使其拥有适当 的广度。为此，要向神经网络中插入对数据分布进行正规化的层，即 Batch Normalization 层（简称 Batch Norm 层）。  

![[1681573994854]]

  

![[1681573994886]]

  
（这里对 mini-batch 的 m 个输入数据的集合 B ={x1,x2,…,xm} 求均值 µB 和方差σ2B。然后，对输入数据进行均值为 0、方差为 1（合适的分布）的正规化。其中的 ε是一个微小值（比如，10e-7 等），它是为了防止出现除以 0 的情况。  
上式所做的是将 mini-batch 的输入数据 {x1,x 2,…,xm} 变换为均值为 0、方差为 1 的数据 ，非常简单。通过将这个处理插入到激活函数的前面（或者后面），可以减小数据分布的偏向。 ）

## 6.4 正则化

### 6.4.1 过拟合

定义：过拟合指的是只能拟合训练数据，但不能很好地拟合不包含在训练数据中的其他数据的状态。  
发生过拟合的原因：  
①模型拥有大量参数、表现力强。  
② 训练数据少。

### 6.4.2 权值衰减（L1、L2、L∞范数）

权值衰减是一直以来经常被使用的一种抑制过拟合的方法。该方法通过在学习的过程中对大的权重进行惩罚，来抑制过拟合。很多过拟合原本就是因为权重参数取值过大才发生的。  

![[1681573994940]]

  
||x||1 也称为 L1 范数，是各个元素的绝对值之和  
||x||2 也称为 L2 范数  
||x||∞也称为 L∞范数，或 Max 范数

### 6.4.3 Dropout

上节说到抑制过拟合的方法，为损失函数加上权重的 L2 范数的权值衰减方法。该方法可以在某种程度上能够抑制过拟合。 但是，如果网络的模型变得很复杂，权值衰减就难以应对。在这种情 况下，经常会使用 Dropout 方法。 Dropout 是一种在学习的过程中随机删除神经元的方法。训练时，随机选出隐藏层的神经元，然后将其删除。被删除的神经元不再进行信号的传递。如下图所示：  

![[1681573994969]]

```
class Dropout: 
    def __init__(self, dropout_ratio=0.5):        
        self.dropout_ratio = dropout_ratio        
        self.mask = None
        
    def forward(self, x, train_flg=True):        
        if train_flg:            
            self.mask = np.random.rand(*x.shape) > self.dropout_ratio            
            return x * self.mask        
        else:            
            return x * (1.0 - self.dropout_ratio)
            
    def backward(self, dout):        
        return dout * self.mask
# 每次正向传播时，self.mask中都会以False的形式保 存要删除的神经元。
# self.mask会随机生成和x形状相同的数组，并将值比dropout_ratio大的元素设为True。
# 反向传播时的行为和ReLU相同。也就是说， 正向传播时传递了信号的神经元，
#反向传播时按原样传递信号；正向传播时没有传递信号的神经元，
#反向传播时信号将停在那里。
```

## 6.5 超参数的验证

之前对于数据集，是将其分为训练集和测试集，训练数据用于学习，测试数据用于评估泛化能力。现在，还要分出一个验证集，训练数据用于参数（权重和偏置）的学习，验证数据用于超参数的性能评估。为了确认泛化能力，要在最后使用（比较理想的是只用一次） 测试数据。

```
import numpy as np
np.random.shuffle # 现场修改序列，改变自身内容（类似洗牌，打乱顺序）
```

# 第 7 章 卷积神经网络

[卷积神经网络的工作原理](https://www.bilibili.com/video/BV1sb411P7pQ?t=1)  
[视频中的笔记](https://zhuanlan.zhihu.com/p/49184702)

## 7.1 整体结构
之前介绍的神经网络中，相邻层的所有神经元之间都有连接，这称为**全连接（fully-connected ）**
我们用 Affine 层实现了全连接层。如果使用这个 Affine 层，一个 5 层的全连接的神经网络就可以通过图 7-1 所示的网络结构来实现如图 7-1 所示，全连接的神经网络中，Affine 层后面跟着激活函数 ReLU 层（ 或者 Sigmoid 层）。这里堆叠了 4 层“ Affine-ReLU”组合，然后第 5 层是 Affine 层，最后由 Softmax 层输出最终结果（概率）。![[Pasted image 20230505174641.png]]

CNN 中新出现了**卷积层（Convolution 层）和池化层（Pooling 层 ）**, CNN 的 
层的连接顺序是“Convolution - ReLU -（Pooling） ”（ Pooling 层有时会被省 
略）
![[Pasted image 20230505174733.png]]
## 7.2 卷积层

### 7.2.1 全连接层存在的问题
**全连接层存在什么问题呢？那就是数据的形状被“忽视”了**。比如：输入数据是图像时，图像通常是高、长、通道方向上的 3 维形状。但是，向全连接层输入时，需要将 3 维数据拉平为 1 维数据。就像前面的手写数字识别例子中，输入图像就是 1 通道、高 28 像素、长 28 像素的（1, 28, 28）形状，但却被排成 1 列，以 784 个数据的形式输入到最开始的 Affine 层。**全连接层会忽视形状，将全部的输入数据作为相同的神经元（同一维度的神经元）处理，所以无法利用与形状相关的信息** 

而**卷积层可以保持形状不变**。当输入数据是图像时，卷积层会以 3 维数据的形式接收输入数据，并同样以 3 维数据的形式输出至下一层。因此， 在 CNN 中，可以（有可能）正确理解图像等具有形状的数据。

> [!NOTE] 
> CNN 中，有时将卷积层的**输入输出数据称为特征图（feature map）**。其中，卷积层的输入数据称为**输入特征图**（input feature map），输出数据称为**输出特征图**（output feature map）。**本书中将“ 输入输出数据 ”和“ 特征图”作为含义相同的词使用。**

### 7.2.2 卷积运算 
#### 计算顺序
![[Pasted image 20230505175309.png]]
#### 卷积运算的偏置
在全连接的神经网络中，除了权重参数，还存在偏置。
**CNN 中，滤波器的参数就对应之前的权重。** 并且，**CNN 中也存在偏置**
向应用了滤波器的数据加上了偏置。偏置通常只有 1 个 （1 × 1（本例中，相对于应用了滤波器的 4 个数据，偏置只有 1 个），这个值会被加到应用了滤波器的所有元素上。
```c
1233
```
![[Pasted image 20230505175323.png]]

### 7.2.3 填充 
向输入数据的周围填入固定的数据（比如 0 等），这称为**填充（padding）**，是卷积运算中经常会用到的处理。
![[Pasted image 20230505175452.png]]
通过填充，大小为 (4, 4) 的输入数据变成了 (6, 6) 的形状。然后，应用大小为 (3, 3) 的滤波器，生成了大小为 (4, 4) 的输出数据。

> [!NOTE] 
> **使用填充主要是为了调整输出的大小。**
> 
> 比如，对大小为 (4, 4) 的输入数据应用 (3, 3) 的滤波器时，输出大小变为 (2, 2)，相当于输出大小比输入大小缩小了 2 个元素。这在反复进行多次卷积运算的深度网络中会成为问题。
> 
> **为什么呢？因为如果每次进行卷积运算都会缩小空间，那么在某个时刻输出大小就有可能变为 1，导致无法再应用卷积运算**。为了避免出现这样的情况，就要使用填充。在刚才的例子中，将填充的幅度设为 1，那么相对于输入大小 (4, 4)，输出大小也保持为原来的 (4, 4)。因此，**卷积运算就可以在保持空间大小不变的情况下将数据传给下一层。**



### 7.2.4 步幅 
应用滤波器的位置间隔称为**步幅（stride）** 
![[Pasted image 20230505175637.png]]

综上，增大步幅后，输出大小会变小。而增大填充后，输出大小会变大 

如果将这样的关系写成算式，会如何呢？接下来，我们看一下**对于填充和步幅，如何计算输出大小**。这里，假设输入大小为 $(H, W)$，滤波器大小为 $(FH, FW)$，输出大小为 $(OH, OW)$，填充为 $P$，步幅为 $S$。此时，输出大小可通过式 (7.1) 进行计算。
$$
\begin{array}{l}OH=\frac{H+2P-FH}{S}+1\\\\ OW=\frac{W+2P-FW}{S}+1\end{array}
$$
这里需要注意的是，虽然只要代入值就可以计算输出大小，但是**所设定的值必分别可以除尽**。当输出大小无法除尽时（结果是小数时），需要采取报错等对策。顺便说一下，根据深度学习的框架的不同，当值无法除尽时，有时会向最接近的整数四舍五入，不进行报错而继续运行。

### 7.2.5 3维数据的卷积运算

> [!NOTE] Title
> - 在 3 维数据的卷积运算中，**输入数据和滤波器的通道数要设为相同的值**
> - 滤波器大小可以设定为任意值（不过，每个通道的滤波器大小要全部相同） 

之前的卷积运算的例子都是以有高、长方向的 2 维形状为对象的。但是，图像是 3 维数据，**除了高、长方向之外，还需要处理通道方向。**
![[Pasted image 20230505175930.png]]

可以发现，纵深方向（通道方向）上特征图增加了。通道方向上有多个特征图时，会按通道进行输入数据和滤波器的卷积运算，并**将结果相加**，从而得到输出。
![[Pasted image 20230505180004.png]]

### 7.2.6 结合方块思考
将数据和滤波器结合长方体的方块来考虑，3 维数据的卷积运算会很容易理解。方块是如图 7-10 所示的 3 维长方体。把 3 维数据表示为多维数组时，书写顺序为（channel, height, width）。比如，通道数为 C、高度为 H、长度为 W 的数据的形状可以写成（C, H, W）。滤波器也一样，要按（channel, height, width）的顺序书写。比如，通道数为 C、滤波器高度为 FH（Filter Height）、长度为 FW（Filter Width）时，可以写成（C, FH, FW）。
![[Pasted image 20230505180141.png]]

**如果要在通道方向上也拥有多个卷积运算的输出，该怎么做呢？为此，就需要用到多个滤波器（权重）**
![[Pasted image 20230505180226.png]]

通过应用 FN 个滤波器，输出特征图也生成了 FN 个。如果将这 FN 个特征图汇集在一起，就得到了形状为 (FN, OH, OW) 的方块。将这个方块传给下一层，就是 CNN 的处理流。
**关于卷积运算的滤波器，也必须考虑滤波器的数量。** 因此，作为 4 维数据，**滤波器的权重数据要按 (output_channel, input_ channel, height, width) 的顺序书写**。比如，通道数为 3、大小为 5 × 5 的滤波器有 20 个时，可以写成 (20, 3, 5, 5)。
**卷积运算中（和全连接层一样）存在偏置**。在图 7-11 的例子中，如果进一步追加偏置的加法运算处理，则结果如下面的图 7-12 所示。

![[Pasted image 20230505180419.png]]
这里，偏置的形状是 (FN, 1, 1)，滤波器的输出结果的形状是 (FN, OH, OW)。这两个方块相加时，要对滤波器的输出结果 (FN, OH, OW) 按通道加上相同的偏置值。
### 7.2.7 批处理
卷积运算的批处理需要将在各层间传递的数据保存为 4 维数据。具体地讲，就是按 (batch_num, channel, height, width) 的顺序保存数据 
![[Pasted image 20230505180615.png]]
批处理将 N 次的处理汇总成了 1 次进行。

## 7.3 池化层

**池化（又称下采样）是缩小高、长方向上的空间的运算**。如图 7-14 所示，进行将 2 × 2 的区域集约成 1 个元素的处理，缩小空间大小。
![[Pasted image 20230505180640.png]]
“Max 池化”是获取最大值的运算，一般来说，**池化的窗口大小会和步幅设定成相同的值。**

> [!NOTE] Title
> 除了 Max 池化之外，还有 Average 池化等。相对于 Max 池化是从目标区域中取出最大值，Average 池化则是计算目标区域的平均值。 在图像识别领域，主要使用 Max 池化。因此，本书中说到“ 池化层 ” 时，指的是 Max 池化。

池化层的特征：
1. 没有要学习的参数
池化层和卷积层不同，没有要学习的参数。池化只是从目标区域中取最大值（或者平均值），所以不存在要学习的参数。
2. 通道数不发生变化
经过池化运算，输入数据和输出数据的通道数不会发生变化。如图 7-15 所示，计算是按通道独立进行的。
![[Pasted image 20230505180857.png]]

3. 对微小的位置变化具有鲁棒性（健壮）
输入数据发生微小偏差时，池化仍会返回相同的结果。因此，池化对输入数据的微小偏差具有鲁棒性。比如，3 × 3 的池化的情况下，如图 7-16 所示，池化会吸收输入数据的偏差（根据数据的不同，结果有可能不一致）。
![[Pasted image 20230505180919.png]]

## 7.4 卷积层和池化层的实现

### 7.4.2 基于 im2col 的展开

> [!NOTE] Title
> im2col 这个名称是 “image to column” 的缩写，翻译过来就是 “从图像到矩阵” 的意思。Caffe、Chainer 等深度学习框架中有名为 im2col 的函数，并且在卷积层的实现中，都使用了 im2col。  

CNN 中各层间传递的数据是 4 维数据。所谓 4 维数据，比如数据的形状是 (10, 1, 28, 28)，则它对应 10 个高为 28、长为 28、通道为 1 的数据。

如果老老实实地实现卷积运算，要重复好几层的 for 语句。这样的实现有点麻烦，而且，NumPy 中存在使用 for 语句后处理变慢的缺点（NumPy 中，访问元素时最好不要用 for 语句）。这里，我们不使用 for 语句，而是使用 im2col 这个便利的函数进行简单的实现。
im2col 是一个函数，将输入数据展开以适合滤波器（权重）。如下图所示，对 3 维的输入数据应用 im2col 后，数据转换为 2 维矩阵（正确地讲，是把包含批数量的 4 维数据转换成了 2 维数据）。  
![[Pasted image 20230505181239.png]]

im2col 会把输入数据展开以适合滤波器（权重）。具体地说，如图 7-18 所示，对于输入数据，将应用滤波器的区域（3 维方块）横向展开为 1 列。**im2col 会在所有应用滤波器的地方进行这个展开处理。**
![[Pasted image 20230505181257.png]]

在实际的卷积运算中，滤波器的应用区域几乎都是重叠的。在滤波器的应用区域重叠的情况下，使用 im2col 展开后，展开后的元素个数会多于原方块的元素个数。因此，使用 im2col 的实现存在比普通的实现消耗更多内存的缺点。但是，汇总成一个大的矩阵进行计算，对计算机的计算颇有益处。

使用 im2col 展开输入数据后，之后就只需将卷积层的滤波器（权重）纵向展开为 1 列，并计算 2 个矩阵的乘积即可（参照图 7-19）。这和全连接层的Affine 层进行的处理基本相同。如图 7-19 所示，基于 im2col 方式的输出结果是 2 维矩阵。因为 CNN 中数据会保存为 4 维数组，所以要将 2 维输出数据转换为合适的形状。以上就是卷积层的实现流程。
![[Pasted image 20230505181531.png]]

im2col 这一便捷函数具有以下接口：
im2col (input_data, filter_h, filter_w, stride=1, pad=0)
• input_data―由（ 数据量，通道，高，长）的  4 维数组构成的输入数据
• filter_h―滤波器的高
• filter_w―滤波器的长
• stride―步幅
• pad―填充

```python title:im2col的使用
import sys, os
sys.path.append(os.pardir) 
from common.util import im2col 

x1 = np.random.rand(1, 3, 7, 7)
col1 = im2col(x1, 5, 5, stride=1, pad=0) 
print(col1.shape) # (9, 75)

x2 = np.random.rand(10, 3, 7, 7) # 10个数据 
col2 = im2col(x2, 5, 5, stride=1, pad=0) 
print(col2.shape) # (90, 75)
```
第一个是批大小为 1、通道为 3 的 7 × 7 的数据，第二个的批大小为 10，数据形状和第一个相同。
分别对其应用 im2col 函数，在这两种情形下，第 2 维的元素个数均为 75。这是滤波器（通道为 3、大小为 5 × 5）的元素个数的总和。批大小为 1 时，im2col 的结果是 (9, 75)。而第 2 个例子中批大小为 10，所以保存了 10 倍的数据，即 (90, 75)。

### 7.4.3 卷积层的实现
```python title:卷积层的实现：Convolution类 h:14-17
class Convolution:
    def __init__(self, W, b, stride=1, pad=0):
        self.W = W # 滤波器（权重）
        self.b = b # 偏置
        self.stride = stride # 步幅
        self.pad = pad # 填充
        
    def forward(self, x):
        FN, C, FH, FW = self.W.shape 
        N, C, H, W = x.shape
        out_h = int(1 + (H + 2*self.pad - FH) / self.stride) 
        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)
        
        # 用 im2col 展开输入数据，并用 reshape 将滤波器展开为 2 维数组。然后，计算展开后的矩阵的乘积。
        col = im2col(x, FH, FW, self.stride, self.pad) 
        col_W = self.W.reshape(FN, -1).T # 滤波器的展开 
        out = np.dot(col, col_W) + self.b
        
        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2) 
        
        return out
```
展开滤波器的部分（代码段中的粗体字）如图 7-19 所示，将各个滤波器的方块纵向展开为 1 列。这里通过 reshape (FN,-1) 将参数指定为 -1，这是 reshape 的一个便利的功能。通过在 reshape 时指定为 -1，reshape 函数会自动计算 -1 维度上的元素个数，以使多维数组的元素个数前后一致。比如， (10, 3, 5, 5) 形状的数组的元素个数共有 750 个，指定 reshape (10,-1) 后，就会转换成 (10, 75) 形状的数组。

forward 的实现中，最后会将输出大小转换为合适的形状。转换时使用了 NumPy 的 transpose 函数。transpose 会更改多维数组的轴的顺序。如图 7-20 所示，通过指定从 0 开始的索引（编号）序列，就可以更改轴的顺序。
![[Pasted image 20230505183151.png]]
接下来是卷积层的反向传播的实现，因为和 Affine 层的实现有很多共通的地方，所以就不再介绍了。但有一点需要注意，在进行卷积层的反向传播时，必须进行 im2col 的逆处理。

### 7.4.4 池化层的实现
池化层的实现和卷积层相同，都使用 im2col 展开输入数据。不过，池化的情况下，在通道方向上是独立的，这一点和卷积层不同。具体地讲，如图 7-21 所示，池化的应用区域按通道单独展开。

![[Pasted image 20230505183309.png]]

像这样展开之后，只需对展开的矩阵求各行的最大值，并转换为合适的形状即可
![[Pasted image 20230505183329.png]]

池化层的实现：
1. 展开输入数据。
2. 求各行的最大值。
3. 转换为合适的输出大小。

> [!NOTE] 
> 最大值的计算可以使用 NumPy 的 np. max 方法。np. max 可以指定 axis 参数，并在这个参数指定的各个轴方向上求最大值。比如，如果写成 np.max (x, axis=1)，就可以在输入 x 的第 1 维的各个轴方向上求最大值。

```python title:池化层的实现
class Pooling:
    def __init__(self, pool_h, pool_w, stride=1, pad=0):
        self.pool_h = pool_h
        self.pool_w = pool_w
        self.stride = stride
        self.pad = pad
    def forward(self, x): 
        N, C, H, W = x.shape
        out_h = int(1 + (H - self.pool_h) / self.stride) 
        out_w = int(1 + (W - self.pool_w) / self.stride)
        # 展开 (1)
        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad) 
        col = col.reshape(-1, self.pool_h*self.pool_w)
        # 最大值 (2)
        out = np.max(col, axis=1) 
        # 转换 (3)
        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2) 
        return out
```

关于池化层的 backward 处理，之前已经介绍过相关内容，这里就不再介绍了。另外，池化层的 backward 处理可以参考 ReLU 层的实现中使用的 max 的反向传播（ 5.5.1 节）。
## 7.5 CNN 的实现
我们已经实现了卷积层和池化层，现在来组合这些层，搭建进行手写数字识别的 CNN
![[Pasted image 20230505183615.png]]
P225
## 7.6 CNN 的可视化
刚才我们对 MNIST 数据集进行了简单的 CNN 学习。当时，第 1 层的卷积层的权重的形状是 (30, 1, 5, 5)，即 30 个大小为 5 × 5、通道为 1 的滤波器。滤波器大小是 5 × 5、通道数是 1，**意味着滤波器可以可视化为 1 通道的灰度图像** 
![[Pasted image 20230505183825.png]]
有规律的滤波器在“观察”什么，答案就是它在观察边缘（颜色变化的分界线）和斑块（局部的块状区域）等 
![[Pasted image 20230505183836.png]]
卷积层的滤波器会提取边缘或斑块等原始信息。而刚才实现的 CNN 会将这些原始信息传递给后面的层。 

根据深度学习的可视化相关的研究，随着层次加深，提取的信息（正确地讲，是反映强烈的神经元）也越来越抽象。 
![[Pasted image 20230505183918.png]]
随着层次加深，神经元从简单的形状向“高级”信息变化。换句话说，就像我们理解东西的“含义”一样，响应的对象在逐渐变化。 

# 第 8 章 深度学习
深度学习是加深了层的深度神经网络。基于之前介绍的网络，只需通过叠加层，就可以创建深度网络。
## 8.1 加深网络
### 8.1.1 向更深的网络出发
这里我们来创建一个如图 8-1 所示的网络结构的 CNN，使用的卷积层全都是 3 × 3 的小型滤波器，特点是随着层的加深，通道数变大（卷积层的通道数从前面的层开始按顺序以 16、16、32、32、64、64 的方式增加 

![[Pasted image 20230505184036.png]]
特点：
- 基于 3×3 的小型滤波器的卷积层。
- 激活函数是 ReLU。
- 全连接层的后面使用 Dropout 层。
- 基于 Adam 的最优化。
- 使用 He 初始值作为权重初始值。

### 8.1.2 进一步提高识别精度——Data Augmentation
![[Pasted image 20230505184232.png]]
Data Augmentation 基于算法 “人为地” 扩充输入图像（训练图像）。具体地说，对于输入图像，通过施加旋转、垂直或水平方向上的移动等微小变化，增加图像的数量。这在数据集的图像数量有限时尤其有效。
除了旋转、平移，Data Augmentation 还可以通过其他各种方法扩充图像，比如裁剪图像的 “crop 处理”、将图像左右翻转的“flip 处理” 等（flip 处理只在不需要考虑图像对称性的情况下有效）。对于一般的图像，施加亮度等外观上的变化、放大缩小等尺度上 的变化也是有效的。不管怎样，通过 Data Augmentation 巧妙地增加训练图像， 就可以提高深度学习的识别精度。

### 8.1.3 加深层的动机

加深层的好处：  
1. 可以减少网络的参数数量。说得详细一点，就是与没有加深层的网络相比，加深了层的网络可以用更少的参数达到同等水平（或者更强）的表现力。  

这一点结合卷积运算中的滤波器大小来思考就好理解了。比如，图 8-5 展示了由 5 × 5 的滤波器构成的卷积层。
![[1681573995238]]

  
![[1681573995291]]

  
> [!NOTE] Title
> 叠加小型滤波器来加深网络的好处是可以减少参数的数量，扩大**感受野（receptive field ，给神经元施加变化的某个局部空间区域）**。
> 
> 并且，通过叠加层，将 ReLU 等激活函数夹在卷积层的中间，进一步提高了网络的表现力。这是因为向网络添加了基于激活函数的“非线性”表现力，通过非线性函数的叠加，可以表现更加复杂的东西。

2. 使学习更加高效。与没有加深层的网络相比，通过加深层，可以减少学习数据，从而高效地进行学习。为了直观地理解这一点，参考书上的 7.6 节的内容。7.6 节中介绍了 CNN 的卷积层会分层次地提取信息。具体地说，在前面的卷积层中，神经元会对边缘等简单的形状有响应，随着层的加深，开始对纹理、物体部件等更加复杂的东西有响应。
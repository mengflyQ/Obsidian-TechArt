---
title: 总结
aliases: 
tags: []
create_time: 2023-04-25 23:05
uid: 202304252305
banner: "[[Pasted image 20230106142455.png]]"
banner_y: 0.27335
---

# 一、 线条绘制算法
## 1 DDA直线算法
**digital differential analyzer**
### 1.1 简单实现
如何在二维平面内表示一条直线？最常见的就是**斜截式**了：

y = kx+b

其中斜率是 k，直线在 yy 轴上的截距是 b。

**斜截式**在数学上是没啥问题的，但是在实际的工程项目中，因为硬件资源是有限的，我们**不可能也没必要**表示一条无限长度的直线，现实往往是已知一条线段的起点(x1​,y1​) 和终点(x2​,y2​)，然后把它画出来。

这时候用**两点式**表示一根直线是最方便的：
![[Pasted image 20230104180903.png]]
把上面的式子稍作变形，可以把 x 和 y 用参数 λ 表示：
![[Pasted image 20230104180947.png]]
这时候我们只要取不同的λ，就可以得出对应的 x 和 y。
按照以上的思路，我们可以用代码实现一下。`C++` 的实现也很简单，如下所示（dl 表示 dλ）：
```c++
void DDAline(int x1, int y1, int x2, int y2, TGAImage& image, TGAColor color)
{
    float dl = 0.01;
    int dx = x2 - x1;
    int dy = y2 - y1;
    for(float t = 0;t < 1;t += dl)
    {
        int x = x1 + t * dx;
        int y = y1 + t * dy;
        image.set(x, y, color);
    }
}
```
目的达到了，但是性能不太好：
-   每画一个点，都要运行两次乘法
-   大量使用浮点运算（众所周知，v<sub>float</sub><v<sub>fixed</sub><v<sub>int​</sub>）
-   如果 `dl` 取的比较小，会导致一个像素点会被绘制多次，重复计算
-   如果 `dl` 取的比较大，会导致直线断掉
### 1.2 优化
首先我们注意到，对于屏幕绘制直线这个场景，**理论上是连续的，但实际是离散的（以像素为单位绘制）**。

比如说 x 从 x1​ 变化到 x2​ 时，每次绘制时，x 都是按步长 1 增长的。也就是x<sub>new</sub>=x<sub>old</sub>+1这时候![[Pasted image 20230104182709.png]]

我们把上面的公式写成代码，就是下面这个样子：

```c++
void DDAline(int x1, int y1, int x2, int y2, TGAImage& image, TGAColor color)
{
    float x = x1;
    float y = y1;
    float step = std::abs(x2 - x1); //步数,即绘制次数
    float dlx = (x2 - x1) / step;   //x步长
    float dly = (y2 - y1) / step;   //y步长

    for(int i = 1;i < step;i++)
    {
        image.set(x, y, color);
        x = x + dlx;
        y = y + dly;
    }

}
```
这个算法其实还有一点儿问题，就是绘制斜率大于 1 的直线时，绘制出的直线会**断掉**（因为y的步长大）。比如说从 (0, 0) 点绘制到 (2, 4) 点，按照上面的算法只会绘制两个点，但是我们期望的是右图那样，起码各个像素要连接起来：
**绘制像素是根据像素坐下角的点进行绘制！左下角的点就代表这个像素！**
![[toyrenderer_day1_line.webp]]
解决方法也很简单，**绘制这种比较「陡峭」的直线时（斜率绝对值大于 1），以 y 的变化为基准，而不是以 x**，这样就可以避免上面直线不连续情况。

最后的直线算法就是这样：
```c++
void DDAline(int x1, int y1, int x2, int y2, TGAImage& image, TGAColor color)
{
    float x = x1;
    float y = y1;
    float dx = x2 - x1;
    float dy = y2 - y1;
    float step;
    float dlx, dly;
    // 根据 dx 和 dy 的长度决定基准
    if(std::abs(dx)>=std::abs(dy))
    {
        step = std::abs(dx);
    }
    else
    {
        step = std::abs(dy);
    }

    dlx = dx / step;   //x步长
    dly = dy / step;   //y步长

    for(int i = 1;i < step;i++)
    {
        image.set(x, y, color);
        x = x + dlx;
        y = y + dly;
    }
}
```
这个算法就是经典的 [DDA (Digital differential analyzer) 算法](https://www.wikiwand.com/en/Digital_differential_analyzer_(graphics_algorithm))，他比我们一开始的代码要高效的多：

-   消除了循环内的乘法运算
-   避免了重复的绘制运算
-   保证线段连续不会断掉

但是它还有个很耗性能的问题：计算过程中涉及大量的**浮点运算**。

作为渲染器最底层的算法，我们肯定希望是越快越好。下面我们就来学习一下，消除浮点运算的 Bresenham’s 直线算法。

## 2 Bresenham画线算法
### 2.1 算法原理
从数学的角度，建立一个坐标系，当我们在坐标系中画一条线时，这条线上的值（坐标的连续的）；但是计算机中的图像是以一个一个像素组成的，是一个又一个的小格子，那么在图像上已知起点和终点画一条线，这条线就是由一个一个格子组成的，**Bresenham算法就是去不断地寻找离“这条线”最近的格子（像素），然后画出线段**，如下图：
![[Pasted image 20230104190307.png]]

那么如何找离线最近的点呢？且看下图：

![[Pasted image 20230104190330.png]]
假设黑色（xi,yi）为 线段的起点，黑色的D点为经过该线的下一点，这时有两个像素点选择：（xi+1,yi+1）、（xi+1,yi），这两个点距离黑色D点的距离分别为d2、d1，通过比较d2和d1大小就可确定选取哪一点作为线段的下一个点。如d2小，说明距离(xi​+1,yi​+1)更近，所以绘制该点的像素。

### 2.2 初步实现
我们先假设已经绘制了一个点 (x, y)，那么在像素屏幕上，下一个新点的位置，只可能有两种情况：
-   (x+1, y)
-   (x + 1, y + 1)
那么问题就转化为，下一个新点的位置该如何选择？

-   先把 x<sub>new</sub> = x + 1 这个值带入直线方程里，算出来y<sub>new</sub>​ 的值
-   然后比较 y<sub>new</sub>​ 和 y + 0.5 的大小
    -  y<sub>new</sub>​  ≤ y + 0.5，说明距(x + 1, y)较近，选点 (x + 1, y)
    -  y<sub>new</sub>​ > y + 0.5，选点 (x + 1, y + 1)

我们再把思路完善一下，把每次取舍时的误差考虑进去：
![[day2_Bresenham_line.webp]]
如上图所示，实际上绘制的点的位置是 (x, y)，理论上点位置是 (x, y + ϵ)。
当点从 x 移动到 x+1 时，**理论**上新点的位置应该是 (x + 1, y + ϵ + k)，其中 k 是直线的斜率。
实际绘制时，要比较 y+ϵ+k 和 y + 0.5 的大小：

-  y+ϵ+k≤y+0.5，选点 (x+1, y)
-  y+ϵ+k>y+0.5，选点 (x+1, y+1)

对于下一个新点 x+2，我们可以按照下式更新误差 ϵ：

-   若前一个点选择的是(x+1, y)，则 ϵ<sub>new</sub>​=(y+ϵ+k)−y=ϵ+k
-   若前一个点选择的是 (x+1, y+1)，则 ϵ<sub>new</sub>​=(y+ϵ+k)−(y+1)=ϵ+k−1

把上面的思考过程用伪代码表示一下：
![[Pasted image 20230104191241.png]]
### 2.3 消除浮点运算
观察上面的伪代码，我们可以发现这里面出现了 0.5，也就是说存在浮点运算。下面我们就通过一些等价的数学变换消除浮点数。

首先对于不等式 ϵ+k<0.5，我们给它不等号左右两边同时乘以 **2 倍的 Δx**，这样就可以同时消除斜率除法和常量 0.5 带来的浮点运算:
![[Pasted image 20230104191439.png]]
然后用ϵ′ 表示ϵΔx，上式可以转换为2(ϵ′+Δy)<Δx

同样的，我们在更新 \ϵ 时，把它也替换为 ϵ′ ，也就是对于下面两式：
![[Pasted image 20230104191538.png]]
等号两边同时乘以 \Δx，有：
![[Pasted image 20230104191619.png]]
然后用 ϵ′ 表示 ϵΔx，可以得到：
![[Pasted image 20230104191635.png]]
这时候我们就可以得到一个去掉浮点数运算的伪代码：
![[Pasted image 20230104191643.png]]
```c++
void line(Screen &s,
  int x1, int y1,
  int x2, int y2,
  TGAImage &image, TGAColor color) 
  
{
  int y = y1;
  int eps = 0;
  int dx = x2 - x1;
  int dy = y2 - y1;

  for (int x = x1; x <= x2; x++) {
    image.set(x, y, color);
    eps += dy;
    // 这里用位运算 <<1 代替 *2
    if((eps << 1) >= dx)  {
      y++;
      eps -= dx;
    }
  }
}
```
这样我们就实现了斜率在 [0, 1][0,1] 区间的高效算法。也就是说，现在我们可以绘制 1/8 个象限的直线了。剩下范围的直线，可以通过交换 xy 等方式实现绘制。
![[v2-436a5d881b674d9c76313c8eb2c482a8_b 1.gif]]
最终算法如下：
```cpp
// Bresenham’s 直线算法
// 具体实现参考https://www.wikiwand.com/en/Bresenham%27s_line_algorithm#/All_cases
void line(int x1, int y1, int x2, int y2, TGAImage& image, TGAColor color) {
    // 处理斜率的绝对值大于 1 的直线
    bool steep = false;
    if (std::abs(x1 - x2) < std::abs(y1 - y2)) {
        std::swap(x1, y1);
        std::swap(x2, y2);
        steep = true;
    }
    // 交换起点终点的坐标
    if (x1 > x2) {
        std::swap(x1, x2);
        std::swap(y1, y2);
    }
    int y = y1;
    int eps = 0;
    int dx = x2 - x1;
    int dy = y2 - y1;
    int yi = 1;

    // 处理 [-1, 0] 范围内的斜率
    if (dy < 0) {
        yi = -1;
        dy = -dy;
    }

    for (int x = x1; x <= x2; x++) {
        if (steep) {
            image.set(y, x, color);
        }
        else {
            image.set(x, y, color);
        }

        eps += dy;
        // 这里用位运算 <<1 代替 *2
        if ((eps << 1) >= dx) {
            y = y + yi;
            eps -= dx;
        }
    }
}
```


# 二、 三角形光栅化和背面剔除
## 1 传统方法：扫线法
通过将三角形切割成上下两部分，从三角形的左侧线段绘制到右侧线段逐行扫描，适合单线程的CPU。
![[1672644086080.png]]
## 2 现代方法：包围盒扫描

也是逐行扫描，但是会更简单，而且更适合大规模并行计算，也就是对GPU更友好。
对于下图的三角形，我们找到三角形的最低点和最高点，最左点和最右点，画一个矩形包括住这个三角形，叫做 **Bounding box**（图中灰色矩形）。
![[1672644087020.png]]
计算方法：根据 ABC 顶点坐标得出 xy 坐标最大值最小值


算法的关键在于**判断一个坐标点是否在三角形内部**，方法有很多：

**1.  面积**
将 A,B,C 都与 P 连线，然后判断与 P 构成的三角形面积之和，是否等于三角形的面积。

**2.  内角和**
将 A,B,C 都与 P 连线，然后判断与 P 构成的三角形在 P 点的三个角之和是否为 360°。
![[1672644087049.png]]
**3.  叉乘**

按照顺序算出 $\vec{AB}\times\vec{AP},\vec{BC}\times\vec{BP},\vec{CA}\times\vec{CP}$，若所得三个向量同向，则在三角形内部。
![[1672644087111.png]]
若我们规定朝向屏幕里为负，则 $\vec{AB}\times\vec{AP}$方向为负，同理 $\vec{BC}\times\vec{BP}$和 $\vec{CA}\times\vec{CP}$的方向也为负，所以 P 在三角形内部。

因为向量的叉积实际表明了两个向量的位置关系，比如 $\vec{AB}\times\vec{AP}$ 为负，就说明了 $\vec{AP}$在 $\vec{AB}$的右侧，即 P 点在 $\vec{AB}$\右侧。同理，P 也在 $\vec{BC},\vec{CA}$右侧，即在三角形内部。

当 P 出现在三角形外部时，就不满足 P 在三个向量同一侧。

**4. 重心坐标线性插值**

**必须用三维空间的坐标进行插值，不能用投影后得到的二维坐标进行插值！**

通过判断是否有坐标的分量为负值知道是否在三角形的内部。若αβγ都大于0，则点在三角形内


![[Pasted image 20230517235501.png]]

**计算重心坐标的方法：**
1. 面积法：利用向量叉积求面积，通过面积计算
![[Pasted image 20230517235519.png]]


2. 公式法：用已经推出的公式计算
 ![[Pasted image 20230520101036.png]]


重心坐标也为着色器里面的其它计算提供了方便，可以通过获得ABC点的值来获取到三角形内任意坐标的位置、颜色、法线、深度等信息。
![[Pasted image 20230517235722.png]]

## 3 背面剔除

目的是裁剪掉背向我们的三角形，减少渲染的负担。

原理是通过三角形平面的**法线向量和视角负方向向量进行点乘，通过结果是否大于0判断看的这个三角形平面朝向着我们，如果不是就抛弃，不进入三角形的光栅化阶段。**
背面剔除的发生在顶点着色器之后，因为有可能在顶点着色器中对顶点的位置进行了修改。
## 4 obj文件格式
```c++
v -0.000581696 -0.734665 -0.623267
v 0.000283538 -1 0.286843
v -0.117277 -0.973564 0.306907
...
# 1258 vertices

vt  0.532 0.923 0.000
vt  0.535 0.917 0.000
vt  0.542 0.923 0.000
...
# 1339 texture vertices

vn  0.001 0.482 -0.876
vn  -0.001 0.661 0.751
vn  0.136 0.595 0.792
...
# 1258 vertex normals

g head
s 1
f 24/1/24 25/2/25 26/3/26
f 24/1/24 26/3/26 23/4/23
f 28/5/28 29/6/29 30/7/30
...
# 2492 faces
```
说明：

-   `v -0.000581696 -0.734665 -0.623267`
    v 即 vertex，表示这个顶点的 3D 坐标
    
-   `vt 0.897 0.370 0.000`
    vt 即 vertex texture，表示一个纹理坐标 uvt，一般 3D 模型只需要 2D 纹理，故第三个分量一般是 0
    
-   `vn 0.617 0.401 0.678`
    vn 即 vertex normal，表示一个顶点的法线，计算光照会用到
    
-   `f 106/83/106 107/84/107 108/85/108`
    f 即 face，后跟的三组数字代表多边形的顶点，这里给出的是三个顶点，故为三角形。每组数字依次表示顶点 v 编号/纹理坐标 vt 编号/法线 vn 编号，编号即 v、vt、vn 在 obj 文件中的出现顺序，从 1 开始计算
    
所谓**插值计算像素的 z 的某些属性**，可以这样理解：

> 假设像素 P 在三角形 ABC 内的重心坐标为 (a, b, 1-a-b)，则：
> 
> -   像素 P 的法线 P.normal = A.normal*a + B.normal*b + C.normal*(1-a-b)
> -   像素 P 的颜色 P.color = A.color*a + B.color*b + C.normal*(1-a-b)
> -   像素 P 的深度 P.z = A.z*a + B.z*b + C.z*(1-a-b)
> 
> 重心坐标的本质，就是描述三个顶点对三角形内每个 pixel 的“影响”。

# 三、 遮挡剔除Zbuffer
剔除前：![[Pasted image 20230106133217.png|300]]
原因：眼睛和嘴巴里都有一层内腔，，，模型渲染的时候把内腔给渲染上，覆盖掉了本来的嘴巴和眼睛。
![[1672644086861.png]]
剔除后：![[Pasted image 20230106133250.png|300]]

遮挡剔除是在三角形光栅化过程通过与深度缓冲区比较Z值，剔除掉在深度缓冲区后面的片元，降低渲染的负担。核心就是通过**Zbuffer**深度测试实现。
深度测试时判断，如果该像素z值大于Zbuffer中保存的z值，则更新z值并绘制该像素。（注意这里的z值是坐标z值，而不是深度，如果深度视角理解，那么就是当深度小于zbuffer中存储的深度值时，通过深度测试，后文会提到对z值和深度的理解：[[总结#通过深度计算#]]）

# 四、变换
推导：[[01 三维旋转]]

### 透视矫正插值
[图形学 - 关于透视矫正插值那些事 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/403259571)
[[透视矫正插值]]

## 特殊：法线变换
法线主要用于计算光照


### 利用模型的顶点法线计算
法向量的变换比较特殊，简单来说就是法向量左乘变换矩阵的逆转置矩阵，这样可以在非统一变换中保持法线和切线垂直。
unity中引擎帮我们将世界坐标的计算映射到屏幕上，所以是左乘了M的逆转置矩阵。在我们实现的软渲染器中，需要左乘MVP的逆转置矩阵。
**推导**：[[图形学奇点#法线]]
其中也提到了一个方法，**左乘逆转置矩阵=右乘逆矩阵**。

### 利用法线贴图计算
**法线映射NormalMapping**
法线映射与 Phong shading 的主要差别在哪呢？在于我们掌握信息的多少。在 Phong shading 时，用到三角形每个顶点的法线(插值获取其内像素的法线)，而法线映射纹理能提供相当多的法线(多到每个像素都有对应法线，而无需插值获取)，显著改善渲染细节。
教程中给了两个不同的法线贴图：
![[Pasted image 20230106162114.png|200]]![[Pasted image 20230106162128.png|200]]
左图是模型空间的法线贴图，右图是切线空间的法线贴图。使用右图时需要使用TBN矩阵将贴图中提取出的法线从切线空间变换到计算光照使用的空间。
两者区别与TBN矩阵相关可见：[[图形学奇点#法线贴图]]

### TBN怎么求
![[Pasted image 20230106224130.png]]

untiy 中我们可以直接拿到 tangent，进而与 normal 叉乘得到 bitangent，轻松构建出 TBN 矩阵。计算方法：[[04 法线、切线空间、TBN矩阵#在 unity shader 中如何得到 TBN 矩阵？]] 

软渲染器中拿不到，需要计算出来。

所以问题在于如何求T？答案就是：**根据纹理坐标和模型坐标求出TB！**
![[Pasted image 20230106224534.jpg]]

这张图描述了模型中每个三角形所在的纹理坐标系与模型坐标系的联系。
对于模型中每一个片元（三角形）的顶点，我们有其模型坐标以及纹理坐标，这个技术就要通过这两组坐标得到TBN矩阵。

如图对于每个三角形在模型空间中的两个边向量用E1和E2来表示：
![[Pasted image 20230106224606.png]]
使用矩阵来表示：
![[Pasted image 20230106224616.png]]
继而推导出：
![[Pasted image 20230106224625.png]]
以上就是在一个片元中，通过[顶点坐标](https://www.zhihu.com/search?q=%E9%A1%B6%E7%82%B9%E5%9D%90%E6%A0%87&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%2286442304%22%7D)与纹理坐标获得T,B向量的过程。
注意：这里解出的T或者B不是最终需要的，T向量需要进一步的与N向量正交化，所以我们只需要解出T，然后通过B = cross（N，T），这才是最终的B。有了T,B就可以计算得到N，从而构建出TBN矩阵。

# 六、Shader着色器
在渲染三角形面内的具体像素时，按法线、颜色的来源途径，可以分为三种方式：
**已知三角形内每个顶点的法线、坐标**
![[Pasted image 20230106214228.png]]
1.  **Flat shading**
    先平均各顶点的法向量，在计算每个像素的颜色时，共用这个平均法向量。这种方法在渲染圆滑物体时很不好用。
2.  **Gouraud shading**
    先计算各顶点的颜色，三角形内的像素颜色由插值各顶点得出。
3.  **Phong shading**
    在绘制每个像素时，先插值计算出当前像素的法向量，用这个法向量计算颜色。


**Gouraud与Phong着色器有何不同？**

**顶点着色器中逐顶点计算光照：高洛德着色（Gouraud shading)**
在每个顶点上计算光照，然后再渲染图元内部进行线性插值。
- 顶点数目小于像素数目，因此计算量小于phong着色
- 但是由于以来线性插值获得像素光照，当光照模型中有非线性的计算（例如计算高光反射）时，就会破坏原计算的非线性关系，我们会发现高光部分明显不平滑。
- 由于在渲染图元内部对顶点颜色进行插值，导致渲染图元内部的颜色总是暗于顶点颜色，会产生明显的棱角现象


**片元着色器中逐像素计算光照：Phong着色（Phong shading）**
又称**法线矢量插值着色**，以每个像素为基础得到法线（对顶点法线插值得到或从法线纹理中采样得到）

注意：着色模式不是光照模型，不要将phong着色和phong、blinnphong光照模型混为一谈。

# 七、阴影映射shadowmapping
![[Pasted image 20221209164343.png]]
通过shadowmapping只能做硬阴影，软阴影需要PCF、PCSS等算法。
## 通过z值计算
分两个Pass，通过调节lookat矩阵的参数设置不同的摄像机位置。

**Pass1** 
shadowbuffer：渲染摄像机在光源位置时的图像，z值存入shadowbuffer（执行深度测试，结果存入shadowbuffer），生成一张深度图，这张深度图又叫做shadowmap，这是光源视角下的深度图：
![[Pasted image 20230107131328.png|300]]
**Pass2**
framebuffer：渲染摄像机在观察位置时的图像，进行正常渲染，我们可以获得当前视角下的z值存入zbuffer，如果我们输出深度图可以看到如图：
![[Pasted image 20230107221314.png|300]]
还没结束，这是屏幕空间下的坐标，我们想把pass2渲染的z值和pass1渲染的z值进行比较，就需要转换到同一坐标系。

将NDC屏幕坐标从framebuffer屏幕空间转换到shadowbuffer屏幕空间，使用到的变换矩阵如下：
```c++
 mat<4, 4, float> M_Fbscreen2Sbscreen = M_sb_Model2Screen * (Viewport * M_MVP).invert(); // 将顶点屏幕坐标转换为shadowbuffer屏幕坐标(framebuffer屏幕空间->模型空间->shadowbuffer屏幕空间)
```

通过比较在shadowbuffer屏幕空间的z值与shadowbuffer存储的值确定颜色权重shadow，如果z值大于shadowbuffer，说明可以看到，shadow = 1，否则=0.3，作为颜色权重乘到最后的颜色中，这样就区分了明暗。

```c++
float shadow = 0.3 + 0.7 * (sb_p[2] > shadowbuffer[idx]); // 发生深度冲突（z-fighting）
```

最终渲染效果如下：可以看到，和pass1深度图对应的区域较亮。
![[Pasted image 20230107131345.png|300]]

**发现了问题：代码中的深度测试为什么是z大于zbuffer值的时候通过测试，不应该是小于吗？我们的相机是看向-z还是z？**
回答：因为我把z和深度搞混了。
![[A1494214C14D0ADF7F44C943248909DE 1.png|300]]
以右手坐标系为例，AB为两个物体。摄像机是朝向-z轴的，所以z越大说明距离摄像机越近（在深度图中体现就是越近越白），会通过深度测试。
注意这里我说的z值是坐标z值，坐标z值≠深度，深度是指距离摄像机的距离，坐标z值越大，深度越小。（本软光栅就是直接用坐标z来进行比较，zbuffer中存储的也不是深度，而是坐标z值）。
**有些时候（比如在opengl、unity中）我们将深度简称为Z，Z-buffer就是深那么此时Z不是坐标z值，在这种情况下，深度（Z）越大则距离摄像机越远（在深度图中体现为越近越黑）。进行深度测试时保留深度较小的。推荐以这种方式进行理解。**

再来一张图加深理解：
![[Pasted image 20221209145349.png]]
### 深度冲突
![[Pasted image 20230107223020.png|300]]
我们观察到发生了深度冲突（z-fighting，[[LearnOpenGL#深度冲突]]），这里采用一个暴力的解决方法：简单地将一个 z-buffer 相对另一个移动一点，就足以消除冲突。是的，这会导致其他一些问题 (什么问题？)
深度偏移过大会导致Peter Panning现象，[[4 高级扩展#1、问题1：自阴影/自遮挡]]

```c++
float shadow = 0.3 + 0.7 * (sb_p[2] + 43.34 > shadowbuffer[idx]); 
```

最终渲染效果如下：可以看到，和pass1深度图对应的区域较亮。
![[Pasted image 20230107131345.png|300]]

### 真正的mapping
我们最后只是将颜色乘了一个权重值，真正的mapping需要涉及纹理采样

unity中的屏幕空间阴影映射过程：
1.  渲染屏幕空间的深度贴图
2.  从光源方向渲染出shadowmap
3.  **在屏幕空间**做一次阴影收集计算（Shadows Collector，将前两步生成的图做深度比较），
		a.  **这次计算会得到一张屏幕空间的shadowmap（Collect Shadows）**
		b.  //实际上就是对前两步的深度图做一个比较，得到一张新的深度图
4.  在绘制物体时，用物体的**屏幕坐标uv**采样第三步中生成的屏幕空间shadowmap

我们只是实现了初级的shadowmapping，这里有更多[[4 高级扩展#4.3 实时阴影#]]



# 八、环境光遮蔽AO
使用传统的基于物理的关照算法(例如光线跟踪算法 )可以达到很好的效果但是技术计算复杂 ，难以实时，其计算复杂难以做到实时应用 。所以在游戏等实时应用中一般选用环境光遮蔽 (AO)技术模拟全局光照效果，在画面质量和渲染速度之间取得平衡 。

前面我们计算resultcolor的时候，环境光用了一个 常量20表示，物体各个部位受到的环境光都相同，这显然不适合。
## 暴力法求AO
### 球坐标系
球坐标 (r,θ,ϕ)表示一个点P在三维空间的位置
r：原点与点P之间的“径向距离”
θ：原点到点P的连线与正z轴之间的“极角”
φ：原点到点P的连线在xy平面的投影线与正x-轴之间的“方位角”
![[%FIT(LL@Z2YCMX~D9GO2Z$8.jpg]]
在单位球面（r=1）上**均匀选取随机点**，使用u和v上的（0，1）随机变量
θ = 2πu
φ = cos<sup>-1</sup>(2v - 1)

球坐标系(r,θ,φ)与直角坐标系(x,y,z)的转换关系: 
x=rsinθcosφ
y=rsinθsinφ
z=rcosθ


### 暴力法

根据【随机点选取算法】在生成【随机观察位置】，注意保持y大于0
![[Pasted image 20230108173145.png]]
```c++
// 单位球面选取随机点
Vec3f rand_point_on_unit_sphere() {
    float u = (float)rand() / (float)RAND_MAX;
    float v = (float)rand() / (float)RAND_MAX;
    float theta = 2.f * M_PI * u;
    float phi = acos(2.f * v - 1.f);
    return Vec3f(sin(theta) * cos(phi), sin(theta) * sin(phi), cos(phi));
}

ViewDir = rand_point_on_unit_sphere();
ViewDir.y = std::abs(ViewDir.y); //只要上半球
```

在观察位置渲染深度图，对通过深度测试的点进行着色（白色），保存到一张贴图（下文称作白点图）中。

![[Pasted image 20230108143408.png|300]]

循环n次，不断选取随机点，每次逐像素绘制白点图，将这些白点图累加起来存入AO贴图，最后将叠加的颜色除以循环次数，得到最终的AO贴图。

理解：环境光这笔描述了物体能够接收光的能力，难以接受光的地方自然会更暗一些（在贴图中也会更暗)，那么循环了这n次，有些uv位置会被重复着色，有些uv位置着色次数较少或没有着色，最后将叠加的颜色除以循环次数，将值限制到（0，1），并且体现出明暗关系：绘制次数多的点颜色更白，绘制次数少的点颜色更暗。

![[Pasted image 20230108143443.png|300]]
上图是循环1000次的结果循环次数越多精度越高，然后AO贴图就可以拿去用了。
单独输出这张AO:
![[Pasted image 20230108210537.png|300]]
值得注意的是，这种方法允许预计算场景中静态几何体的环境光遮蔽效果，并且速度不会收到循环次数限制，因为循环一遍后我们就已经生成了ao贴图，虽然精度不高但已经开始当作纹理使用了。

缺点：
- 循环次数少精度低，次数多消耗大
- 受美术资源影响：我们使用的模型胳膊为了节省资源使用了相同的纹理坐标，这意味着我们在光照计算中计算了两次胳膊，因此在最终渲染着结果中，亮度翻了四倍。
- 两次纹理坐标的计算是不准的，需要用一些小手段修复这种误差 (见本节课的摘要图片)。

优点：这种方法很灵活，而且能计算比均匀半球更复杂的光照。

## SSAO屏幕空间环境光遮蔽
这里就不实现了，源码给的方法并不好，学习一下百人计划讲的。

# 九、体素着色
将计算重心坐标的返回值修改会一个常量，例如vec3f(1,1,1)，那么一个三角形内的所有点重心坐标都是相同的，所以会插值计算出相同的颜色，造成体素形态的着色。
_![[Pasted image 20230108001712.png]]
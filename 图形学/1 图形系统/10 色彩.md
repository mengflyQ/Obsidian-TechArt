---
title: 10 色彩
aliases: []
tags: []
create_time: 2023-07-27 23:54
uid: 202307272354
banner: "[[Pasted image 20230727235440.png]]"
banner_y: 0.5
---

# 1 色彩知识

**只有扎实地掌握了颜色的基础理论和操作，才能更好地制作出真实且美观的 PBR 材质，进而更好地为产品服务。**

## 2.1 色彩理论

色彩就是颜色，本质是人眼能够感知的可见光。本节将重点介绍色彩相关的知识和理论。

### 2.1.1 成像原理

****光的本质是在可见光频段（波长在 380nm~780nm）的单一或复合电磁波。**

![](1679151991880.png)

虽然真实物理世界的光绝大多数是连续的复合光，但人眼能够感知的光波长分别是**红**（Red，波长为 700nm）、**绿**（Green，波长为 546.1nm）、**蓝**（Blue，波长为 438.8nm）的光，其它颜色皆由这三种原色光混合而成。

![](1679151991913.png)

上图的上部分是自然界存在的连续的自然光，下部分是离散的红、绿、蓝光，刚好跟人类视觉成像原理匹配，所以人类无法发现它们之间的差别。也就是说，人类的视觉是有损的，将无限维度的复合光简化成了三维视觉空间。

人眼见到的颜色不仅取决于光源的颜色，还取决于物体的表面特征，如颜色反射率、粗糙度、导电性、各向异性等等，最直观的是颜色反射率。

![](1679151992171.png)

一束白光（复合光）照在成熟的苹果表面上，由于苹果表面吸收了除红色以外的光，反射较多红色光，使得其表面呈现红色的特征。

**这些物体的表面特征就是 PBR 材质研究的范畴**，也是本文要重点研究和阐述的对象。后续章节将会重点介绍 PBR 抽象出的属性和特性。

最简单、最直接的光照公式如下：

$$人眼感知的物体颜色 = 光源颜色 * 物体表面颜色反射系数$$

但是以上公式只考虑了光源和物体表面反射系数，实际上，还需要考虑粗糙度、导电性、各向异性、透明度等等因素，可扩展一下，加入 $衰减因子$，以涵盖其它因素对物体表面反射系数的影响：

 

$$人眼感知的物体颜色 = 光源颜色 * (物体表面颜色反射系数 * 衰减因子)$$

其中 $衰减因子$ 的计算决定了以上公式是基于物理的还是基于经验值或是其它模式的，也决定了渲染效果的真实可信度。例如，Cook-Torrance 就是一种计算高光反射衰减因子的 PBR 光照模型：

$$人眼感知的物体高光颜色 = 光源颜色 * (物体表面颜色反射系数 * 衰减因子_{Cook-Torrance})$$

### 2.1.2 色彩模型和色彩空间

> [!summary] Title
> 主要用的是 RGB，sRGB，HSV

> [!NOTE] 
> 色彩模型（整体）：用什么来描述颜色，比如 RGB 三原色
> 色彩空间（细分）：色彩模型描述颜色的具体信息和含义

**色彩模型**是用一定规则来描述（排列）颜色的方法。常见的色彩模型有 RGB、HSV、HSL、LAB、CYMK 等。

然而，色彩模型无法确切地描述颜色的具体信息和含义，例如：RGB 模型用规定红、绿、蓝 3 个分量描述颜色，然而并没有确定红色、绿色、蓝色到底是什么波长亮度多少的光，更无法描述它们能够表达的范围。

这就需要引入**色彩空间**，以确切地描述色彩模型的具体信息和含义。比如，使用 **RGB 色彩模型**的 **sRGB 色彩空间**最大红色的定义就是 CIE XYZ: 0.4360657, 0.2224884, 0.013916。其中 CIE XYZ 是一个特殊的色彩空间，根据人眼三刺激值实验测试结果而建立。

**一个色彩模型下可以有多个不同的色彩空间**，它们根据排列的条件的不同会有不同的色域（所能表示色彩的范围）和含义，**色彩模型只有具体到一种色彩空间上才有实用性。例如，RGB 色彩模型下有 sRGB、Adobe RGB、ProPhoto RGB 等色彩空间。**

#### 2.1.2.1 CIE 1931 XYZ

**CIE 1931 XYZ 色彩空间**（也叫做 **CIE 1931 色彩空间**）是其中一个最先采用数学方式来定义的色彩空间，它由国际照明委员会（CIE）于 1931 年创立。

CIE XYZ 色彩空间是从 1920 年代后期 W. David Wright 和 John Guild 做的一系列实验中得出的。他们的实验结果合并到了 CIE RGB 色彩空间的规定中，CIE XYZ 色彩空间再从它得出。

这种色彩空间是基于 RGB 三原色测量而成，刚好覆盖所有人类可见的色彩范围（下图）。

![](1679151992326.png)

#### 2.1.2.2 LAB

**Lab 色彩空间**（**Lab color space**）是颜色 - 对立空间，带有维度 **L** 表示亮度，**a** 和 **b** 表示颜色对立维度，基于了非线性压缩的 CIE XYZ 色彩空间坐标。

不像 RGB 和 CMYK 色彩空间，Lab 颜色被设计来接近人类视觉。它致力于感知均匀性，它的 L 分量密切匹配人类亮度感知。因此可以被用来通过修改 a 和 b 分量的输出色阶来做精确的颜色平衡，或使用 L 分量来调整亮度对比。这些变换在 RGB 或 CMYK 中是困难或不可能的——它们建模于物理设备的输出，而不是人类的视觉感知。

对于不同的亮度值 L，所呈现的二维图将有较大差异：

![](1679151992403.png)

#### 2.1.2.3 RGB 和sRGB

RGB 色彩模型采用与人眼成像原理相似的 R、G、B 分量表达颜色，是一种在黑色介质上叠加色彩原色的模型。

![](1679151992455.png)

RGB 呈现的立体色彩三维图如下，是面向设备的一种色彩模型，当今的**绝大多数显示设备都采用 RGB 色彩模型**。

![](1679151992535.png)

RGB 色彩模型下拥有较多的色彩空间，常见的有 sRGB、AdobeRGB、ProPhotoRGB 等，它们能够表达的色域范围依次递增（下图）。

![](1679151992640.png)

**sRGB 色彩空间**是惠普与微软于 1996 年一起开发的用于显示器、打印机以及因特网的一种标准 RGB 色彩空间。这种标准得到了 W3C、Exif、英特尔、Pantone、Corel 以及其它许多业界厂商的支持。也是目前应用和支持得最广泛的一种色彩空间。

sRGB 使用的是 Gamma 校准系数为 **2.2** 的色彩空间，也是 CRT 显示器在这种情况下的平均线性电压响应。

sRGB 中定义的 R、G、B 及白色分别位于 CIE xy 颜色坐标系中的 `[0.6400, 0.3300]、[0.3000, 0.6000]、[0.1500, 0.0600]、[0.3127,0.3290]` 的 D65。（下图）

![](1679151992721.png)

**Adobe RGB 色彩空间**是一种由 Adobe Systems 于 1998 年开发的色彩空间。开发的目的是为了尽可能在 CMYK 彩色印刷中利用计算机显示器等设备的 RGB 颜色模式上囊括更多的颜色。Adobe RGB 色彩空间包括了约 50% 的 Lab 色彩空间中的可视色彩，主要在青绿色（cyan-green）色系上有所提升。

Adobe RGB 中定义的 R、G、B 及白色分别位于 CIE xy 颜色坐标系中的 [0.6400, 0.3300]、[0.2100, 0.7100]、[0.1500, 0.0600]、[0.3127,0.3290] 的 D65。（下图）

![](1679151992802.png)

#### 2.1.2.4 HSV

由于 RGB 是面向显示设备的色彩模型，对人眼来说，难以分辨各个分量合成的颜色。例如，50% 的红色分量和 80% 的绿色混合后的颜色，人类无法快速感知。

于是引入了 HSV 色彩模型，以便人类更加方便描述和感知色彩。

**HSV** 分别代表了 **H**ue（色相）、**S**aturation（饱和度）、**V**alue（明度），是一种面向人类的色彩模型。它的色彩三维图如下：

![|500](1679151992930.png)

**HSV 的值可由 RGB 三原色计算出来**，具体过程如下：

设 $(r, g, b)$分别是一个颜色的红、绿和蓝坐标，它们的值是在 $0.0$到 $1.0$之间的实数，设 $max$等价于 $r$, $g$和 $b$中的最大值，设 $min$等于这些值中的最小值。要找到在 HSV 空间中的 $(h, s, v)$值，这里的 $h$ ∈$[0, 360)$度是角度的色相角，而 $s, l ∈ [0.0,1.0]$是饱和度和明度，计算公式：

![](1679151993036.png)

![](1679151993116.png)

$$v = max$$

**同样地，HSV 坐标空间的颜色也可以转成 RGB 坐标空间**：

![](1679151993201.png)

HSV 也被称为 **HSB**，与之相类似的还有 **HSL**（色相、饱和度、亮度）。它们都是面向人类的色彩模型，区别仅仅是饱和度、亮度的定义略有不同（下图）。

![](1679151993251.png)

HSV 广泛地应用在 DDC 软件中的颜色选取、变色及其它颜色操作中，也是 UE 和 UE 材质编辑器中最常用的一种色彩模型。

![](1679151993299.png)

_UE 的颜色拾取器，上半部分是 HSV 图形选择界面，下半部分左侧是 RGB 色彩模型的值，半部分右侧是 HSV 色彩模型的值。_

#### 2.1.2.5 CMYK

**CMYK** 分别代表 **C**yan（青色）、**M**agenta（洋红、品红）、**Y**ellow（黄色）、Blac**k**（黑色），是一种在白色介质上吸收原色色彩的模型，常用于印刷。

![](1679151993409.png)

#### 2.1.2.6 YUV

**YUV** 是电视等数码领域常用的一种色彩空间，“Y” 表示**明亮度**（Luminance、Luma），“U”和 “V” 则是**色度**、**浓度**（Chrominance、Chroma）。Y'UV, YUV, YCbCr，YPbPr 等专有名词都可以称为 YUV。

以下是 YUV 色彩空间的 UV 分布图：

![](1679151993484.png)

Y′UV, YUV, YCbCr, YPbPr 所指涉的范围，常有混淆或重叠的情况。从历史的演变来说，其中 YUV 和 Y'UV 通常用来编码电视的模拟信号，而 YCbCr 则是用来描述数字的影像信号，适合影片与图片压缩以及传输，例如 MPEG、JPEG。但在现今，YUV 通常已经在计算机系统上广泛使用。

若将图片分解成 YUV 各分量，可得到以下的画面：

![](1679151993590.png)

_最上是正常的图片，下面三幅图分别是分解出来的 Y、U、V 分量图。_

除了以上色彩模型和色彩空间，实际上还有很多其它的色彩模型和空间，但与 PBR 关联较强的只有 RGB 和 HSV 色彩模型。故其它不在此讨论，有兴趣的可以查阅这篇文章：[深入理解 color model(颜色模型)](https://www.jianshu.com/p/f03e9ac9c9ef)。

### 2.1.3 色彩属性

#### 2.1.3.1 色环（色相Hue）

**色环**也叫**色轮**，其实就是 HSV 或 HSL 中的**色相Hue**分量，可由一个 2D 的圆形表示出来（下图）。

![|500](1679151993669.png)

其中 0 度是红色，60 度是黄色，120 度是绿色，180 度是青色，240 度是蓝色，300 度是品红。

在色环中，相距 60 度以内的色彩被称为**相邻色**，也被称为**类似色**；相距 100~179 度的色彩被称为**对比色**；相距 180 度的色彩被称为**互补色**。例如，对于红色，它的相邻色是黄色和品红，对比色是绿色和蓝色，互补色是青色。

在色环中，常见的 RGB 和 CYM 的相邻和互补色如下图：

![|500](1679151993735.png)

在色环中，还存在**冷暖色系**，代表着相同物体在不同温度下所发出的颜色，也代表着其它很多含义（活泼度、紧张度、情绪度、强烈度、夸张度、食欲度、成熟度等等）。其中，**暖色**代表物体温度较低时发出的颜色，以橙色为中心的半圆；**冷色**是物体温度较高时发出的颜色，以蓝色为中心的半圆：

![](1679151993977.png)

在良好的色彩搭配当中，色彩数量不宜过多，控制在 3 种以内；色彩之间搭配合理、得当，充分利用相邻色、互补色及冷暖调以达到画面的统一、和谐或增加对比度、冲击力。

![](1679151994057.png)

_上图大面积的冷色表明了山湖环境的宁静和寒冷，而小范围的暖色突出了屋子灯光的暖和，强烈的冷暖对比给人以高反差的视觉观感。_

当然实际应用中，不宜受条条框框的限制，应以主题为目标，充分发挥色环的作用。更多色彩搭配理论推荐阅读：[《色彩设计的原理》](https://item.jd.com/10851918.html)。

UE 材质编辑器提供了色相修改节点`HueShift`：

![](1679151994103.png)

#### 2.1.3.2 色阶（明度）

**色阶**反应了 HSV 色彩模型的分量 **V**：明度，表达了人眼能够感受到的色彩的亮度级别。

值得一提的是，人眼对 R、G、B 三原色的亮度感知程度是不一样的。**绿色提供最多的亮度贡献值**，红色、蓝色次之，可用以下公式表达：

$$颜色亮度 = R*0.3 + G*0.6 + B*0.1$$

仔细观察上述公式，可发现 R、G、B 的 3 个亮度贡献值相加刚好为 $0.3+0.6+0.1=1.0$，这也保证了能量守恒。

在摄影学中，通常将颜色的亮度划分为若干等分，每个等分跨度一致，一个等分成为**色阶**。

![](1679151994386.png)

其中亮度靠近黑色的色阶被称为**暗调**（low tone，也叫低调、阴影、黑色、黑场），亮度位于中间的色阶被成为**中调**（mid tone，也叫中间调、曝光），亮度靠近白色的被称为**亮调**（high tone，也叫高调、白色、高光、白场）。

至于色阶被划分的数量及命名并没有统一的规定。例如，Photoshop 的 Camera Raw 中，将色阶划分为：高光、亮调、暗调、阴影：

![](1679151994444.png)

而 Light Room 中，将色阶划分为：白色、高光、曝光、阴影、黑色。

![](1679151994519.png)

虽然划分和名称不一，但我们只需要记住：靠近黑色的是低调，中间部分是中调，靠近白色的是高调。

理解和掌握色阶色调，有助于操作 PBR 材质、后处理、色调映射、颜色操作等。例如，如果需要对 PBR 的漫反射贴图进行调整，而且需要对各个色阶进行精确控制，则可以用 UE 的材质节点`3PointLevels`：

![](1679151994593.png)

上图中的`Black Value`、`Middle Value`、`White Value`分别代表暗调、中调、亮调。

#### 2.1.3.3 色纯（饱和度）

**色纯**也叫**色彩饱和度**，表达了色纯的鲜艳程度。纯度越高，色彩越艳越浓，纯度越低则色彩变灰变淡。

![](1679151994624.png)

上图从左到右饱和度依次降低，可以看见，饱和度越高，色彩越浓越艳丽，饱和度越低，色彩趋向灰白色。

利用饱和度的这种特点，可以将画面分为高饱和、中饱和、低饱和画面，分别代表着不同的风格和意义。比如，高饱和画面充满激情、热烈，但不耐看，容易视觉疲劳；低饱和画面代表冷淡、平静，但也会给人一种压抑的感觉。

![](1679151994678.png)

相同的画面，由于左边饱和度低，给人以压抑和情绪感；而右边饱和度高，给人以清新明丽的感觉。

所以，充分利用色彩纯度，可以突出色彩的作用和画面的风格。

UE 材质编辑器也提供了相应节点，可方便地调整饱和度：

![](1679151994774.png)

#### 2.1.3.4 色温 (白平衡)

**色温**是可见光在摄影、录像、出版、图形渲染等领域具有重要应用的特征。光源的色温是通过对比它的色彩和理论的热黑体辐射体来确定的。在摄影学中，也被称为**白平衡**。

下面是黑体物质在温度慢慢升高的颜色变化图：

![](1679151995104.png)

但是，上图只是近似变化图，实际上，发光物体的色温跟很多因素有关，计算公式可由**普朗克辐射定律（Planck's Radiation Law）**描述：

$$U (λ, T) = \frac{8\pi hcλ^{-5}} { e^{\frac{hc}{λkT}}-1 }$$

公式中各符号代表的意义如下：

*   $U$ - 辐射能量
*   $λ$ - 电磁波波长，单位：米
*   $T$ - 温度，单位开尔文（Kelvin）
*   $h$ - 普朗克常量，值为 $6.626×10^{-34} J·s$
*   $k$ - 波尔兹曼常量，值为 $1.381×10^{-23} J·K^{-1}$
*   $c$ - 真空光速，值为 $3.0 × 10^8 m \cdot s^{-1}$

在生活中，常见发光物体对应的色温如下表：

<table><thead><tr><th style="text-align: right">色温</th><th>发光物体</th></tr></thead><tbody><tr><td style="text-align: right">1700 K</td><td>火柴光</td></tr><tr><td style="text-align: right">1850 K</td><td>蜡烛</td></tr><tr><td style="text-align: right">2800 K</td><td>钨灯（白炽灯）的常见色温</td></tr><tr><td style="text-align: right">3000 K</td><td>卤素灯及黄光日光灯的常见色温</td></tr><tr><td style="text-align: right">3350 K</td><td>演播室 “CP” 灯</td></tr><tr><td style="text-align: right">3400 K</td><td>演播室台灯,、照相泛光灯（不是闪光灯）等...</td></tr><tr><td style="text-align: right">4100 K</td><td>月光、浅黄光日光灯</td></tr><tr><td style="text-align: right">5000 K</td><td>日光</td></tr><tr><td style="text-align: right">5500 K</td><td>平均日光、电子闪光（因厂商而异）</td></tr><tr><td style="text-align: right">5770 K</td><td>有效太阳温度</td></tr><tr><td style="text-align: right">6420 K</td><td>氙弧灯</td></tr><tr><td style="text-align: right">6500 K</td><td>最常见的白光日光灯色温</td></tr><tr><td style="text-align: right">9300 K</td><td>电视屏幕（模拟）</td></tr></tbody></table>

5000K 和 6500K 的黑体的颜色分别接近于普通 D50 和 D65 的发光物，这通常用于颜色再现的场合（摄影、出版，等等）。在摄影中，5000K 又是最常作为太阳发出的白色光色温。

同一张画面，不同的色温将呈现出不同的效果：

![](1679151995151.png)

_左图是正常色温画面，右图是色温偏向暖调，给人以太阳强烈照射的暖色感。_

在 UE 中，灯光可通过属性面板开启色温调节，以模拟不同类型的发光源：

![](1679151995311.png)

#### **2.1.3.5 对比度**

**对比度（Contrast）** 是描述整副图像的明暗反差程度，反映的是色彩的明度（亮度）关系。

对比度越高，明暗反差越明显，暗部更加暗，亮部更加亮（下图）。

![](1679151995412.png)

_左图通过加强对比度之后，形成明暗反差更加强烈的右图。_

适当提高对比度可增加画面的冲击力，提升画面的通透度，但同时，要注意过犹不及，过高的对比度，会出现死黑和死白现象，导致画面诡异或不合理。

UE 材质编辑器也提供了对比度调整节点 `CheapContrast`：

![](1679151995699.png)

#### **2.1.3.6 清晰度**

**清晰度（Clarity）** 是反映画面的可识别度和可辨别度。清晰度越高的照片，能呈现的细节越多，反之，图片将变得越模糊。

![](1679151995788.png)

_左图是正常清晰度的照片，右图降低了清晰度，显而易见，图片变得非常模糊不清。_

同样地，UE 材质编辑器也有相应节点调整颜色清晰度：

![](1679151995836.png)

#### **2.1.3.7 锐利度**

**锐利度（Sharpness）** 跟清晰度比较类似，但也有区别。清晰度反映的是画面像素之间的反差程度，而锐利度反映的是画面轮廓或边缘的反差程度。更通俗地说，清晰度表述的是**所有**像素，而锐利度只表述**轮廓、边缘**或反差较大的**局部**像素。

![](1679151995936.png)

右图经过提升锐利度后，脸部、头发、衣服、草丛等的边缘和轮廓变得更加清晰了。

可能有人会疑惑：**色彩既然有了清晰度的属性为什么还需要锐利度？**

从摄影学上更好回答这个问题：对含有人物的画面，为了使画面更加美观，往往不需要在皮肤上增加清晰度，只需要在脸部和五官轮廓处增加，而锐利度恰好符合这一特点，使得摄影师或者设计师能够快速地得到美观而清晰的画面。

在 Photoshop 中，增加锐利度的方法有很多，常见的有：USM 锐化、边缘锐化、智能锐化、高反差保留等等。

![](1679151996017.png)

在 UE 材质编辑器中，也有材质节点增加锐利度：

![](1679151996138.png)

上图的`HighPass`就是 PS 里的高反差保留锐化。

对 UE 渲染的画面而言，在后处理节点执行锐化是非常有必要的。因为 UE 默认采用了延迟着色模式并且开启了 TAA（时间抗锯齿），而 TAA 算法的特性会导致画面变模糊，在最后阶段增加锐利度，可一定程度上抵消 TAA 带来的画面模糊，提升画面通透度和美观感。

### 2.1.4 直方图

**直方图**是反应一副图像中所有像素在各个亮度色阶的数量分布情况。

通常情况下，直方图左侧是暗调，中间是中调，右边是亮调。例如，下图左侧是一副正常后期过的图片，它对应的直方图在右上角。

![](1679151996328.png)

通过直方图，我们可以清晰地观察到，上述图片大量像素亮度集中在高调部分，属于一副高调风格的片子。此外，还可以通过调整色阶，实时查看图片的直方图以观察整副图片的亮度变化情况。

### **2.1.5 色调曲线**

**色调曲线**（Tone curve）是一种**将颜色值的输入值一一映射到输出值的曲线函数，可以精确地控制处于不同色阶的像素的亮度**。若将色调曲线设为 $f_{tone}$，则颜色调整公式为：

$$x' = f_{tone}(x)$$

其中 $x'$是调整后的颜色值，$x$是原始颜色值，可以是 RGB 的任一分量。

下列是一些特殊色调曲线的调整和对应的效果图。

![](1679151996488.png)

正常的画面和色调曲线，此时的色调曲线呈 45 度的直线。_

![](1679151996554.png)

加强明暗对比的画面和色调曲线，此时的色调曲线暗部处于直线下方，中间调位于直线上，亮部位于直线上方。

![](1679151996643.png)

自定义的色调曲线，曲线大范围偏离到直线下部，使得整体画面亮度变暗，对比度变小。

由此可见，色调曲线给予了非常精确、自由、灵活的色彩调整功能，在摄影学、数码硬件、DDC、图像处理、计算机图形学、计算机视觉乃至 PBR 制作中，都有着举足轻重的作用。





## **2.2 颜色操作**
### **2.2.1 基础操作**

本小节将分析颜色的基本操作加减乘除，由于加与减、乘与除本质上是一样的，所以只需分析加法和乘法。

#### **2.2.1.1 颜色相加**

颜色相加是最常用到的一种操作，通常用于若干个光源叠加，或者若干种颜色分量叠加。当然，PBR 制作也经常用到颜色相加，以调整颜色的结果。颜色相加操作本质上是对颜色执行线性曲线的平移，抽象成函数：

$$f (x) = x + c$$

其中 $c$ 就是相加操作数。

颜色相加操作的分析主要可分两种情况：一是操作数是灰白色；二是操作数是彩色。

如下图，是第一种情况，可以看到彩色 $(0.75, 0.5, 0.25)$ 加了灰白色 $(0.25, 0.25, 0.25)$，得到右边的新颜色 $(1.0, 0.75, 0.5)$。

![](1679151998198.png)

彩色操作数的 HSV 是 $(30,0.67,0.75)$，新颜色 HSV 是 $(30,0.51,1.0)$。由此可得出结论：**颜色与灰色相加，得到的新颜色色相不变，饱和度降低，亮度增加。**

现在看第二种情况，将灰色改成彩色：

![](1679151998282.png)

颜色操作数 1 的 HSV 是 $(30,0.67,0.75)$，颜色操作数 2 的 HSV 是 $(216,0.82,0.59)$，结果颜色的 HSV 是 $(300,0.07,0.84)$。由此可得出结论：**颜色与彩色相加，得到的新颜色色相会改变，饱和度也会改变，亮度会增加。**

实际上，加法还有其它一些特殊情况，诸如黑色、同色相颜色相加的情况，结果颜色的变化见下表：

<table><thead><tr><th>加法操作数</th><th>色相变化</th><th>饱和度变化</th><th>亮度变化</th><th>对比度变化</th></tr></thead><tbody><tr><td>灰色</td><td>不变</td><td>降低</td><td>增加</td><td>降低</td></tr><tr><td>彩色</td><td>改变</td><td>改变或不变</td><td>增加或不变</td><td>降低或不变</td></tr><tr><td>黑色</td><td>不变</td><td>不变</td><td>不变</td><td>不变</td></tr><tr><td>同色相彩色</td><td>不变</td><td>改变或不变</td><td>增加或不变</td><td>降低或不变</td></tr><tr><td>白色</td><td>变成 0</td><td>变成 0</td><td>大于等于 1</td><td>变成 0</td></tr></tbody></table>

上表针对的是加法操作，减法的结果与加法有着规律的对比，降低的变增加，增加的变降低，不变的依然保持不变。

#### **2.2.1.2 颜色相乘**

颜色相乘也是最常用、最基本的操作，代表着颜色随着某种系数衰减或者增强。颜色相乘操作本质上是对颜色执行线性曲线的缩放，抽象成函数：

$$f(x) = c \cdot x$$

其中 $c$ 就是乘法操作数。

颜色相乘操作也可分为灰色和彩色因子两大类，其中灰色因子分为因子大于 1 或不大于 1 两种情况。先分析灰色因子，如下图：

![](1679151998349.png)

  

![](1679151998403.png)

上图是小于 1 的因子，新颜色的色相和饱和度不变，亮度降低；下图是大于 1 的因子，新颜色的色相和饱和度不变，亮度增加。

![](1679151998466.png)

上图中，两个彩色相乘，得到的结果色相、饱和度、亮度都发生了改变。

结合一些特殊的情况，可得到如下表：

<table><thead><tr><th>乘法操作数</th><th>色相变化</th><th>饱和度变化</th><th>亮度变化</th><th>对比度变化</th></tr></thead><tbody><tr><td>灰色（大于 1）</td><td>不变</td><td>不变</td><td>增加</td><td>增加</td></tr><tr><td>灰色（小于 1）</td><td>不变</td><td>不变</td><td>降低</td><td>降低</td></tr><tr><td>白色</td><td>不变</td><td>不变</td><td>不变</td><td>不变</td></tr><tr><td>黑色</td><td>变成 0</td><td>变成 0</td><td>变成 0</td><td>变成 0</td></tr><tr><td>彩色</td><td>改变</td><td>改变</td><td>改变</td><td>改变</td></tr></tbody></table>

除法与乘法有着类似的规律，只是灰色（大于 1）和灰色（小于 1）反过来，并且与黑色相除的结果无定义。

### **2.2.2 颜色插值**

**颜色插值**是通过一组插值系数在多个操作数中取不同权重的值的操作，在 PBR 制作、后处理、数码后期等领域使用得非常多，常见的插值方式有线性、S 形、三角插值等等。

#### **2.2.2.1 线性插值**

线性插值需要两个操作数 $a$, $b$ 和一个插值系数 $x$，则它们的插值公式是：

$$f(x) = a + (b - a) * x$$

其中 $x$ 的值域是 $[0, 1]$，以上公式对应的曲线图如下：

![](1679151998522.png)

UE 材质编辑器也提供了线性插值节点：

![](1679151998591.png)

#### **2.2.2.2 S 插值**

线性插值在操作数附近过渡比较生硬，不够自然，而 S 形插值则可以解决这个问题。S 形插值可用很多方式模拟，如 $\sin$、色调映射、贝塞尔曲线等。

其中，用 $\sin$ 模拟的 S 形插值的公式是：

$$f(x) = \sin(x\cdot \pi-\frac{\pi}{2})\cdot 0.5 + 0.5$$

模拟出的曲线如下图：

![](1679151998642.png)

从上图可以看出，在曲线两端，斜率由水平逐渐过渡，从而达到平滑插值的目的。

UE 默认不提供上述曲线的插值材质节点，需要手动实现，笔者实现的材质函数 `SineLerp` 如下图：

![](1679151998728.png)

由于 UE 的内置 `Sine` 材质节点在内部乘了 $\pi$ 且做了偏移，所以实现起来跟上面提到的公式略有不同，会更加简便，但也会给不熟悉 UE 材质编辑器的人带来困惑。

#### **2.2.2.3 其它插值**

其它插值诸如法线融合、三角插值、方格插值、高度图插值，对应不同的应用场景，在 PBR 材质中较少用到，有兴趣的同学自行查阅相关资料或到 UE 材质编辑器摸索。

![](1679151998761.png)

_UE 材质编辑器提供的各式插值方式。_

### **2.2.3 颜色混合**

**颜色混合**是指将一种颜色与目标颜色通过某种方式相融合的操作，这些操作被称为**混合模式（Blend Mode）**。

不同的混合模式将得到不同的混合结果，通常涉及两个颜色：**混合颜色**（Blend Color，记作 $a$）和**底色**（Base Color，记作 $b$），部分混合模式还涉及混合系数 $alpha$。

它也是 Photoshop 的图层混合模式，同时 UE 也提供了相应的混合材质节点。混合模式很多，可分为普通、变暗、变亮、饱和度、差集、颜色等几大类。（下图）

![](1679151998818.png)

_Photoshop 的图层混合模式，相信美术、TA、摄影、设计等领域的同学都不陌生。_

*   **正常 (Normal)**

正常混合模式是最普通、最常用的一种混合模式，其实就是在两个图层中进行线性插值。它的公式如下：

$$f(a, b, alpha) = a \cdot alpha + b \cdot (1 - alpha)$$

用 UE 实现的效果如下图：

![](1679151998875.png)

*   **正片叠底 (Multiply)**

正片叠底就是将混合颜色和底色相乘，通常会得到更低亮度和饱和度的颜色。公式如下：

$$f(a, b) = a \cdot b$$

用 UE 实现的效果如下图：

![](1679151998946.png)

*   **颜色加深 (Color Burn)**

在此混合模式中，若混合颜色 $a$ 越暗，则在最终结果中使用该颜色越多。如果颜色 $a$ 为白色，则不进行任何更改。它的公式：

$$f(a,b) = 1- \frac{1-b}{a}$$

UE 的材质节点 `Blend_ColorBurn` 实现了这种混合模式：

![](1679151998998.png)

*   **线性加深 (Linear Burn)**

将底色颜色与混合颜色相加，然后从结果中减去 1。它的公式：

$$f(a,b) = a + b - 1$$

UE 的材质节点 `Blend_LinearBurn` 的内部实现及效果：

![](1679151999040.png)

*   **颜色减淡 (Color Dodge)**

通过将底色颜色反转并将其除以混合颜色，使结果变亮。混合公式：

$$f(a,b) = \frac{b}{1-a}$$

UE 的材质节点 `Blend_ColorDodge` 可实现这种混合模式：

![](1679151999089.png)

*   **线性减淡 (Linear Dodge)**

将 “底色”（Base）颜色与 “混合”（Blend）颜色相加。混合公式：

$$f(a,b) = a + b$$

UE 的材质节点 `Blend_LinearDodge` 可实现这种混合模式：

![](1679151999155.png)

*   **线性光 (Linear Light)**

线性光是 Overlay（覆盖）的线性版本，用于提供更粗糙的结果。此函数对混合颜色执行比较，从而每当混合比 50% 灰度亮时，就通过筛滤（Screen）操作对底色和混合颜色进行组合。如果混合颜色比 50% 灰度暗，那么将像 “乘” 功能一样，将底色与混合相乘。公式如下：

$$f(a,b)={ \begin{cases} ab, &{\mbox{if }}a<0.5 \\2a+b-1,&{\mbox{else}} \end{cases} }$$

UE 的材质节点 `Blend_LinearLight` 的混合效果：

![](1679151999185.png)

*   **变暗 (Darken)**

针对底色和混合颜色的每个像素，选择较暗的值。如果混合颜色为白色，则不会产生变化。公式：

$$f(a,b) = \min(a, b)$$

UE 材质编辑器的 `Blend_Darken` 实现及效果：

![](1679151999217.png)

*   **变亮 (Lighten)**

对底色和混合颜色的每个像素进行比较，并返回较亮的结果。公式：

$$f(a,b) = \max(a, b)$$

UE 材质编辑器的 `Blend_Lighten` 实现及效果：

![](1679151999309.png)

*   **差异 (Difference)**

通过从混合中减去底色，然后取结果的绝对值，创建反转样式的效果。公式：

$$f(a,b) = | a - b|$$

UE 材质编辑器的 `Blend_Difference` 实现及效果：

![](1679151999353.png)

*   **排除 (Exclusion)**

将底色和混合纹理二等分，对其进行组合，然后对结果执行部分反转。公式：

$$f(a,b) = 0.5 - 2(a - 0.5)(b - 0.5)$$

UE 材质编辑器的 `Blend_Exclusion` 实现及效果：

![](1679151999431.png)

*   **强光 (Hard Light)**

强光与覆盖（Overlay）的粗糙版本相似，它会对底色和混合进行筛滤或相乘。此函数对混合颜色执行比较，从而每当混合比 50% 灰度亮时，就通过筛滤（Screen）操作对底色和混合进行组合。如果混合比 50% 灰度暗，那么将像 “乘” 功能一样，将底色与混合相乘。然后，提高最终结果的对比度，以产生粗糙输出。公式如下：

$$f(a,b)={\begin{cases}2ab, &{\mbox{if }}a<0.5 \\1 - (1-2(a-0.5))(1-b),&{\mbox{else}}\end{cases}}$$

UE 材质编辑器的 `Blend_HardLight` 实现的效果：

![](1679151999492.png)

*   **覆盖 (Overlay)**

**覆盖**在 PS 被称为**叠加**，对底色和混合进行筛滤或相乘。此函数对混合颜色执行比较，从而每当混合比 50% 灰度亮时，就通过筛滤（Screen）操作对底色和混合进行组合。如果混合比 50% 灰度暗，那么将像 “乘” 功能一样，将底色与混合相乘。公式：

$$f(a,b)={ \begin{cases} 2ab, &{\mbox{if }}a<0.5 \\1-2(1-a)(1-b),&{\mbox{else}} \end{cases} }$$

UE 的材质节点 `Blend_Overlay` 的混合效果：

![](1679151999547.png)

*   **点光 (Pin Light)**

点光与 Overlay（覆盖）相似，它使底色和混合一起变亮或变暗。此函数对混合颜色执行比较，从而每当混合比 50% 灰度亮时，就通过筛滤操作对底色和混合进行组合。如果混合比 50% 灰度暗，那么将像 “乘” 功能一样，将底色与混合相乘。对比度会软化，这使此函数成为 Overlay（覆盖）的不太粗糙版本。公式：

$$f(a,b)={ \begin{cases} \min(2a,b), &{\mbox{if }}a<0.5 \\ \max(2(a-0.5),b),&{\mbox{else}} \end{cases} }$$

UE 的材质节点 `Blend_PinLight` 的混合效果：

![](1679151999594.png)

*   **筛滤 (Screen)**

**筛滤** (Screen) 在 PS 里叫**滤色**，按混合颜色使底色变亮。其工作方式如下：对这两种颜色都执行 “一减”，将它们相乘，然后对结果执行 “一减”。公式：

$$f(a,b) = 1 - (1 - a)(1 - b)$$

UE 材质编辑器的 `Blend_Screen` 实现及效果：

![](1679151999628.png)

*   **柔光 (Soft Light)**

**柔光**是 Overlay（覆盖）的柔和版本。此函数对混合颜色执行比较，从而每当混合比 50% 灰度亮时，就通过筛滤操作对底色和混合进行组合。如果混合比 50% 灰度暗，那么将像 “乘” 功能一样，将底色与混合相乘。对比度会软化，这使此函数成为 Overlay（覆盖）的不太粗糙版本。公式：

$$f(a,b)={ \begin{cases} (a+0.5)\cdot b, &{\mbox{if }}a<0.5 \\ 1 - (1-(a-0.5))(1-b),&{\mbox{else}} \end{cases} }$$

它也是 Photoshop 后期处理中用得比较多的一种混合模式，可以加大画面对比度，提升通透感。UE 的材质节点 `Blend_SoftLight` 的混合效果：

![](1679151999678.png)

## **2.3 常用曲线**

从上两节可以看到，颜色的原理、理论和操作大量运用了曲线函数，这节将 PBR 制作中常用的曲线总结出来并加以分析。

### **2.3.1 线性曲线**

线性曲线在颜色插值、色调映射、后处理、混合等操作中经常用到，抽象的公式如下：

$$f(x) = ax + b$$

其中 $x$ 是变量，$a$ 和 $b$ 是实数。当 $a=0.6,b=-0.1$ 时的曲线如下所示：

![|350](1679151999727.png)

### **2.3.2 指数曲线**

指数曲线是指变量 $x$ 的指数 $n$ 大于 1，可由若干个多项式抽象出来：

$$f(x) = \sum_{i=1}^{n}a_ix^i + b$$

其中 $a_i$ 是每个项的实数。当然，我们实际应用中，极少用到多项式，一般只需一项，即取 $a_n=1,a_i=0(i<n),b=0$，如此便可简化成：

$$f(x) = x^n$$

进一步地，取 $n=2$ 可得到曲线 $f(x)=x^2$，对应的曲线图：

![|400](1679151999778.png)

由上图可知：在指数级曲线中，当底数小于 1 时，数值比原来的值要小。

常用的还有不同指数的曲线：

![|450](1679151999811.png)

细心的童鞋应该发现了，当 $n=2.2$ 和 $n=0.45$ 时，就是前面提到的 Gamma 校正曲线。

### **2.3.3 三角函数**

三角函数有正弦、余弦、切线、余切等等，但 PBR 制作中常用的是正弦和余弦，而正弦和余弦本质是一样的，只是偏移不同，故下面只列出正弦公式：

$$f(x) = a\cdot\sin(x\cdot t + \theta) + b$$

其中 $a$ 是振幅，$t$ 是周期缩放因子，$\theta$ 是相位偏移，$b$ 是振幅偏移。当 $a=1,t=1,\theta = 0, b = 0$ 就是 $f(x)=\sin(x)$，对应曲线如下：

![|450](1679151999844.png)

当 $a=0.5,t=\pi,\theta = -\frac{\pi}{2}, b = 0.5$ 就可获得 S 形插值曲线：

$$f(x) = 0.5 \cdot \sin(x\cdot \pi-\frac{\pi}{2}) + 0.5$$

### **2.3.4 贝塞尔曲线**

贝塞尔曲线是一种由若干控制点控制的平滑曲线。假设控制点数量是 $n$，则控制点可表示为 $P_0, P_1,...,P_{n-1}(n\ge2)$。

当控制点数量是 2 时，贝塞尔曲线公式如下：

$$\boldsymbol B(t) = P_0 \cdot t + P_1 \cdot (1-t), t\in[0,1]$$

实际上就是线性插值和正常混合公式。

当控制点数量是 3 时，贝塞尔曲线公式和曲线图如下：

$$\boldsymbol B(t) = P_0 \cdot (1-t)^2 + P_1 \cdot 2t(1-t) + P_2\cdot t^2, t\in[0,1]$$

![|329](1679151999894.png)

当控制点数量是 4 时，公式将更加复杂：

$$\boldsymbol B(t) = P_0 \cdot (1-t)^3 + P_1 \cdot 3t(1-t)^2 + P_2\cdot 3(1-t)t^2 + P_3 \cdot t^3, t\in[0,1]$$

对应的示例图如下：

![|366](1679151999933.png)

### **2.3.5 Catmull–Rom 曲线**

贝塞尔曲线的特点是模拟出来的曲线不经过控制点，而 Catmull–Rom 曲线恰恰补足了这个特性，模拟出来的曲线具体平滑且经过控制点的特性。（下图）

![|450](1679151999974.png)

曲线公式和计算可以参见 [Centripetal Catmull–Rom spline](https://en.wikipedia.org/wiki/Centripetal_Catmull%E2%80%93Rom_spline)。

它正因为有这种优点，所以被广泛应用于动画插值、颜色混合、曲线调整当中，例如 Photoshop、LightRoom、UE 中的曲线调整：

![](1679152000058.png)

_在 Lightroom 利用色调曲线的若干控制点精确调整图片色调，此处的控制点就采用了 Catmull–Rom 曲线。_

### **2.3.6 其它曲线**

实际上，还有很多很多曲线，但限于篇幅，只介绍以上常用的几类曲线，其它曲线可以参看以下链接：

*   [List of Famous Curves](https://www.matematica.pt/en/useful/list-curves.php)
*   [缓动函数速查表](https://easings.net/)

其中[缓动函数速查表](https://easings.net/)列举了大量实用的曲线，并且附带了动态图，可以直观地看到曲线平滑度和坡度：

![](1679152000102.png)




# 2 伽马矫正
## Gamma 校正
`Gamma` 是指对线性三色值和非线性视频信号之间进行编码和解码的操作。
### 颜色空间
![[Pasted image 20221030155028.png]]

图中可以看到，sRGB 和 Rec. 709 的色域是差不多的，三原色的位置是相同的，那么它们之间的区别就是：**传递函数**不同

### 传递函数
-   什么是传递函数：

-   知道了颜色的颜色值之后，想要在电子设备上显示，就需要把它转换为视频信号，传递函数就是用来做转换的。

-   一个传递函数包括两部分：
    -   **光转电传递函数（OETF）**，把场景**线性光**转到**非线性**视频信号值。
    -   **电转光传递函数（EOTF）**，把**非线性**视频信号值转到**显示**光亮度 
    -   **一个简单理解**：拍照时，将照片存储在内存卡中，就是用视频信号存储的，如果要看这个照片，就把视频信号再转换成光信号。
![[Pasted image 20221030155110.png]]
**传递函数其实就是 Gamma 校正所使用的函数。**

### 简单定义
**线性空间**（Linear Space）是 RGB 颜色都处于函数曲线的对角直线状态（下图），处于线性空间的颜色值是线性变化的，而不会有任何非线性改变，用公式来表达是：$x'=f (x) = x$。
![[1679151996755.png]]

与线性空间相对立的是 **Gamma 空间**，它是有着指数级的函数曲线的变换空间，Gamma 曲线计算公式：
$$x'= f(x) = x^n$$
其中，$x$ 是颜色 $r,g,b$ 任一分量的值，值域是 $[0.0, 1.0]$，$n$ 是 Gamma 校正指数。下图中，分别是 $n$ 取 $0.45$, $1.0$, $2.2$ 的 Gamma 空间色调曲线图。
![[1679151996861.png|400]]

1.0 是线性空间，输入输出值一样；0.45 和 2.2 是 Gamma 曲线，处于此空间的色彩将被提亮或压暗，并且 $0.45 \cdot 2.2 \approx 1.0$，以保证两次 Gamma 校正之后能够恢复到线性空间：

$$x' = f_{gamma2.2}(f_{gamma0.45}(x)) = ({x^{0.45}})^{2.2} = x^{0.45 \cdot 2.2} = x^{0.99} \approx x$$

![](1679151997142.png)
>从左到右：指数 0.45 的 Gamma 校正图像，1.0 的线性空间的原始图像，指数 2.2 的 Gamma 校正图像。

**上图左执行 2.2 的 Gamma 校正后将得到中间图像；同样，上图右执行 0.45 的 Gamma 校正后也可以得到中间图像。**

### 编码和解码的理解

-   拍到的照片，存在电脑里，就是把自然界中的光信号编码为视频信号 (我们常用的格式如 srgb 都是0.45)
-   查看照片时，就要把视频信号还原为线性的光信号，进行解码操作 (2.2)，显示器进行 Gamma 校正。

**用一张图来举例：**
 ![[Pasted image 20221030155903.png]]
**gamma 编码：**
-   左图为存在硬盘中，**将捕获到的物理数据做一次 gamma 值约为 0.45 的映射**，这个过程称为 **gamma 编码**，图片变亮
![[Pasted image 20221030171028.png]]

**gamma 校正：**
-   中间为显示图像时，需要为每一个像素做一次 gamma 值约为 2.2 的校正，来使的最终结果为正确的物理数据。图片变灰


**为什么不用线性的方式存储，而要来回转换呢？**
-   ①和人眼的特性有关
-   人眼对暗部的变化感应更敏感

-   ②非线性转换为了优化存储空间和带宽
-   我们用于显示图像数据都是 8bit，**为了充分利用带宽，就需要使用更多位置去存储暗部值**。也就是暗部使用高精度保存，亮部使用相对较低精度保存。

## 韦伯定律与 CRT
### 美术上的均匀和物理上的均匀
![[Pasted image 20221030160526.png]]
美术上的中灰色 and 物理上的中灰色
**那一个变化更均匀？**
- 正如上边所说，我们人眼对于暗部是更敏感的，视觉上人们会认为上面这条线亮度是均匀增加的，实际在物理上下面这条线亮度均匀增加。
-   上边是视觉上的均匀变化，而下边是物理量上的均匀变化。
-   补充：理论上上边的中灰是物理量（下边）的 21.8%，视觉上认为的美术中灰色，大约是物理中灰色的 20%
### Gamma 编码曲线
![[Pasted image 20221030160838.png]]
-   **gamma 编码的曲线：**
将自然界线性增长的灰阶变化和人心理上感受到的灰阶变化做一个映射，得到 Gamma 编码的曲线。

-   由图中可以看到
-   自然界中亮度的 0.2 左右的亮度，对应的就是人眼感受到的中灰色（0.5）
-   将 0.2 以下看作暗部，0.2 以上看作亮部，可以看到暗部的变化率更高，也就是说人眼对暗部的变化感受更敏感。

### 韦伯定律（用 gamma 校正的一个原因）
![[Pasted image 20221030160904.png]]
- 简单来说就是：
- 当所受刺激越大时，需要增加的刺激也要足够大才会让人感觉到明显的变化，但是只适用于中等强度的刺激。

### CRT 非线性响应（用 gamma 校正的另外一个原因）
![[Pasted image 20221030161656.png]]
#### CRT 与转换函数
-   **CRT（阴极射线显像管）**
![[Pasted image 20221030161813.png]]
在物理世界中，如果光的强度增加一倍，那么亮度也会增加一倍，这是线性关系。
早期 CRT（阴极射线显像管）设备的亮度和电压不成线性关系，而是呈亮度增加量等于电压增加量的 2.2 次幂的非线性关系
![[Pasted image 20221030170827.png]]
2.2 也叫做该显示器的**Gamma**值，**现代显示器的 Gamma 值也都大约是 2.2**。


-   由于 CRT 的这个物理特性，刚好可以把亮度压暗，也就说，左图变亮的情况下，经过右图显示器的压低亮度校正，结果刚好可以显示正常（有趣的巧合）。

- CRT 设备的显示原理：
- 通过一个电子束去攻击屏幕上的凝光质图层，发射电子束的电子枪的电压和屏幕上产生的光强成非线性关系。
![[Pasted image 20221030162052.png]]
>左图（提亮）：gamma 编码的曲线：人眼对于物理光强度的一个响应曲线
>右图（压暗）：crt 电压与屏幕亮度关系的曲线


#### 中灰值
-   **所谓的中灰值，并非某个固定的具体数值，而是取决于视觉感受**

 一个例子可以证明：
-   对于第一张图，可以很明显看到 AB 颜色不同![[Pasted image 20221030162541.png|500]]
对于下面这张图，只是把 AB 连起来，就可以看到，其实是一种颜色  
![[Pasted image 20221030162554.png|500]]

## 线性工作流
### 线性空间与 Gamma 空间
线性空间：相机捕捉到的真实世界光信号
Gamma 空间：对线性空间颜色值编码，把场景线性光转到非线性视频信号值。

**线性空间对于计算机图形学中，有着至关重要的作用，它能够保证在 GPU 的 shader 中经过多次复杂的计算后，依然能够得到正确的颜色值**；反之，如果是在 Gamma 空间执行 shader 计算，将得到误差很大的画面效果。

正因为线性空间能够得到更加准确的渲染结果，所以主流商业引擎（UE、Unity、CryEngine、Frostbite 等）都支持了线性空间渲染管线。

![](1679151997244.png)
>线性空间渲染管线（下半部分）在 shader 前期去除了 Gamma 校正，在 shader 后期恢复 Gamma 校正。


对于技术美术来说，知道上边所说的还不够，因为很多时候我们会接触到一些图形效果的制作和修改。
这时候就需要一个**正确的工作流程**。所谓 **线性工作流**，就是在各个环节正确的使用 gamma 编码/解码，来达到最终输出的数据和最初输入的物理数据一致的目的。
![[Pasted image 20221030162743.png|500]]

如果**使用 Gamma 空间的贴图，在传给着色器之前需要从 Gamma 空间转到线性空间**。

目的是**在着色器中做一些渲染计算时会使用线性空间的颜色值**，这样就不会出现一些显示错误的结果。

**如果不在线性空间下进行渲染工作，可能会产生的问题：**
-   **①亮度叠加时**
前文提到，图像存储在硬盘中，**会将捕获到的物理数据做一次 gamma 值约为 0.45 的映射**，这个过程称为 gamma 编码。
线性空间下，原本四个亮度为 0.098 的值，进行叠加后应该是 0.196。结果由于在 Gamma 空间下，他们都是 0.098<sup>0.45</sup>，也就是四个 0.35 叠加，叠加后为 1.4，亮度>1，产生**过曝**现象。 
-   可以看到非线性空间下亮度叠加出现了过曝（亮度>1 的）的情况
-   **因为 Gamma 空间经过 gamma 编码后的亮度值相对之前会变大**。
![[Pasted image 20221030163030.png]]

- **②颜色混合时**
-   如果在混合前没有非线性的颜色进行转换，就会在纯色的边界出现一些黑边。
![[Pasted image 20221030163044.png]]

  ③**光照计算时**
-    在光照渲染结算时，如果我们把非线性空间下（视觉上的）的中灰色 0.5 当做实际物理光强为 0.5 来计算时，就会出现左边这种情况
-   在显示空间下是 0.5，但在渲染空间下它的实际物理光强为 0.18（如右图）
![[Pasted image 20221030163101.png]]

### Unity 中的颜色空间
#### 在 Unity 中选择颜色空间
-   点击菜单 -> Project Settings -> Player 页签 -> Other Settings 下的 Rendering 部分，通过修改 Color Space 可以来选择 Gamma/Linear（线性）
- ![[Pasted image 20221030164250.png]]
-   当选择 Gamma Space 时
-   Unity 不会做任何操作（默认 Gamma）

-   **当选择 Linear Space 时
-   **引擎的渲染流程在线性空间计算**，理想情况下项目使用线性空间的贴图颜色，不需要勾选 sRGB；
-   如果勾选了 sRGB 的贴图，Unity 会通过硬件特性采样时进行线性转换。


 **Unity 主要通过以下两个硬件特性来支持**
-   **sRGB Frame Buffer**
	-   将 Shader 的计算结果输出到显示器前做 Gamma 校正
	-   作为纹理被读取时会自动把存储的颜色从 sRBG 空间转换到线性空间
	-   调用 ReadPixels（）、ReadBackImage（）时，会直接返回 sRGB 空间下的颜色
	-   sRBG Frame Buffer 只支持每通道为 8bit 的格式，不支持 float 浮点格式
	-   HDR 开启后会先把渲染结果会知道浮点格式的 FB 中，最后绘制到 sRGB FB 上输出。

-   **sRGB Sampler**
	-   将 sRBG 的贴图进行线性采样的转换
	-   使用硬件特性完成 sRGB 贴图的线性采样和 shader 计算结果的 gamma 校正，比在 shader 里对贴图采样和计算结果的校正要快。
### 资源导出问题/注意事项
#### SubstancePainter
![[Pasted image 20221030164600.png]]
-   SubstancePainter 的贴图导出时，其线性的颜色值经过了 gamma 编码，所以颜色被提亮了。
-   此时这个贴图需要在 Unity 中勾选 sRBG 选项（让 unity 知道这个贴图在 gammar 空间），来让它被采样时能还原回线性值。
#### PS
![[Pasted image 20221030164711.png]]
-   如果使用线性空间，一般来说 PS 可以什么都不改，导出的帖图只要勾上 sRGB 就可以了。
- 如果调整 PS 的伽马值为 1，导出的贴图在 Unity 中也不需要勾选 sRGB 了。
![[Pasted image 20221030164917.png]]
#### 半透明效果
-   **Unity 中**：
-   Unity 进行半透明混合时，会先将它们转换到一个线性空间下然后再混合

-   **PS 中**：
-   PS 的图层和图层之间做混合时，每个上层的图层都会读取他们的 Color Profile（gamma 值），然后经过一个 gamma 变换再做混合，这样做得结果就会偏暗一些。
-   （可以在它的工作空间的设置中进行更改，选择用灰度系数混合 RGB 颜色，参数设置为一，这样图层才是一个最终直接混合的结果）
![[Pasted image 20221030165103.png]]

## ⭐【先看】知乎总结
[Gamma、Linear、sRGB 和Unity Color Space，你真懂了吗？](https://zhuanlan.zhihu.com/p/66558476)
本文将会简单介绍 Gamma、Linear、sRGB 和伽马校正的概念。接着通过实例解析统一到线性空间的步骤，最后介绍如何在 Unity 中实施相应的工作流。
### 什么是 Linear、Gamma、sRGB 和伽马校正？

在物理世界中，如果光的强度增加一倍，那么亮度也会增加一倍，这是**线性关系**。

而历史上最早的显示器 (阴极射线管)显示图像的时候，电压增加一倍，亮度并不跟着增加一倍。即输出亮度和电压并不是成线性关系的，而是呈亮度增加量等于电压增加量的 2.2 次幂的非线性关系：

![[Pasted image 20221030172034.png]]

2.2 也叫做该显示器的**Gamma**值，**现代显示器的 Gamma 值也都大约是 2.2**。

> [!NOTE] 
>现在的液晶显示器依然保留了 2.2 方的解码 gamma 校正。但这并不是什么历史遗留问题，也不是因为 CRT 的物理特性，而是现代数据编码上实实在在的需求——对物理线性的颜色编码做 0.45 次方的 gamma 校正，目的是为了让颜色编码的亮度分级与人眼主观亮度感受线性对应。这样，在相同的数据位数下，图像数据可以保留更多人眼敏感的信息。以 8 位色为例：由于人眼对暗色调更加敏感，那就对物理线性的颜色做 0.45 次方的处理，也就是编码 gamma。校正完成后，相当于使用了 0~128 的范围来表达原来与物理强度保持线性时 0~55 的亮度变化。因此，显示器做解码 gamma 的目的是为了让便于保存和传输的颜色编码变回物理线性的形式，以便人眼观察显示器时能得到与观察现实世界时相近的感受。

这种关系意味着当电压线性变化时，相对于真实世界来说，亮度的变化在暗处变换较慢，暗占据的数据范围更广，颜色整体会偏暗。

如图，直线代表物理世界的**线性空间（Linear Space）**，下曲线是显示器输出的**Gamma2.2 空间（Gamma Space）**。
![[Pasted image 20221030173023.png]]

好了，正常情况下，人眼看物理世界感知到了正常的亮度。而如果显示器输出一个颜色后再被你看到，即相当于走了一次 Gamma2.2 曲线的调整，这下子颜色就变暗了。如果**我们在显示器输出之前，做一个操作把显示器的 Gamma2.2 影响平衡掉**，那就和人眼直接观察物理世界一样了！这个平衡的操作就叫做**伽马校正。**

在数学上，伽马校正是一个约 0.45 的幂运算（和上面的 2.2 次幂互为逆运算）：
![[Pasted image 20221030173109.png]]
![[Pasted image 20221030173124.png]]
>左 (Gamma0.45) 中 (Gamma2.2) 右 (线性物理空间)

经过 0.45 幂运算，再由显示器经过 2.2 次幂输出，最后的颜色就和实际物理空间的一致了。

**最后，什么是 sRGB 呢？** 1996 年，微软和惠普一起开发了一种标准**sRGB**色彩空间。这种标准得到许多业界厂商的支持。**sRGB 对应的是 Gamma0.45 所在的空间**。

**为什么 sRGB 在 Gamma0.45 空间？**

假设你用数码相机拍一张照片，你看了看照相机屏幕上显示的结果和物理世界是一样的。可是照相机要怎么保存这张图片，使得它在所有显示器上都一样呢？ 可别忘了所有显示器都带 Gamma2.2。反推一下，那照片只能保存在 Gamma0.45 空间，经过显示器的 Gamma2.2 调整后，才和你现在看到的一样。换句话说，**sRGB 格式相当于对物理空间的颜色做了一次伽马校正**。

还有另外一种解释，和人眼对暗的感知更加敏感的事实有关。
![[Pasted image 20221030173401.png]]
如图，在真实世界中（下方），如果光的强度从 0.0 逐步增加到 1.0，那么亮度应该是线性增加的。但是对于人眼来说（上方），感知到的亮度变化却不是线性的，而是在暗的地方有更多的细节。换句话说，**我们应该用更大的数据范围来存暗色，用较小的数据范围来存亮色。** 这就是 sRGB 格式做的，定义在 Gamma0.45 空间。而且还有一个好处就是，**由于显示器自带 Gamma2.2，所以我们不需要额外操作显示器就能显示回正确的颜色**。

以上内容，看完后还是不懂也没关系，在继续之前你可以先死记住以下几个知识点：

-   **显示器的输出在 Gamma2.2 空间。**
-   **伽马校正会将颜色转换到 Gamma0.45 空间。**
-   **伽马校正和显示器输出平衡之后，结果就是 Gamma1.0 的线性空间。**
-   **sRGB 对应 Gamma0.45 空间。**

### 统一到线性空间

现在假设你对上文的概念有一定认识了，我们来讲重点吧。

在 Gamma 或 Linear 空间的渲染结果是不同的，从表现上说，在 Gamma Space 中渲染会偏暗，在 Linear Space 中渲染会更接近物理世界，更真实：

![[Pasted image 20221030173512.png]]
>左（Gamma Space），右（Linear Space）

**为什么 Linear Space 更真实？**

你可以这么想，物理世界中的颜色和光照规律都是在线性空间描述的对吧？（光强度增加了一倍，亮度也增加一倍）。而计算机图形学是物理世界视觉的数学模型，Shader 中颜色插值、光照的计算自然也是在线性空间描述的。如果你用一个非线性空间的输入，又在线性空间中计算，那结果就会有一点“不自然”。

换句话说，**如果所有的输入，计算，输出，都能统一在线性空间中，那么结果是最真实的**，玩家会说这个游戏画质很强很真实。事实上因为计算这一步已经是在线性空间描述的了，所以只要保证输入输出是在线性空间就行了。

所以为什么你的游戏画面不真实呢？因为你可能对此混乱了，你的输入或输出在 Gamma Space，又没搞清楚每个纹理应该在什么 Space，甚至也不知道有没用伽马校正，渲染结果怎么会真实呢？

**现在假设我们的目标是获得最真实的渲染，因此需要统一渲染过程在线性空间，怎么做呢？**

**注**：统一在 Linear 空间是最真实的，但不代表不统一就是错的。一般来说，如果是画质要求高的作品（如 3A）等，那么都是统一的。没这方面要求的则未必是统一的，还有一些项目追求非真实的渲染，它们也未必需要统一。

统一到线性空间的过程是看起来是这样的，用图中橙色的框表示（现在看不懂图没关系，跟着后面的步骤来一步步看）：
![[Pasted image 20221030173707.png]]
我们从橙色框的左上角出发。

第一步，输入的纹理如果是 sRGB（Gamma0.45），那我们要进行一个操作转换到线性空间。这个操作叫做**Remove Gamma Correction**，在数学上是一个 2.2 的幂运算 c→c2.2 。如果输入不是 sRGB，而是已经在线性空间的纹理了呢？那就可以跳过 Remove Gamma Correction 了。

**注**：美术输出资源时都是在 sRGB 空间的，但 Normal Map 等其他电脑计算出来的纹理则一般在线性空间，即 Linear Texture。详见后文！

第二步，现在输入已经在线性空间了，那么进行 Shader 中光照、插值等计算后就是比较真实的结果了（上文解释了哦~），如果不对 sRGB 进行 Remove Gamma Correction 直接就进入 Shader 计算，那算出来的就会不自然，就像前面那两张球的光照结果一样。

第三步，Shader 计算完成后，需要进行**Gamma Correction**，从线性空间变换到 Gamma0.45 空间，在数学上是一个约为 0.45 的幂运算 c→c12.2 。如果不进行 Gamma Correction 输出会怎么样？那显示器就会将颜色从线性空间转换到 Gamma2.2 空间，接着再被你看到，结果会更暗。

第四步，经过了前面的 Gamma Correction，显示器输出在了线性空间，这就和人眼看物理世界的过程是一样的了！

  

我们再举个例子，我们取 sRGB 纹理里面的一个像素，假设其值为 0.73。那么在统一线性空间的过程中，它的值是怎么变化的？
![[Pasted image 20221030184116.png|300]]
第一步，0.73 (上曲线) * [Remove Gamma Correction] = 0.5 (直线)。（ 0.73<sup>2.2</sup>=0.5 ）

第二步，0.5 (直线) * [Shader] = 0.5 (直线)（假设我们的 Shader 啥也不干保持颜色不变）

第三步，0.5 (直线) * [Gamma Correction] = 0.73 (上曲线)。（ 0.5<sup>1/2.2</sup>=0.73 ）

第四步，0.73 (上曲线) * [显示器] = 0.5 (直线)。（ 0.73<sup>2.2</sup>=0.5 ）

如果不进行 Gamma Correction，就会变暗，因为第三步不存在了，第四步就会变成：

0.5 (直线) * [显示器] = 0.218 (下曲线)。（ 0.5<sup>2.2</sup>=0.218 ）

再对照上面的图琢磨琢磨？

### Unity 中的 Color Space

我们回到 Unity，Editor>Project Setting>Player 中的“Color Space”属性可以选择 Gamma 或 Linear 作为 Color Space：
![[Pasted image 20221030184401.png]]
**这两者有什么区别呢？**

**如果选择了 Gamma，那 Unity 不会对输入和输出做任何处理**，换句话说，Remove Gamma Correction 、Gamma Correction 都不会发生，除非你自己手动实现。
手动颜色空间转换：
![[Pasted image 20230723133314.png]]

**如果选了 Linear，那么就是上文提到的统一线性空间的流程了**。对于 sRGB 纹理，Unity 在进行纹理采样之前会自动进行 Remove Gamma Correction，对于 Linear 纹理则没有这一步。而在输出前，Unity 会自动进行 Gamma Correction 再让显示器输出。

怎么告诉 Unity 纹理是 sRGB 还是 Linear 呢？**对于特定用途的纹理，你可以直接设置他们所属的类型：如 Normal Map、Light Map 等都是 Linear，设置好类型 Unity 自己会处理他们。**
![[Pasted image 20221030184638.png]]
**还有一些纹理不是上面的任何类型，但又已经在线性空间了（比如说 Mask 纹理、噪声图），那你需要取消 sRGB 这个选项让它跳过 Remove Gamma Correction 过程**：
### UE 中的 Color Space
[Unreal中关于颜色的技术分享_百科TA说 (baidu.com)](https://baike.baidu.com/tashuo/browse/content?id=9167c87c2cd4f1c2f4d1c173&lemmaId=2147136&fromLemmaModule=pcRight)
用过 unreal 的小伙伴应该都会注意到，我们在 unreal 里面进行贴图设置的时候，对于 basecolor 都需要勾选上 sRGB。为什么需要勾选？每张贴图都需要勾选么？如果不做勾选会怎么样？这就需要用我们的 gamma 校正和线性空间来破案了。接下来就一起来看这篇 Unreal 中关于颜色的技术分享。
![[Pasted image 20221030185833.png]]

Gamma 校正

首先什么是 gamma 校正。官方解释，RGB 值与功率并非简单的线性关系，而是幂函数关系，这个函数的指数称作 Gamma 值，一般为 2.2（power2.2），而这个换算过程，称为 Gamma 校正。官方来源，开发 gamma 编码是用来抵消阴极射线管（CRT）显示器的输入和输出特性，电子枪的电流，也是光的亮度，与输入的正极电压的变化是非线性的。通过 gamma 压缩来改变输入信号抵消了这个非线性，因此输出图像就能有预期的亮度。

画图来理解就是如下，

如果我们有一张线性的照片，如果我们显示器也是线性的，那经过显示器输出的图像就应该和真实的图像是一样的；
![[Pasted image 20221030185921.png]]
但是实际上我们的显示器根本不按套路来，它的 gamma 值是 2.2，所以如果我们的图片是线性的，那么从 gamma 为 2.2 的显示器中输出出来就是下面这个样子
![[Pasted image 20221030185928.png]]
可以看到结果有明显的色彩失真，所以如果我们把照片的 gamma 值设置成 1/2.2 的话，经过两次调整，结果就是正确的啦

![[Pasted image 20221030185956.png]]
在进行 gamma 校正的方式就是采样进行输入的时候，Gamma=1/2.2，调亮 Gamma；

在显示输出的时候 Gamma=2.2，调暗 Gamma。
![[Pasted image 20221030190026.png]]
**线性空间**

一般在图片的渲染中存在两个颜色空间，第一个是 Gamma（非线性）的颜色空间；然后是 Linear（线性）颜色空间。Gamma 使用的是进行了校正的颜色表；而 linear 使用的是一个线性的完整颜色表，而且渲染中用到的光线也是线性空间的，所以我们在进行计算的时候要在线性空间中进行，输入和输出需要进行 gamma 校正。

最好的办法就是在图片输入的时候采用 sRGB 格式，目的是为了告诉 linear color space，需要对输入的颜色进行 power2.2 校正切换到线性空间，然后再进行 shader 计算，计算完毕以后再通过 power1/2.2 切换回 gamma 空间。所以解决了我们刚开始提的在 unreal 中的**basecolor 需要勾选 sRGB 选项**。而**非 sRGB 纹理则会直接在 shader 中进行计算，比如 normal 和 mask。**

所以以上就解释了我们在导入贴图的时候需要注意到的问题，只有勾选了引擎才会进行正确的像素计算；一般 basecolor 才需要勾选；对于 basecolor 来说，不勾选 GPU 就不会进行 gamma 校正，而直接使用存储的值进行渲染，但同时也不会得到真实的效果。

### 到底什么纹理应该是 sRGB，什么是 Linear？

关于这一点，我个人有一个理解：**所有需要人眼参与被创作出来的纹理，都应是 sRGB（如美术画出来的图）。所有通过计算机计算出来的纹理（如噪声，Mask，LightMap）都应是 Linear**。

这很好解释，人眼看东西才需要考虑显示特性和校正的问题。而对计算机来说不需要，在计算机看来只是普通数据，自然直接选择 Linear 是最好的。

**除了纹理外，在 Linear Space 下，Shaderlab 中的颜色输入也会被认为是 sRGB 颜色，会自动进行 Gamma Correction Removed。**

有时候你可能需要想让一个 Float 变量也进行 Gamma Correction Removed，那么就需要在 ShaderLab 中使用[Gamma]前缀：

```c
[Gamma]_Metallic("Metallic",Range(0,1))=0
```

如上面的代码，来自官方的 Standard Shader 源代码，其中的_Metallic 这一项就带了[Gamma]前缀，表示在 Lienar Space 下 Unity 要将其认为在 sRGB 空间，进行 Gamma Correction Removed。

**扩展：为什么官方源代码中_Metallic 项需要加[Gamma]？** 
这和底层的光照计算中考虑能量守恒的部分有关，Metallic 代表了物体的“金属度”，如果值越大则反射 (高光)越强，漫反射会越弱。在实际的计算中，这个强弱的计算和 Color Space 有关，所以需要加上[Gamma]项。

虽然 Linear 是最真实的，但是 Gamma 毕竟少了中间处理，渲染开销会更低，效率会更高。上文也说过不真实不代表是错的，**毕竟图形学第一定律：如果它看上去是对的，那么它就是对的**。

**注**：在 Android 上，Linear 只在 OpenGL ES 3.0 和 Android 4.3 以上支持，iOS 则只有 Metal 才支持。

在早期移动端上不支持 Linear Space 流程，所以需要考虑更多。不过随着现在手机游戏的发展，越来越多追求真实的项目出现，很多项目都选择直接在 Linear Space 下工作。

一旦确定好  Color Space，那么就需要渲染工程师、技术美术和美术商量和统一好工作流了。在中小团队或项目中，这些概念很容易被忽略，导致工作流混乱，渲染效果不尽人意。现在你懂了吗？

# 进阶
![[Pasted image 20230723133508.png]]

# 3 HDR 和 LDR
## 基本概念
-   **Dynamic Range**（动态范围）=最高亮度/最低亮度
-   **HDR**= High Dynamic Range
-   **LDR** = Low Dynamic Range（我们日常看到的）
-   **ToneMapping**：将超高的动态范围（HDR）转换到我们日常显示的屏幕上的低动态范围（LDR）的过程
![[Pasted image 20221030192152.png]]
-   一些小芝士：
-       因为不同的厂家生产的屏幕亮度（物理）实际上是不统一的，那么我们在说**LDR 时，它是一个 0 到 1 范围的值**，对应到不同的屏幕上就是匹配当前屏幕的最低亮度（0）和最高亮度（1）
-       自然界中的亮度差异是非常大的。例如，蜡烛的光强度大约为 15，而太阳光的强度大约为 10w。这中间的差异是非常大的，有着超级高的动态范围。将太阳光显示在屏幕上就是 ToneMapping。
-       我们日常使用的屏幕，其最高亮度是经过一系列经验积累的，所以使用、用起来不会对眼睛有伤害；但自然界中的，比如我们直视太阳时，实际上是会对眼睛产生伤害的。
- 
- **相机是如何将 HDR 映射到 LDR 的**
-   首先将曝光值进行计算，映射到相机可以感应的范围
-   受光圈、快门、传感器的灵敏度等影响
-   然后把这个值输入为线性的值，存储到图片中（一般为 raw 格式）
-   之后会经过一个变化（LUT），通过白平衡、色彩校正、色调映射、伽马校正这个过程，最后的结果烘焙成 LUT（pbr 中 LUT 的图，就是这个过程的结果）
-   每个相机厂商的 LUT 格式不太一样。
### 为什么需要 HDR
![[Pasted image 20221030192615.png]]
-   LDR 只能将现实中的颜色压缩再呈现出来
-   HDR 可以由更好的色彩，更高的动态范围和更丰富的细节。
-   可以有效防止画面过曝，**超过 1 的亮度值的色彩也能很好地表现**，像素光亮度变得很正常，视觉传达更真实
-   HDR 才有超过 1 的数值，才会有光晕（bloom）效果，高质量的 bloom 效果能体现出画面的渲染品质
![[Pasted image 20221030192649.png]]

## Unity 中的 HDR
### 1. Camera 中的 HDR 设置
![[Pasted image 20221030192735.png]]
-   开启的话，会将场景渲染为 HDR 图像缓冲区
-   下一步进行屏幕后处理：Bloom 和 ToneMapping
-   在 ToneMapping 过程中，会把 HDR 转换为 LDR
-   LDR 的图像会发送给显示器
###  2. Lightmap 的 HDR 设置
-   选择 High Quality 将启用 HDR 光照贴图的支持，选择 Normal Quality 将切换为使用 RGBM 编码
-   RGBM 编码：将颜色存储在 RGB 通道中，将乘数（M）存储在 Alpha 通道中
![[Pasted image 20221030192844.png]]
### 3. 拾色器的 HDR 设置
![[Pasted image 20221030192922.png]]
![[Pasted image 20221030192919.png]]
-   如果将 Property 的颜色参数的前边加上[HDR]就会将其标识为 HDR
-   颜色设置为 HDR，那么拾色器中就会出现一个 Intensity 的滑条用来调整强度
-   **滑条每增加 1，提供的光强度增加一倍。**
### 4. HDR 的优点、缺点

-   优点
-   画面中亮度超过 1 的部分不会被截掉，增加了亮部的细节，减少了曝光
-   减少画面暗部的色阶感
-   更好的支持 bloom 效果

-   缺点
-   渲染速度慢，需要更多显存
-   不支持硬件抗锯齿
-   部分低端手机不支持

## HDR 与 ToneMapping
### 1. ToneMapping 概念
**启用 HDR 的应用程序面临一个问题：应用程序阶段的 HDR 数据格式很可能与显示设备所需的 HDR 格式不一致，或者显示设备压根不支持 HDR，只支持 LDR 格式。**

为了解决以上这个问题，就需要引入**色调映射（Tone Mapping），它可以将 HDR 颜色变换成 LDR 格式或者另一种 HDR 格式（VDR）。**

-   前边的回顾：LDR 范围为 0 到 1，HDR 可以超过 1,；
-   **ToneMapping 的概念：**

-   **想要在显示器上表现更高动态范围的颜色，就要把 HDR 压缩为 LDR（这个过程就是 ToneMapping），这种映射关系就是色调映射。**

-   下边例子是一个<font color="#ff0000">线性的亮度映射</font>，但这并不符合我们对真实世界的理解，因此，基本上所有的映射最后都是通过一个**s 曲线**来实现。
![[Pasted image 20221030193256.png|500]]
### 2. ACES 曲线
![[Pasted image 20221102204612.png]]
-   Academy Color Encording System 学院颜色编码系统
-   是最流行、最被广泛使用的 ToneMapping 映射曲线
-   效果：对比度提高，压暗暗部使暗部变化更不明显。能很好的保留暗部和亮部的细节。之后在这个基础上再进行调色
![[Pasted image 20221030193438.png|500]]
### 3. 其他类型的 ToneMapping 算法
[Tone mapping进化论 ](https://zhuanlan.zhihu.com/p/21983679)

### 4. LUT（Lookup Table）
![[Pasted image 20221030193623.png]]
-   **简单的理解**：就是滤镜，通过 LUT，你可以将一组 RGB 值输出为另一组 RGB 值，从而改变画面的曝光与色彩
-   和 ToneMapping 不同，**LUT 是在 LDR 之间做变化**。而 ToneMapping 是对 HDR 做变换的。
-   调整 RGB 三通道的 LUT 被称为 3D LUT
	-   格式有如下几种
	- ![[Pasted image 20221030193651.png]]
 -   小 trick：可以在 PS 中调整 LUT，导出的 LUT 作为滤镜调整画面
 ![[Pasted image 20221030193716.png]]
 UE4 的后处理滤镜部分中也有 LUT 相应的位置
 ![[Pasted image 20221030193748.png]]


# 4 色彩分级 color grading 
## 基础概念

### Color Adjustment

色彩调整（Color adjustment）是指对图像中的颜色进行调整，以达到特定的色彩效果或者色彩校正的目的。
**色彩调整通常包括三个步骤：**
- 色彩校正 (color correction)
- 色彩分级 (color grading) 
- 色调映射 (tone mapping)。

色彩矫正 vs 色彩分级： “Correcting is a balance. Grading is a look.”

*   **色彩矫正**： 色彩校正统一你的电影镜头。色彩校正使得电影的色调与真实世界的色调保持一致。通过色彩校正，可以让每个视频片段之间的颜色相匹配，从而使它们的色调统一起来。在色彩矫正过程中，你可以调整诸如曝光、对比度和白平衡，并确保像肤色这样的重要色调得到准确体现。如果你的相机或灯光情况使真实世界中的白色在镜头中出现蓝色，你将在这个阶段纠正这些区域，使其更接近真实的白色。纠正白平衡有助于使你的所有颜色更加真实。**色彩校正不在乎你的风格，而是颜色的正确性。**
*   **色彩分级**： 色彩分级使你的画面更有优势。在色彩分级阶段，你可以为你影片的着色应用一种整体风格。这为你的项目注入了视觉基调，传达了你希望观众感受到的情感。**在调色之前，先进行色彩矫正，以确保开始时有平衡的、自然的色彩。在色彩矫正过后，可以尝试用色彩分级为影片奠定基调和氛围。** 如果你的电影是一部残酷的犯罪剧，可以尝试冷色调。而更快乐的视频类型可以尝试用暖色调。

![[8486b8705b6fbbd8b38f205d98c3c3a8_MD5.jpg]]

**色彩校正和色彩分级可以同时进行，合并为同一个步骤，即色彩分级。**（并且一般都合并处理）

### Color Grading LUT

LUT (Look-up Texture) 指的是一种预处理方法。将 key 作为采样坐标，计算出来的 value 作为纹理，预先渲染到纹理中。在需要用到这个键对映射关系时，通过 key 对纹理进行采样，直接得到 value 的值，从而减少了中间计算的消耗。 Color Grading 恰好可以满足这种键对映射关系，所以可以采用 LUT 的方法。

![[8e71591a64f06755052c5e7e78809fa0_MD5.jpg]]

**2D LUT 的缺陷是只能对颜色进行 color grading，无法对饱和度、对比度等使用（因为 RGB 通道被单独分出来了，无法进行组合运算）。**

**3D LUT 指的是将原 RGB 矢量作为 key，经过 color grading 后的 RGB 矢量作为 value 的键对映射。**

![[2013939056f500753d92574b63861860_MD5.jpg]]

**3D LUT 不仅可以对颜色进行 color grading，还可以对饱和度、对比度等进行。** 3D LUT 纹理的每个像素代表一个颜色，称为 node。3D 纹理的尺寸决定了 nodes 的数量，从而决定了 color grading 的精度。我们可以将 3D LUT 看作是一个向量空间变换。假设原 RGB 空间的颜色为向量 $\vec{c_{in}}$ ，分级 RGB 空间的颜色为向量 $\vec{c_{out}}$ 。那么 3D LUT 就是一个函数，或者说变换 $\mathbf{M}$ ，它使得 $\vec{c_{out}}=\mathbf{M}\vec{c_{in}}$ 。函数 $\mathbf{M}$ 的值如何确认？将它想象为一个已经画出所有点的以原 RGB 为自变量，分级 RGB 为值的 3D 坐标系。在这个坐标系上找到 $\vec{c_{in}}$ 对应的值 $\vec{c_{out}}$ 即可。

**在实际应用中，我们不存储 3D cube 纹理，而是将这张 cube 纹理展开成一张 2D 纹理。**（可以想象成把 cube 的每一层平铺为一层）（没找到合适的图，稍微 p 了一下原图）

![[23f91a5a432ca48e2c438b7ed0ca6189_MD5.jpg]]

从这张 3D LUT cubemap 到 2D LUT texture 可以看作一种映射关系，或者说一个变换。

## URP 的 ColorGradingLUT

### 项目设置

首先，确保项目的颜色空间为线性空间。Project Settings->Player->Color Space->Linear。

![[c37a4df1ee24bf415f1666b40b57b742_MD5.jpg]]

然后，打开 RP Asset 的 HDR。

![[e984a574e4b9a98403e45d3cc91023a6_MD5.jpg]]

最后，将相机的 HDR 设置为随项目设置。

![[a8e0058340f5225bced3e58ceb657ce0_MD5.jpg]]

### HDR 分析

下面，我们关闭 Unity 中所有的后处理，仅仅给两个球体赋予 Unlit 材质，左边使用 LDR 颜色，右边使用 HDR 颜色。先关闭 HDR 选项。对左边的 LDR 颜色取 (0.5, 1.0, 0.5)，右边的 HDR 颜色吸取左边物体颜色。此时我们发现 HDR 颜色值为 (0.2, 1, 0.2)。这是由于 HDR 颜色最终会显示在 LDR 空间，而这个转换是非线性的。

![[45ba3bcd782088e8b9c5437c6fe20a8d_MD5.jpg]]

此时将 HDR 颜色亮度上调 1，HDR 颜色就更亮了。

![[8f624f7607d858c81f850c1797c531d2_MD5.jpg]]

我们再复制一个 HDR 的 Unlit，将左边 Unlit 的亮度设为 3.0，右边设为 16.0。在关闭 HDR 的情况下，它们都是颜色值一样的纯白。

![[e5ccd2546f4c623b3e06b7537428c972_MD5.jpg]]

此时打开项目的 HDR，发现三个物体的颜色并不会发生任何变化。可是按道理来说右边 Unlit 的亮度应该比左边更亮。这是因为更改为 HDR 后，变化的中间纹理的存储格式，而中间纹理最终会转换到 LDR 空间以显示在屏幕上。我们并没有用中间纹理干事，所以此时打开 HDR 是没有任何效果的。

为了观察打开 HDR 与否的区别，我们打开 Frame Debugger。关闭项目 HDR，发现中间纹理 `_CameraColorAttachmentA` 的格式为 sRGB。

![[58669f3ffc89420c344a5040c6ea4241_MD5.jpg]]

打开项目 HDR，发现中间纹理的格式变为了 sFloat。

![[6d24e222e2477ebd51b9736eea0234c4_MD5.jpg]]

### tonemapping

那么，我们该如何利用这些 HDR 格式的中间纹理搞事呢？这就引入了 tonemapping，它将整体颜色压暗，使得极亮之间表现出区别。中间纹理一般与后处理挂钩，所以 tonemapping 一般在后处理阶段进行。我们为场景添加一个挂载了 ACES tonemapping 的 Global Volume。

![[32c8f589047a395201560da90a135133_MD5.jpg]]

应用上 ACES，明显感到所有颜色都变暗了。当然，在 LDR 空间下，两个极亮的 HDR Unlit 颜色还是没区别。

![[f3a0ce12a9a5a23de0cfaa8574cb8e44_MD5.jpg]]

但我们打开项目的 HDR，发现颜色变亮了，而且右边强度为 16 的 Unlit 物体更亮。

![[1d669e114158f3bb075275449ea2f26f_MD5.jpg]]

### Bloom

另外，Bloom 也能体现出 HDR 的优势。用 Global Vlomue 为场景配置一个 Bloom 效果。首先开启 HDR，然后调整 HDR 物体的 Unlit 颜色亮度，这样可以看到 Bloom 的辉光效果会变得越来越亮。

![[dc01d68984c66a46c71b392e8077b781_MD5.gif]]

然而，如果关闭 HDR，亮度立刻消失。这是因为 LDR 的纹理不支持如此高的亮度精度，亮度超过 1 的部分被钳位到 1，导致 Bloom 无法判断这些区域是否为极亮的区域。最后，经过 ACES 的压暗，最终左右两个 HDR 颜色显示为一样的亮度。

![[e1153f37c3c13e7d1672795adbd52d1a_MD5.gif]]

### ColorGradingLUT

下面继续分析 Frame Debugger。在 LDR 空间下，Frame Debugger 长这样。可以看到一个多出来的 Color Grading LUT，注意此时的渲染目标以及 RT 格式。

![[1b61846a845e06cb07339af5eb3a99f3_MD5.jpg]]

使用 Shader 是 LutBuilderLdr。

![[61dee8f06135d27f9eaf041cc38008cb_MD5.png]]

下面打开项目的 HDR，并且把 RP Asset 中 Post-processing 的 Grading Mode 改为 High Dynamic Range。

![[faf151359b64a28b70e0a2d7bbfbf984_MD5.jpg]]

发现 Frame Debugger 中的 ColorGradingLUT 多了一坨新颜色，并且 RT 的格式也变成了 sFloat。并且我们关闭后处理的 tonemapping，这时候的 LUT 几乎是纯色块。

![[20da5ef0f6ff4b2d6d4b6a7ca0e26980_MD5.jpg]]

并且使用的 Shader 是 LutBuilderHdr。

![[1618a096927126a5ea367cd2d25f6da1_MD5.png]]

然后我们打开 ACES Tonemapping，此时的 LUT 有了亮度区分。

![[d2894b936422199d6f944043ae7de8f0_MD5.jpg]]

**也就是说，HDR LUT 会根据 tonemapping 的选项，对 HDR 颜色应用 tonemapping。**

但若将 RP Asset 中 Post-processing 的 Grading Mode 改为 Low Dynamic Range，ColorGradingLut 又会变为 LDR 的情况。也就是说，**Unity 判断是否生成 HDR LUT 的条件有两个：打开 HDR 并且 RP Asset 的 Grading Mode 为 High Dynamic Range。注意这只是 LUT 是否是 HDR 的，与项目是否是 HDR 无关。**

我们应该如何改变 LUT 的颜色对应表呢？答案是给 Global Volume 注入 Color Grading 相关后处理。我们打开 RP 源文件 `ColorGradingLutPass.cs`，可以发现 ColorGrading 与以下后处理组件有关。

![[c82dc1a7f98cafba518fa98939f38f58_MD5.jpg]]

我们给 Global Volume 注入一个 Color Adjustments，调节参数，可以发现 LUT 的确发生变化。

![[55efa89b687fe4af6e5e0d5592930919_MD5.jpg]]

**也就是说，不论是否进行 Color Grading，ColorGradingLUT 始终是后处理的一部分。**

并且还可以发现，LUT 的渲染在 RenderingPrePasses 后，并且将 LUT 渲染给了一张中间纹理 `_InternalGradingLUT`。那么何时应用它呢？我们跳到最后一步 Render PostProcessing Effects 的最后一步 Draw Procedural。发现它把 `_InternalGradingLUT` 以及一张 `_UserLUT` (尽管我们并没有为后处理添加自己的 LUT) 传给 `UberPost.hlsl`。

![[f22e8d4b05b2b7e328f9ad76985788f7_MD5.jpg]]

最后，我们注意到帧调试器里是没有出现 tonemapping 步骤的，这说明 tonemapping 实际上是根据 HDR LUT 开启与否，在最后上图最后一步中根据选项进行的。具体可以从下面代码讨论中分析。

可以发现，ColorGrading 是每一帧都进行的，这是因为判断 colorgrading 是否变换是很麻烦的，特别是在 OverlayCamera 的情况下。由于 lut 的 texel 肯定小于屏幕 texel，所以说性能还是优化了不少的。

### UberPost. hlsl

下面打开 `UberPost.hlsl`。首先可以找到一行多重编译指令。

![[682c9e543ee29da1dd03f44eab0144ab_MD5.png]]

这代表是否启用了 HDR，如果未启用 HDR，则选择使用 aces tonemap 或 neutral tonemap。在 Frame Debugger 上也可以验证这一点。

继续向下，找到片元着色器。其中一行是应用 ColorGrading。注意这一行注释，它也对应了我们之前的推测，即只要打开后处理，color grading 就一直存在。

![[21105919a636d5da576f4dbf9227a687_MD5.png]]

跟踪这个 `ApplyColorGrading`。首先可以确定在渲染 LUT 时，并没有把后曝光渲染进去，而是在空间转换前对输入进行处理。

![[21f4cca2878cf660c75de0a86733f098_MD5.png]]

然后根据 HDR Grading 或 LDR Grading 进行判断。首先是 HDR Grading。

![[4fa1bc863832a16ebfb2e2fbb2e5c682_MD5.jpg]]

可以发现，HDR Grading，采样 HDR LUT 的作用有两个：第一，将原颜色应用 Color Adjustment。第二，将原颜色转到 LDR 空间。

然后分析 LDR Grading。

![[a526d9f9e38c1ce78fcd2e6746ac2448_MD5.jpg]]

可以发现，LDR Grading，采样 LDR LUT 的作用有一个：将原颜色应用 Color Adjustment。而 HDR 空间到 LDR 空间的转换是通过对输入应用 tonemapping 进行的。

### 总结

最后总结一下：

*   Unity 打开 HDR，更改的是中间纹理的格式
*   打开后处理，ColorGradingLUT（渲染 LUT）就会存在，不论是否进行 Color Grading
*   LUT 的渲染在 RenderingPrePasses 后
*   渲染 HDR LUT 条件
*   项目为 HDR
*   RP Asset 的 Grading Mode 为 HDR
*   LUT 的作用有两种情况
*   LDR LUT：应用 color grading。渲染时只用渲染 color grading 的颜色转换。
*   HDR LUT：应用 color adjustment。渲染时要渲染 color grading 和 tonemapping 的颜色转换。（根据 tonemapping 的选项，如果没有就不 tonemapping）
*   打开后处理，HDR 空间到 LDR 空间输出转换有两种情况
*   RP Asset 的 Grading Mode 为 LDR：应用 tonemapping，模式依照 tonemapping 后处理选项
*   RP Asset 的 Grading Mode 为 HDR：采样 HDR LUT

## LUT 的生成与分析

### 生成 Neutral LUT

想要生成一张 LUT，我们首先需要得到一张中性 LUT (Neutral LUT)，然后对这张中性 LUT 进行 Color Grading。如何获取一张中性 LUT 呢？这里提供一种通过 Unity 获取的方法。首先将 RP Asset 中 Post-Processing 的 Grading Mode 改为 LDR，LUT Size 改为 16。

![[12e52fc0c7b95b30184d5ca28d6ea463_MD5.jpg]]

然后打开相机的 Post-Processing。

![[9daac126bb9492599abd4605e76b95dd_MD5.jpg]]

这会让 RP 执行 ColorGradingLUT 步骤，我们只需要保存这一步生成的图像即可。

![[69685a04dca357086ab453614b916353_MD5.jpg]]

用 RenderDoc 截帧，在资源里搜索 lut，找到这张纹理。

![[e9a10d9c6fa133cdca0f821101a52f59_MD5.jpg]]

点 `View Contents` 转到纹理，再保存即可。需要注意的是，RenderDoc 的纹理是**垂直翻转**了的，我们用 PS 翻转回来即可。

![[087fe1f58ce25cd31c5b3ac2a1195fab_MD5.jpg]]

HDR LUT 同理。这里简述一下在 Unity 里生成 HDR LUT 的设置。打开 HDR (项目和相机)；RP Asset 中 Post-processing 的 Grading Mode 为 HDR，LUTsize 为 32；添加一个 Global Volume，挂载一个 Tonemapping，改为 ACES。

两张 LUT 如下：

![[d4443f50c020c134db836e416008fd8c_MD5.png]]

![[4fac7cbe759523d449eeb492665315a2_MD5.png]]

连接：[github](https://github.com/dyxdyxdyx/TA-100/tree/master/Assets/2.7%20HDR/Textures)

### 应用 ColorGrading

这里简单讲一下思路，就是对上面一步得到的 Neutral LUT 进行 ColorGrading。为了方便观察，我们可以先对一张照片进行 ColorGrading，然后再将这些 ColorGrading 的参数应用到 Neutral LUT 中。

下面是我用 PS 对 Neutral LUT 应用 ColorGrading 后的一张 LUT。

![[46a5d945aaaaef3549207f19f3116bc5_MD5.png]]

连接：[github](https://github.com/dyxdyxdyx/TA-100/tree/master/Assets/2.7%20HDR/Textures)

### LUT 分析

### 应用 LUT

以 LDR Neutral LUT 为例，HDR LUT 在 LDR LUT 的基础上做了一个 tonemapping（前面也分析了）。首先，我们将 LUT 逐通道分开。如下图，可以发现不同程度的 blue 将 LUT 分为了 16 块。每个块中，red 从左到右由 0 到 1，green 从下到上由 0 到 1。LUT 中，最左下角一定是黑色，右上角一定是白色。

![[19c1995cc8610fb73b36ee37873e1b3b_MD5.jpg]]

也就是说，对于每一个块，red 和 blue 映射了该块程度 blue 下的一种颜色。

![[32f861524f74ae453e2e5b64d35de084_MD5.jpg]]

那么，对这张 LUT 的采样步骤也很明确了。首先，通过 blue 确定当前块的索引。然后，计算当前块中的 red 偏移得到 $u$ ，最后计算 green 偏移得到 $v$ 。以这张 16x16 的 LUT 为例。首先我们需要计算得到当前 blue 对应的块的索引。 $blue\in[0,1]$ ，一共有 16 块，我们需要将它映射到 $block\in[0,15]$ 。 $block = ⌊blue*15⌋$ _。然后计算这个块的基准_ $u$ _坐标，_ $u_{base}\in[0, 16*15=240]$ ，则 $u_{base}=u_{perBlockOffset}\times block=\frac{240}{15}\times block$ 。然后通过 red 计算 $u$ 基准偏移。同理，red 将 block 分为 16 小块， $u_{offset}=⌊red*15⌋/15\times 15$ _。_此时 $u=u_{base}+u_{offset}\in[0,255]$ _，_则 $u=(u_{base}+u_{offset})/255$ 。然后计算 $v$ ，同理，green 将 block 分为 16 小块，则 $v=⌊green*15⌋/15$ 。以上代码对应描述如下：

```
float u = floor(color.b * 15.0) / 15.0 * 240.0;
    u = (floor(color.r * 15.0) / 15.0 * 15.0) + u;
    u /= 255.0;

    float v = floor(color.g * 15.0);
    v /= 15.0;

    half3 left = SAMPLE_TEXTURE2D(tex, samplerTex, half2(u, v)).rgb;
```

然而这样采样出来的颜色过渡十分突兀，这是因为两个 block 间的 blue 直接进行了一个 level 的突变。

![[0b86ab3c5fd6f9f27db5b39f21cf6c38_MD5.jpg]]

所以，我们还需要采样偏右边的 block，然后对左边和右边 block 结果进行混合。

![[8ee94280ceaa75dc40ce6b29a51f3f25_MD5.jpg]]

代码如下。

```
u = ceil(color.b * 15.0) / 15.0 * 240.0;
    u = (ceil(color.r * 15.0) / 15.0 * 15.0) + u;
    u /= 255.0;

    v = ceil(color.g * 15.0) / 15.0;

    half3 right = SAMPLE_TEXTURE2D(tex, samplerTex, half2(u, v)).rgb;

    color = lerp(left, right, frac(color * 15));
```

## URP 应用 LUT

首先在 Unity 放一张 LUT 纹理，由于我们需要在 sRGB 对这张贴图采样，所以取消勾选 sRGB，让这张贴图不进行 Degamma。其次，由于在 Shader 计算时，为了减少性能消耗，不采用上面的对 rg 也进行 floor 的操作，将 FilterMode 改为 Bilinear（否则为 Point）。最后，取消 Mipmap 的生成，将 Warp Mode 改为 Clamp，MaxSize 改为 LUT 大小，Compression 改为 High Quality。

![[7013fd75b43e5b4f6875476fd05770fe_MD5.jpg]]

### LDR LUT

下面先写一个最基础的 LDR LUT。我们需要在 RP 中插入一个 RenderPass，所以需要先创建一个 RenderFeature。它创建了一个 `ApplyColorLut` Shader 的材质，并且将材质和参数传递给 RenderPass 的构造函数。最后，RenderPass 入队。 **ColorGradingLutRendererFeature. cs**

```
using UnityEngine;
using UnityEngine.Rendering;
using UnityEngine.Rendering.Universal;
using UnityEngine.Rendering.Universal.Internal;

struct ColorGradingLutParams{
    public Texture customLut;
    public float contribution;
}

internal class ColorGradingLutRendererFeature : ScriptableRendererFeature{
    private const string mShaderName = "Hidden/PostProcess/ApplyColorLut";

    #region Params Define

    public Texture customLut = null;
    [Range(0.0f, 1.0f)] public float contribution = 0.0f;

    #endregion

    private Material mMaterial;
    private ColorGradingLutParams mLutParams;

    private ApplyColorLutRenderPass mApplyColorLutRenderPass = null;

    public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) {
        if (renderingData.cameraData.postProcessEnabled)
            if (mApplyColorLutRenderPass.isActive())
                renderer.EnqueuePass(mApplyColorLutRenderPass);
    }

    public override void Create() {
        mMaterial = CoreUtils.CreateEngineMaterial(mShaderName);
        mLutParams.customLut = customLut;
        mLutParams.contribution = contribution;
        mApplyColorLutRenderPass = new ApplyColorLutRenderPass(mMaterial, mLutParams);
        mApplyColorLutRenderPass.renderPassEvent = RenderPassEvent.BeforeRenderingPostProcessing;
    }

    protected override void Dispose(bool disposing) {
        CoreUtils.Destroy(mMaterial);
    }
}
```

然后写对应的 RenderPass。在构造函数中对传递参数赋值，然后在 `Execute` 函数中写相应的渲染逻辑，首先用 Shader 把 source 渲染到临时纹理，然后把临时纹理复制到 des。在上述 LUT 图像分析中，我们需要将其参数一般化。为了避免在 Shader 里进行除法，我们以 LUT 纹素 $texel\in[0,1]$ 为范围，我们需要计算出一个颜色格子的大小 $gridSize=1/width\times 1/height$ ，然后计算出一个 block 的大小 $blockSize=1/height\times 1/height$ ，最后需要颜色格的范围 $[0,height-1]$ 。所以，我们需要向 Shader 传递的参数 $lutParams = (1/width, 1/height, height-1)$ 。

**ApplyColorLutRenderPass. cs**

```
using UnityEngine;  
using UnityEngine.Rendering;  
using UnityEngine.Rendering.Universal;  

internal class ApplyColorLutRenderPass : ScriptableRenderPass{  
    private ProfilingSampler mProfilingSampler = new ProfilingSampler("ApplyColorLut");  
    private Material mMaterial;  

    private ColorGradingLutParams mLutParams;  

    private RTHandle mTempRT0;  
    private const string mTempRT0Name = "_TemporaryRenderTexture0";  

    private int mCustomLutId = Shader.PropertyToID("_CustomLut"),  
        mCustomLutParamsId = Shader.PropertyToID("_CustomLutParams"),  
        mContributionId = Shader.PropertyToID("_Contribution");  

    private const string mHDRGradingKeyword = "_HDR_GRADING",  
        mTonemapACESKeyword = "_TONEMAP_ACES";  

    public bool isActive() => mMaterial != null && mLutParams.customLut != null;  

    public ApplyColorLutRenderPass(Material material, ColorGradingLutParams lutParams) {  
        mMaterial = material;  
        mLutParams = lutParams;  

        mTempRT0 = RTHandles.Alloc(mTempRT0Name, name: mTempRT0Name);  
    }  
    public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) {  
        var cmd = CommandBufferPool.Get("ApplyColorLut");  
        context.ExecuteCommandBuffer(cmd);  
        cmd.Clear();  

        mMaterial.SetTexture(mCustomLutId, mLutParams.customLut);  
        mMaterial.SetFloat(mContributionId, mLutParams.contribution);  
        mMaterial.SetVector(mCustomLutParamsId, new Vector4(1.0f / mLutParams.customLut.width, 1.0f / mLutParams.customLut.height, mLutParams.customLut.height - 1.0f, 0.0f));  

        var renderer = renderingData.cameraData.renderer;  
        var source = renderer.cameraColorTargetHandle;  
        var destination = renderer.cameraColorTargetHandle;  

        var descriptor = renderingData.cameraData.cameraTargetDescriptor;  
        descriptor.msaaSamples = 1;  
        descriptor.depthBufferBits = 0;  

        RenderingUtils.ReAllocateIfNeeded(ref mTempRT0, descriptor, name: mTempRT0Name, filterMode: FilterMode.Bilinear);  
        using (new ProfilingScope(cmd, mProfilingSampler)) {  
            cmd.Blit(source, mTempRT0, mMaterial, 0);  
        }        
        cmd.Blit(mTempRT0, destination);  

        cmd.ReleaseTemporaryRT(Shader.PropertyToID(mTempRT0.name));  

        context.ExecuteCommandBuffer(cmd);  
        cmd.Clear();  
        CommandBufferPool.Release(cmd);  
    }}
```

关于注入点：按理来说，ApplyLut 应该是所有后处理之后进行，但是这里面涉及到 tonemapping，如果在系统后处理后面，系统后处理的最后一步会调用 tonemapping 将颜色钳位 0 到 1，导致我们获取不了 HDR 颜色。所以将注入点放到后处理前。这样做会导致所有系统自带后处理用不了的情况，但是实际情况下根本不可能自己写一个 Lut 后处理，所以这里只是用来理解一下原理。

然后写 shader 文件。 **ApplyColorLut. shader**

```
Shader "Hidden/PostProcess/ApplyColorLut" {
    Properties {
        [HideInInspector] _MainTex ("Base (RGB)", 2D) = "white" {}
    }

    SubShader {
        Tags {
            "RenderType" = "Opaque"
            "RenderPipeline" = "UniversalPipeline"
        }
        LOD 200
        HLSLINCLUDE
        #include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Color.hlsl"
        #include "../Common/PostProcessing.hlsl"
        #include "ApplyColorLutPass.hlsl"
        ENDHLSL
        Pass {
            name "ApplyColorLUT Pass"

            HLSLPROGRAM
            #pragma vertex Vert
            #pragma fragment frag

            #pragma shader_feature _TONEMAP_ACES
            ENDHLSL
        }
    }
}
```

**PostProcessing. hlsl**

```
#ifndef POSTPROCESSING_INCLUDED
#define POSTPROCESSING_INCLUDED

#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"

TEXTURE2D(_MainTex);
SAMPLER(sampler_MainTex);

TEXTURE2D(_CameraDepthTexture);
SAMPLER(sampler_CameraDepthTexture);

struct Attributes {
    float4 positionOS : POSITION;
    float2 uv : TEXCOORD0;
};

struct Varyings {
    float2 uv : TEXCOORD0;
    float4 vertex : SV_POSITION;
    UNITY_VERTEX_OUTPUT_STEREO
};

half4 GetSource(float2 uv) {
    return SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, uv);
}

half4 GetSource(Varyings input) {
    return GetSource(input.uv);
}

Varyings Vert(Attributes input) {
    Varyings output = (Varyings)0;
    // 分配instance id
    UNITY_INITIALIZE_VERTEX_OUTPUT_STEREO(output);

    VertexPositionInputs vertexInput = GetVertexPositionInputs(input.positionOS.xyz);
    output.vertex = vertexInput.positionCS;
    output.uv = input.uv;

    return output;
}

#endif
```

在具体的 Pass 文件中，我们需要在片元着色器中获取片元颜色，对它进行 Lut，然后输出。 **ApplyColorLutPass. hlsl**

```
TEXTURE2D(_CustomLut);  
SAMPLER(sampler_CustomLut);  

float4 _CustomLutParams; 
float _Contribution;

half4 frag(Varyings input) : SV_Target {
    half3 color = GetSource(input).xyz;
    color = ApplyColorGrading(color, TEXTURE2D_ARGS(_CustomLut, sampler_CustomLut));
    return half4(color, 1.0);
}
```

在应用 ColorGrading 函数中，我们需要先将颜色从线性空间转到 sRGB 空间（因为 Lut 取消勾选 sRGB，此时它不会进行 Degamma，它一直在 sRGB 空间内），然后引用这个 sRGB color 采样 Lut，最后转换回线性空间进行输出。 **ApplyColorLutPass. hlsl**

```
half3 ApplyColorGrading(half3 input, TEXTURE2D_PARAM(customLutTex, customLutSampler)) {
    saturate(input);
    input.rgb = LinearToSRGB(input);
    half3 outLut = ApplyLut(TEXTURE2D_ARGS(customLutTex, customLutSampler), input, _CustomLutParams.xyz);
    input = lerp(input, outLut, _Contribution);
    input.rgb = SRGBToLinear(input.rgb);
    return input;
}
```

在 ApplyLut 函数中，我们需要首先计算出 block 的索引，然后计算出

 $\begin{align} u=u_{base}+u_{offset}+u_{toCenter}=block*blockWidth+gridIndex_{red}*gridWidth+0.5*gridWidth\\ v=v_{offset}+v_{toCenter}=gridIndex_{green}*gridHeight+0.5*gridHeight \end{align}$

前面提到， $gridSize=1/width\times 1/height,~blockSize=1/height\times 1/height$ 。为了减少消耗，我们取消对 $gridIndex$ 计算时的 floor。代码如下：

```
// scaleOffset = (1 / lut_width, 1 / lut_height, lut_height - 1)
// gridSize = scaleOffset.x x scaleOffset.y, blockSize = scaleOffset.y
real3 ApplyLut(TEXTURE2D_PARAM(tex, samplerTex), float3 color, float3 scaleOffset) {
    // 计算block索引
    color.b *= scaleOffset.z;
    float block = floor(color.b);
    // 计算在u = uBase+uOffset
    float u = block * scaleOffset.y + color.r * scaleOffset.z * scaleOffset.x + scaleOffset.x * 0.5;
    float v = color.g * scaleOffset.z * scaleOffset.y + scaleOffset.y * 0.5;
    color.rgb = lerp(
        SAMPLE_TEXTURE2D_LOD(tex, samplerTex, float2(u,v), 0.0).rgb,
        SAMPLE_TEXTURE2D_LOD(tex, samplerTex, float2(u,v)+float2(scaleOffset.y, 0.0), 0.0).rgb,
        color.b - block); // 根据Blue在block位置插值

    return color;
}
```

根据前面在 URP 的 ColorGradingLUT 中的分析，LDR Lut 还需要对颜色进行一次 tonemapping，这里直接使用 Color 库的函数，本来写了个丐版 aces，结果效果也太丐了。注意，添加 shader_feature，并且在脚本里进行控制，这里就不展示了。

```
float3 ApplyTonemapping(half3 input) {
    #ifdef _TONEMAP_ACES
    input = min(input, 60.0);
    input = AcesTonemap(unity_to_ACES(input));
    #endif

    // 把颜色钳位到0-1 输出LDR颜色
    return saturate(input);
}
half3 ApplyColorGrading(half3 input, TEXTURE2D_PARAM(customLutTex, customLutSampler)) {
    input = ApplyTonemapping(input);
    ...
}
```

如图，这是应用 LDR Lut 后的效果。

![[facad6c90b9438538bd7cd61e8a8a7ae_MD5.gif]]

可以看到，由于精度问题，应用 LUT 后的颜色过渡显然更明显了，比如绿色球的高光部分。这是 16x32 的 LDR Lut 应用另一个 Color Grading 的效果。

![[720516e9d18ff4fa4fa6268fbd985d87_MD5.jpg]]

最后，写了一个高斯 Bloom 注入在 ApplyLut 相同注入点前面，测试一下 tonemapping 的效果。效果和系统的是一样的。

![[52f433b62dd8b0034b9695ad75482b4f_MD5.gif]]

### HDR LUT

前面 URP 中的 ColorGradingLut 提到，HDR LUT 的存储信息有两个：第一个，ColorGrading。第二个，Tonemapping。由于 URP Lut 自带 Tonemapping，所以我们只需要对 HDR LUT 进行采样即可。需要注意的是，HDR LUT 的定义空间在 LogC，所以需要将输入值转到 LogC 后进行采样。

```
half3 ApplyColorGrading(half3 input, TEXTURE2D_PARAM(customLutTex, customLutSampler)) {
 #ifdef _HDR_GRADING
    float3 inputLutSpace = saturate(LinearToLogC(input));
    half3 outLut = ApplyLut(TEXTURE2D_ARGS(customLutTex, customLutSampler), inputLutSpace, _CustomLutParams.xyz);
    input = lerp(input, outLut, _Contribution);
 #else
    input = ApplyTonemapping(input);
    input.rgb = LinearToSRGB(input);
    half3 outLut = ApplyLut(TEXTURE2D_ARGS(customLutTex, customLutSampler), input, _CustomLutParams.xyz);
    input = lerp(input, outLut, _Contribution);
    input.rgb = SRGBToLinear(input.rgb);
 #endif

    return input;
}
```

应用 HDR LUT 前：

![[29c0cf4e0310d0ea437e7a488b11a3e8_MD5.jpg]]

应用 HDR LUT 后：

![[b8b43c9ad9df5c32f9af160b2df1cf9f_MD5.jpg]]

## URP 渲染 LUT

### 生成默认 LUT 带

首先需要在 RendererFeature 中添加生成 LUT 的 RenderPass。 **ColorGradingRendererFeature. cs**

```
using Unity.VisualScripting;
using UnityEngine;
using UnityEngine.Rendering;
using UnityEngine.Rendering.Universal;
using UnityEngine.Rendering.Universal.Internal;
using UnityEngine.Serialization;

struct ColorGradingLutParams{
    public bool hdr;
    public bool aces;
    public int lutSize;
}

struct ApplyColorLutParams{
    public bool hdr;
    public bool aces;
    public Texture customLut;
    public float contribution;
}

internal class ColorGradingLutRendererFeature : ScriptableRendererFeature{
    private const string mApplyColorLutShaderName = "Hidden/PostProcess/ApplyColorLut";
    private const string mLutBuilderShaderName = "Hidden/PostProcess/LutBuilder";

    #region Params Define

    [Header("ColorGradingLut")] public bool hdr = false;
    public bool aces = false;
    public int lutSize = 16;

    [Header("CustomColorLut")] 

    public Texture customLut = null;
    [Range(0.0f, 1.0f)] public float contribution = 0.0f;

    #endregion

    private Material mApplyColorLutMaterial;
    private Material mColorGradingLutMaterial;

    private ApplyColorLutParams mApplyColorLutParams;
    private ColorGradingLutParams mColorGradingLutParams;

    private ApplyColorLutRenderPass mApplyColorLutRenderPass = null;
    private ColorGradingLutRenderPass mColorGradingLutRenderPass = null;

    private const string mInternalLutName = "_InternalLut";

    public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) {
        if (renderingData.cameraData.postProcessEnabled) {
            if (mApplyColorLutRenderPass.isActive())
                renderer.EnqueuePass(mApplyColorLutRenderPass);
            if (mColorGradingLutRenderPass.isActive())
                renderer.EnqueuePass(mColorGradingLutRenderPass);
        }
    }

    public override void Create() {
        mColorGradingLutMaterial = CoreUtils.CreateEngineMaterial(mLutBuilderShaderName);
        mApplyColorLutMaterial = CoreUtils.CreateEngineMaterial(mApplyColorLutShaderName);

        mColorGradingLutParams.hdr = hdr;
        mColorGradingLutParams.aces = aces;
        mColorGradingLutParams.lutSize = lutSize;

        mApplyColorLutParams.hdr = hdr;
        mApplyColorLutParams.aces = aces;
        mApplyColorLutParams.customLut = customLut;
        mApplyColorLutParams.contribution = contribution;

        mColorGradingLutRenderPass = new ColorGradingLutRenderPass(mColorGradingLutMaterial, mColorGradingLutParams);
        mColorGradingLutRenderPass.renderPassEvent = RenderPassEvent.AfterRenderingPrePasses;

        mApplyColorLutRenderPass = new ApplyColorLutRenderPass(mApplyColorLutMaterial, mApplyColorLutParams);
        mApplyColorLutRenderPass.renderPassEvent = RenderPassEvent.BeforeRenderingPostProcessing;
    }

    protected override void Dispose(bool disposing) {
        CoreUtils.Destroy(mApplyColorLutMaterial);
    }
}
```

然后填写这个 RenderPass。传递的参数在后面进行解释。 **ColorGradingRenderPass. cs**

```
using UnityEngine;
using UnityEngine.Rendering;
using UnityEngine.Rendering.Universal;

internal class ColorGradingLutRenderPass : ScriptableRenderPass{
    private ProfilingSampler mProfilingSampler = new ProfilingSampler("CustomColorGradingLut");
    private Material mMaterial;

    private ColorGradingLutParams mColorGradingLutParams;

    private RTHandle mInternalLut;

    private int mLutParamsId = Shader.PropertyToID("_LutParams");

    private const string mInternalLutName = "_CustomInternalLut";

    public ColorGradingLutRenderPass(Material material, ColorGradingLutParams colorGradingLutParams) {
        mMaterial = material;
        mColorGradingLutParams = colorGradingLutParams;

        mInternalLut = RTHandles.Alloc(mInternalLutName, name: mInternalLutName);
    }

    public bool isActive() => mMaterial != null;

    public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) {
        var cmd = CommandBufferPool.Get();
        context.ExecuteCommandBuffer(cmd);
        cmd.Clear();

        var lutHeight = mColorGradingLutParams.lutSize;
        var lutWidth = lutHeight * lutHeight;

        // params = (lut_height, 0.5 / lut_width, 0.5 / lut_height, lut_height / lut_height - 1)
        mMaterial.SetVector(mLutParamsId, new Vector4(lutHeight, 0.5f / lutWidth, 0.5f / lutHeight, lutHeight / (lutHeight - 1.0f)));

        RenderTextureDescriptor descriptor = new RenderTextureDescriptor(lutWidth, lutHeight, RenderTextureFormat.ARGB32, 0, 1);

        RenderingUtils.ReAllocateIfNeeded(ref mInternalLut, descriptor, name: mInternalLutName, filterMode: FilterMode.Bilinear);
        cmd.SetRenderTarget(mInternalLut, RenderBufferLoadAction.DontCare, RenderBufferStoreAction.Store);

        using (new ProfilingScope(cmd, mProfilingSampler)) {
            cmd.DrawProcedural(Matrix4x4.identity, mMaterial, 0, MeshTopology.Triangles, 3);
        }

        // 设置全局纹理，让ApplyColorLut可以访问到
        cmd.SetGlobalTexture(mInternalLut.name, mInternalLut.nameID);
        cmd.ReleaseTemporaryRT(Shader.PropertyToID(mInternalLut.name));

        context.ExecuteCommandBuffer(cmd);
        cmd.Clear();
        CommandBufferPool.Release(cmd);
    }
}
```

下面写 Shader 代码。首先，我们使用绘制一个全屏三角形的方式进行纹理渲染，在顶点着色器中，根据顶点 id 判断顶点在全屏三角形的裁剪空间位置和 uv 插值坐标并返回。

![[fb446d851602aaa80bdcbd7e58d12041_MD5.jpg]]

```
float4 _LutParams;

struct Varyings {
    float4 positionCS : SV_POSITION;
    float2 uv : VAR_SCREEN_UV;
};

Varyings vert(uint vertexID : SV_VertexID) {
    Varyings output;
    // 根据id判断三角形顶点的坐标
    // 坐标顺序为(-1, -1) (-1, 3) (3, -1)
    output.positionCS = float4(vertexID <= 1 ? -1.0 : 3.0, vertexID == 1 ? 3.0 : -1.0, 0.0, 1.0);
    output.uv = float2(vertexID <= 1 ? 0.0 : 2.0, vertexID == 1 ? 2.0 : 0.0);
    // 不同API可能会产生颠倒的情况 进行判断
    if (_ProjectionParams.x < 0.0) {
        output.uv.y = 1.0 - output.uv.y;
    }
    return output;
}
```

片元着色器中，我们根据 uv 坐标得到当前的 color 并输出。如果使用 HDR，则返回 LogC 空间颜色。

```
half4 frag(Varyings input) : SV_Target {
    half3 color = GetDeafultLutValue(input.uv, _LutParams);
    #ifdef _HDR_GRADING
    return half4(LogCToLinear(color), 1.0);
    #else
    return half4(color, 1.0);
    #endif
}half4 frag(Varyings input) : SV_Target {
    half3 color = GetDeafultLutValue(input.uv, _LutParams);
    #ifdef _HDR_GRADING
    return half4(LogCToLinear(color), 1.0);
    #else
    return half4(color, 1.0);
    #endif
}
```

下面推导如何根据 uv 坐标计算 color，这其实就是根据 color 计算 lut uv 的反过程。首先写出根据 color 计算 uv 的公式：

 $\begin{align} block &= floor(b * (height-1))\\ u &= block * (1/height) + r * (height-1) * (1/width) + 0.5/width\\ v &= g * (height-1) * (1/height) + 0.5/height\\ \end{align}$

我们先将偏移到 texel 中心的 offset 减去， $u-=0.5/width,~v-=0.5/height$ 。然后先计算简单的 $v=g*height/(height-1)$ 。然后计算 $r$ 。

 $\begin{align} u * height &= block + r * (height-1) * (1/width) * height\\ &=block+r*(height-1)/height\\ r*(height-1)/height&=u*height-block\\ &=u*height-floor(b*(height-1)) \end{align}$

由于 U 轴将 blue 均分为 $height$ 个程度，所以 $u\in[b,b+1/height)$ ，所以 $u*height\in[b*height,b*height+1)$ _。所以_ $floor(b*(height-1))\leq u*height<floor(b*(height-1))+1$ 。即 $u*height-floor(b*(height-1))$ 为 $u*height$ _的小数部分_ $frac(u*height)$ 。综上所述， $r*(height-1)/height=frac(u*height)$ ， $r=frac(u*height)*height/(height-1)$ 。这这里，我们令 $floor(b*(height-1))=b*(height-1)$ ，则 $b*(height-1)=u*height-r*(height-1)/height$ _，得_ $b*(height-1)/height=u-r*(height-1)/(height*height)$ 。所以 $b=(u-r*(height-1)/(height*height))*height/(height-1)$ 。将 rgb 的公共参数提出来，得到 $params=(height, 0.5/width, 0.5/height, height/height-1$ 。

整理得到：

 $\begin{align} uv -&= params.yz\\ r&=frac(uv.x*params.x)\\ b&=u-r/params.x\\ g&=v\\ rgb&=params.w \end{align}$

所以，生成默认 LUT 带的函数如下：

```
// params = (lut_height, 0.5 / lut_width, 0.5 / lut_height, lut_height / lut_height - 1)
real3 GetDeafultLutValue(float2 uv, float4 params) {
    uv -= params.yz;
    real3 color;
    color.r = frac(uv.x * params.x);
    color.b = uv.x - color.r / params.x;
    color.g = uv.y;
    return color * params.w;
}
```

首先看一条 16x16 的 LDR LUT。

![[cf0ee62d9583f13dc793a64cb5f7a1e9_MD5.jpg]]

然后再看一条 32x32 的 HDR LUT。由于没进行 tonemapping，结果是色块。

![[b1a5c09492051899c0ebdc85e0fb0767_MD5.jpg]]

### ColorGrading

首先，我们需要声明 Inspector 属性。 **ColorGradingLutRendererFeature. cs**

```
#region Params Define

    [Header("ColorGradingLut")] public bool hdr = false;
    public bool aces = false;
    public int lutSize = 16;

    [Header("ColorAdjustments")] public float postExposure;
    [Range(-100f, 100f)] public float contrast; // 对比度
    [ColorUsage(false, true)] public Color colorFilter = Color.white; // 颜色滤镜 没有alpha的HDR颜色
    [Range(-180f, 180f)] public float hueShift; // 色相偏移
    [Range(-100f, 100f)] public float saturation; // 饱和度

    [Header("CustomColorLut")] public Texture customLut = null;
    [Range(0.0f, 1.0f)] public float contribution = 0.0f;

    #endregion
```

然后，在 RenderPass 中传递相应的参数。

```
// 将颜色调整属性发给material 曝光度、对比度、色相偏移和饱和度
        mMaterial.SetVector(mColorAdjustmentsId, new Vector4(
            Mathf.Pow(2f, mColorAdjustmentsParams.postExposure), // 曝光度 曝光单位是2的幂次
            mColorAdjustmentsParams.contrast * 0.01f + 1f, // 对比度 将范围从[-100, 100]转换到[0, 2]
            mColorAdjustmentsParams.hueShift * (1f / 360f), // 色相偏移 将范围从[-180, 180]转换到[-1, 1] ([-0.5, 0.5] ?)
            mColorAdjustmentsParams.saturation * 0.01f + 1f // 饱和度 将范围从[-100, 100]转换到[0, 2]
        ));
        mMaterial.SetColor(mColorFilterId, mColorAdjustmentsParams.colorFilter.linear); // 颜色滤镜 线性
```

按照 URP ColorGradingLut 的方式，后曝光是不渲染进 Lut 的，它通过采样时的预乘计算。所以我们把后曝光值发给 GPU。并且把 internalLut 的参数也发给 GPU。

```
// 设置全局参数，让ApplyColorLut能够访问到
        cmd.SetGlobalTexture(mInternalLut.name, mInternalLut.nameID); // _CustomInternalLut 纹理
        cmd.SetGlobalFloat(mPostExposureId, Mathf.Pow(2f, mColorAdjustmentsParams.postExposure)); // _PostExposure
        // params (1.0/width, 1.0/height, height-1.0)
        cmd.SetGlobalVector(mCustomInternalLutPramsId, new Vector4(1.0f / lutWidth, 1.0f / lutHeight, lutHeight - 1.0f, 0.0f));// _CustomInternalLutParams
```

获取完默认 Lut 带后，我们需要对对应的 color 应用 ColorGrading，并且还需要传递 tonemapping 方式。 **LutBuilderPass. hlsl**

```
half4 frag(Varyings input) : SV_Target {
    float3 color = GetDeafultLutValue(input.uv, _LutParams);
    #ifdef _HDR_GRADING
    #ifdef _TONEMAP_ACES
    return half4(ColorGrade(LogCToLinear(color), true), 1.0);
    #else
    return half4(ColorGrade(LogCToLinear(color)), 1.0);
    #endif
    #else
    return half4(ColorGrade(color), 1.0);
    #endif
}
```

ColorGrading 函数如下，具体解释照注释。注意，HDR Lut 需要渲染 tonemapping 转换。 **LutBuilderPass. hlsl**

```
// 根据色调映设空间(是否ACES) 返回对应亮度
float Luminance(float3 color, bool useACES) {
    return useACES ? AcesLuminance(color) : Luminance(color);
}

// 对比度
float3 ColorGradingContrast(float3 color, bool useACES) {
    // 为了更好的效果 如果使用ACES 则将颜色从线性空间转换到ACEScc空间 否则转换到logC空间
    color = useACES ? ACES_to_ACEScc(unity_to_ACES(color)) : LinearToLogC(color);
    // 从颜色中减去均匀的中间灰度，然后通过对比度进行缩放，然后在中间添加中间灰度
    color = (color - ACEScc_MIDGRAY) * _ColorAdjustments.y + ACEScc_MIDGRAY;
    // 将颜色转换回线性空间
    return useACES ? ACES_to_ACEScg(ACEScc_to_ACES(color)) : LogCToLinear(color);
}

// 颜色过滤
float3 ColorGradeColorFilter(float3 color) {
    // 将颜色与颜色滤镜相乘
    return color * _ColorFilter.rgb;
}

// 色相偏移
float3 ColorGradingHueShift(float3 color) {
    // 将颜色格式从rgb转换为hsv
    color = RgbToHsv(color);
    // 将色相偏移添加到h
    float hue = color.x + _ColorAdjustments.z;
    // 如果色相超出范围 将其截断
    color.x = RotateHue(hue, 0.0, 1.0);
    // 将颜色格式从hsv转换为rgb
    return HsvToRgb(color);
}

// 饱和度
float3 ColorGradingSaturation(float3 color, bool useACES) {
    // 获取颜色的亮度
    float luminance = Luminance(color, useACES);
    // 从颜色中减去亮度，然后通过饱和度进行缩放，然后在中间添加亮度
    return (color - luminance) * _ColorAdjustments.w + luminance;
}

half3 ColorGrade(float3 color, bool useAces = false) {
    // 对比度
    color = ColorGradingContrast(color, useAces);
    color = ColorGradeColorFilter(color);
    // 当对比度增加时，会导致颜色分量变暗，在这之后将颜色钳位
    color = max(color, 0.0);
    // 色相偏移
    color = ColorGradingHueShift(color);
    color = ColorGradingSaturation(color, useAces);
    // 当饱和度增加时，可能产生负数，在这之后将颜色钳位
    // 如果是ACES空间，则把颜色从ACEcg空间转回ACES 并且应用Aces tonemapping
    return max(useAces ? AcesTonemap(ACEScg_to_ACES(color)) : color, 0.0);
}
```

首先检查一下默认 HDR Lut Aces。

![[06c55170d7b4e776a8ebf8d46e581b82_MD5.jpg]]

然后检查一下 ColorGrading 后的情况。

![[9fc09c805610c7d8a1572de22adae474_MD5.jpg]]

### ApplyColorGrading

回到之前写好的 `ApplyColorLutPass.hlsl`，把 internalLut 的纹理采样的结果进行 lerp 即可。注意在 HDR Lut 下，我们认为自定义 lut 仅仅进行 ColorGrading，internalLut 进行 ColorGrading 和 Tonemapping，所以 InternalLut 在 LogC 空间下采样，自定义 lut 在 sRGB 空间下采样。

```
half3 ApplyColorGrading(half3 input, float postExposure, TEXTURE2D_PARAM(lutTex, lutSampler), float3 lutParams, TEXTURE2D_PARAM(customLutTex, customLutSampler), float3 customLutParams,
                        float customLutContrib) {
    input *= postExposure;
    #ifdef _HDR_GRADING
    // Internal HDR Lut 需要进行ColorGrading+Tonemapping，所以在LogC空间
    float3 inputLutSpace = saturate(LinearToLogC(input));
    input = ApplyLut2D(TEXTURE2D_ARGS(lutTex, lutSampler), inputLutSpace, lutParams);

    UNITY_BRANCH
    // Custom Lut 只需要进行ColorGrading，所以在sRGB空间
    if(customLutContrib > 0.0) {
        input = saturate(input);// LDR color
        input.rgb = LinearToSRGB(input.rgb);// In LDR do the lut in sRGB for the user Lut
        half3 outLut = ApplyLut(TEXTURE2D_ARGS(customLutTex, customLutSampler), inputLutSpace, _CustomLutParams.xyz);
        input = lerp(input, outLut, customLutContrib);
        input.rgb = SRGBToLinear(input.rgb);// turn back to Linear Space
    }
    #else
    // 首先进行tonemapping（根据设置）
    input = ApplyTonemapping(input);

    UNITY_BRANCH
    if (customLutContrib > 0.0) {
        // 转到sRGB空间采样LUT
        input.rgb = LinearToSRGB(input.rgb);
        half3 outLut = ApplyLut(TEXTURE2D_ARGS(customLutTex, customLutSampler), input, customLutParams);
        input = lerp(input, outLut, customLutContrib);
        input.rgb = SRGBToLinear(input.rgb);
    }

    input = ApplyLut(TEXTURE2D_ARGS(lutTex, lutSampler), input, lutParams);
    #endif

    return input;
}

half4 frag(Varyings input) : SV_Target {
    half3 color = GetSource(input).xyz;
    color = ApplyColorGrading(color, _PostExposure, TEXTURE2D_ARGS(_CustomInternalLut, sampler_CustomInternalLut), _CustomInternalLutParams.xyz, TEXTURE2D_ARGS(_CustomLut, sampler_CustomLut),
                              _CustomLutParams.xyz, _Contribution);
    return half4(color, 1.0);
}
```

如图，这是一张应用 LDR ColorGradingLut 的图像。

![[a7c4416b0a56d3a97fc5dc70503108a3_MD5.jpg]]

这是应用 HDR ColorGradingLut 的图像。

![[9f80a0c52e0f55b583265e2ade44dea1_MD5.jpg]]

这是应用 HDR ColorGradingLut Aces 的图像。

![[8298b8fffbb439940594339dd8f5828a_MD5.jpg]]

## 参考

[catlikecoding: custom srp](https://catlikecoding.com/unity/tutorials/custom-srp)

[Adobe: Color correction vs. color grading: What's the difference?](https://www.adobe.com/creativecloud/video/discover/color-correction-vs-color-grading.html)

[What is the LUT](https://www.youtube.com/watch?v=3ZpbUOGDWLE)

[The Beginner's Guide to LUTs](https://www.redsharknews.com/post-vfx/item/2966-the-beginners-guide-to-luts)

[3D Game Shaders For Beginners:LUT](https://lettier.github.io/3d-game-shaders-for-beginners/lookup-table.html)
# 4 HSV 和 RGB 转换
**RGB**比较常用（负数都显示成黑色）
**HSV** (Hue, Saturation, Value)
色调（H）、饱和度（S）和明度（V）
Hexadecimal：十六进制
![[Pasted image 20221003152912.png|200]]

转自：[Unity Shader - HSV 和 RGB 的相互转换 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/133441623)
对于颜色值，**RGB** 可能是我们接触最多的颜色模型，图像中的任何颜色都是由**红色（R）**、**绿色（G）**、**蓝色（B）** 这三个通道合成的，这三种颜色可以组合成几乎所有的颜色。

然而，它并不直观，比如我随便说一个 rgb 值，你能猜到他是什么颜色吗？几乎不可能，所以，后面引入了**HSV**、**HSL**等颜色模型。 **HSV** 相对于 **RGB** 来说是一种更加直观的颜色模型，**HSV**更加符合我们人类视觉。
### HSL 和 HSV 概念

**HSL** 即色相、饱和度、亮度（英语：Hue, Saturation, Lightness）。

**HSV** 即色相、饱和度、明度（英语：Hue, Saturation, Value），又称 HSB，其中 B 即英语：Brightness。

-   色相（H）是色彩的基本属性，就是平常所说的颜色名称，如红色、黄色等。
-   饱和度（S）是指色彩的纯度，越高色彩越纯，低则逐渐变灰，取 0-100%的数值。
-   明度（V），亮度（L），取 0-100%

### HSL 和 HSV 色彩空间比较

二者在数学上都是圆柱，但

**HSV** 在概念上可以被认为是颜色的倒圆锥体（白色在上底面圆心，黑点在下顶点）；

**HSL** 在概念上表示了一个双圆锥体和圆球体（白色在上顶点，黑色在下顶点，最大横切面的圆心是半程灰色）。
![[Pasted image 20221024161403.jpg|400]]
![[v2-33e2c70d429d9079c9b53e2f570032aa_1440w 2.webp]]
**以下函数由国外大神 [Inigo Quilez](https://link.zhihu.com/?target=http%3A//www.iquilezles.org/www/index.htm) 提供** [https://www.shadertoy.com/view/MsS3](https://link.zhihu.com/?target=https%3A//www.shadertoy.com/view/MsS3Wc)
### HSB/HSV 转 RGB

> [!bug]
> Color.hlsl 中已经内置了函数，不用自己写了！
> 

```c
// Official HSV to RGB conversion 
vec3 hsv2rgb( in vec3 c )
{
    vec3 rgb = clamp( abs(mod(c.x*6.0+vec3(0.0,4.0,2.0),6.0)-3.0)-1.0, 0.0, 1.0 );

    return c.z * mix( vec3(1.0), rgb, c.y);
}
// Smooth HSV to RGB conversion 
// https://www.shadertoy.com/view/MsS3Wc
vec3 hsv2rgb_smooth( in vec3 c )
{
    vec3 rgb = clamp( abs(mod(c.x*6.0+vec3(0.0,4.0,2.0),6.0)-3.0)-1.0, 0.0, 1.0 );

    rgb = rgb*rgb*(3.0-2.0*rgb); // cubic smoothing 

    return c.z * mix( vec3(1.0), rgb, c.y);
}
```
**ShaderLab 版：**
```c
float3 hsb2rgb( float3 c ){
    float3 rgb = clamp( abs(fmod(c.x*6.0+float3(0.0,4.0,2.0),6)-3.0)-1.0, 0, 1);
    rgb = rgb*rgb*(3.0-2.0*rgb);
    return c.z * lerp( float3(1,1,1), rgb, c.y);
}
```
### RGB 转 HSB/HSV
```c
vec3 rgb2hsb( in vec3 c ){
    vec4 K = vec4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0);
    vec4 p = mix(vec4(c.bg, K.wz),vec4(c.gb, K.xy),step(c.b, c.g));
    vec4 q = mix(vec4(p.xyw, c.r),vec4(c.r, p.yzx),step(p.x, c.r));
    float d = q.x - min(q.w, q.y);
    float e = 1.0e-10;
    return vec3(abs(q.z + (q.w - q.y) / (6.0 * d + e)),d / (q.x + e),q.x);
}
```
**ShaderLab 版:**
```c
float3 RGB2HSV(float3 c)
{
    float4 K = float4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0);
    float4 p = lerp(float4(c.bg, K.wz), float4(c.gb, K.xy), step(c.b, c.g));
    float4 q = lerp(float4(p.xyw, c.r), float4(c.r, p.yzx), step(p.x, c.r));

    float d = q.x - min(q.w, q.y);
    float e = 1.0e-10;
    return float3(abs(q.z + (q.w - q.y) / (6.0 * d + e)), d / (q.x + e), q.x);
}
```
### 实践
下面我们在 Unity Shader 中来看看

#### 笛卡尔坐标系下的 SHV
由下图我们可以清晰的看到 **X 轴决定色相，Y 轴决定饱和度**
![[Pasted image 20221024162348.jpg]]
```less
Shader "lcl/shader2D/HSV"
{

    SubShader
    {
        Pass
        {
            CGPROGRAM
            // vert_img 是 UnityCG.cginc 内置的
            #pragma vertex vert_img 
            #pragma fragment frag

            #include "UnityCG.cginc"

            //  该函数由国外大神 Iñigo Quiles 提供
            //  https://www.shadertoy.com/view/MsS3Wc
            float3 hsb2rgb( float3 c ){
                float3 rgb = clamp( abs(fmod(c.x*6.0+float3(0.0,4.0,2.0),6)-3.0)-1.0, 0, 1);
                rgb = rgb*rgb*(3.0-2.0*rgb);
                return c.z * lerp( float3(1,1,1), rgb, c.y);
            }

            // ---------------------------【片元着色器】---------------------------
            fixed4 frag (v2f_img i) : SV_Target
            {
                fixed4 col;
                // hsb 转换为 rgb
                // uv.x  决定 色相, 
                // uv.y  决定 亮度, 
                col.rgb = hsb2rgb(float3(i.uv.x, 1, 1-i.uv.y));
                return col;
            }
            ENDCG
        }
    }
}
```
#### 极坐标系下的 SHV

在极坐标系下，我们可以看到，**角度决定色相，半径决定饱和度，亮度固定**
![[Pasted image 20221024162435.jpg]]

```less
Shader "lcl/shader2D/HSVInPolarCoordinate"
{

    SubShader
    {
        Pass
        {
            CGPROGRAM
            // vert_img 是 UnityCG.cginc 内置的
            #pragma vertex vert_img 
            #pragma fragment frag

            #include "UnityCG.cginc"

            #define TWO_PI 6.28318530718

            //  该函数由国外大神 Iñigo Quiles 提供
            //  https://www.shadertoy.com/view/MsS3Wc
            float3 hsb2rgb( float3 c ){
                float3 rgb = clamp( abs(fmod(c.x*6.0+float3(0.0,4.0,2.0),6)-3.0)-1.0, 0, 1);
                rgb = rgb*rgb*(3.0-2.0*rgb);
                return c.z * lerp( float3(1,1,1), rgb, c.y);
            }

            // ---------------------------【片元着色器】---------------------------
            fixed4 frag (v2f_img i) : SV_Target
            {
                fixed4 col;
                // 笛卡尔坐标系转换到极坐标系
                float2 center = float2(0.5,0.5)-i.uv;
                float angle = atan2(center.y,center.x);
                float radius = length(center)*2.0;

                // 将角度 从(-PI, PI) 映射到 (0,1)范围
                // 角度决定色相, 半径决定饱和度, 亮度固定
                col.rgb = hsb2rgb(float3((angle/TWO_PI)+0.5,radius,1.0));
                return col;
            }
            ENDCG
        }
    }
}
```


## 改变贴图颜色
![[Pasted image 20221024163907.png]]
实现对 HSV 的修改，可以通过使用_Time 作为值传入 Add，实现动态变化。